<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="content-type" content="application/xhtml+xml; charset=windows-1252" />
    <meta name="author" content="Bhaskar.S">
    <meta name="description" content="Basics of Natural Language Processing using NLTK">
    <meta name="subject" content="Basics of Natural Language Processing using NLTK">
    <meta name="keywords" content="python, nlp, nltk">
    <meta name="robots" content="index, follow">
    <meta name="googlebot" content="index, follow">
    <title>Basics of Natural Language Processing using NLTK</title>
    <link href="../css/polarsparc-v2.4.css" type="text/css" rel="stylesheet" />
  </head>
  <body>
    <br/>
    <table borber="0">
      <tr>
        <td valign="bottom"><span id="gen-home"></span></td>
        <td valign="bottom"><span id="gen-home-a"><a id="gen-home-a" href="https://polarsparc.github.io/">PolarSPARC</a></span></td>
      </tr>
    </table>
    <br/>
    <div id="gen-title-div">
      <p>Basics of Natural Language Processing using NLTK</p>
    </div>
    <br/>
    <table id="gen-ad-table">
      <tbody>
        <tr>
          <td class="author-td">Bhaskar S</td>
          <td class="date-td">01/22/2023</td>
        </tr>
      </tbody>
    </table>
    <hr class="gen-line-hr"/>
    <br/>
    <div id="gen-step-div">
      <p>Overview</p>
    </div>
    <br/>
    <div id="para-div">
      <p><span class="hi-yellow">Natural Language Processing</span> (or <span class="hi-yellow">NLP</span> for short) is related to
        the processing and analysis of the unstructured language interactions between the computer systems and the humans, with the
        intent of building interactive real-world applications that can interpret and understand the context of those unstructured
        language interactions and react accordingly.</p>
    </div>
    <div id="para-div">
      <p>The following are some of the common use-cases for NLP:</p>
      <ul id="gen-sqr-ul">
        <li><p>Customer Service Chatbots</p></li>
        <li><p>Customer Sentiment Analysis</p></li>
        <li><p>Semantic Search Engines</p></li>
        <li><p>Spam Detection</p></li>
        <li><p>Task Oriented Virtual Assistants</p></li>
      </ul>
    </div>
    <div id="para-div">
      <p><span class="hi-yellow">Natural Language Toolkit</span> (or <span class="hi-yellow">NLTK</span> for short) is one of the
        popular Python based open source natural language processing libraries for performing various language processing tasks.</p>
    </div>
    <br/>
    <div id="gen-step-div">
      <p>Installation and Setup</p>
    </div>
    <br/>
    <div id="para-div">
      <p>Installation is assumed to be on a Linux desktop running Ubuntu 22.04 LTS using the user <span class="bold">alice</span>.
        Also, it assumed is that Python 3 is setup in a <span class="bold">Virtual Environment</span>.</p>
      <p>Open a <span class="bold">Terminal</span> window in which we will excute the various commands.</p>
    </div>
    <div id="para-div">
      <p>Let us first create a directory named <span class="hi-blue">/home/alice/nltk_data</span> by executing the following command
        in the Terminal:</p>
    </div>
    <div id="gen-cmd-div">
      <p>$ mkdir -p $HOME/nltk_data</p>
    </div>
    <div id="para-div">
      <p>Now, to install few of the Python packages - the <span class="hi-blue">nltk</span>, the <span class="hi-blue">jupyter</span>,
        the <span class="hi-blue">scikit-learn</span>, and the <span class="hi-blue">wordcloud</span> packages, execute the following
        commands in the Terminal:</p>
    </div>
    <div id="gen-cmd-div">
      <p>$ pip install nltk</p>
      <p>$ pip install jupyter</p>
      <p>$ pip install scikit-learn</p>
      <p>$ pip install wordcloud</p>
    </div>
    <div id="para-div">
      <p>Next, we need to download and setup all the NLTK provided data packages.</p>
    </div>
    <div id="para-div">
      <p>Execute the following command in the Terminal:</p>
    </div>
    <div id="gen-cmd-div">
      <p>$ python</p>
    </div>
    <div id="para-div">
      <p>The prompt will change to <span class="hi-grey">&gt;&gt;&gt;</span> indicating the Python REPL mode.</p>
    </div>
    <div id="para-div">
      <p>Execute the following commands in the Python REPL:</p>
    </div>
    <div id="gen-cmd-div">
      <p>&gt;&gt;&gt; import nltk</p>
      <p>&gt;&gt;&gt; nltk.download()</p>
    </div>
    <div id="para-div">
      <p>The following would be the typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.1</h4>
      <pre>NLTK Downloader
---------------------------------------------------------------------------
    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit
---------------------------------------------------------------------------</pre>
    </div>
    <br/>
    <div id="para-div">
      <p>The prompt will change to <span class="hi-grey">Downloader&gt;</span> indicating the NLTK REPL mode.</p>
    </div>
    <div id="para-div">
      <p>Type the letter <span class="hi-grey">c</span> and press ENTER in the NLTK REPL as shown below:</p>
    </div>
    <div id="gen-cmd-div">
      <p>Downloader&gt; c</p>
    </div>
    <div id="para-div">
      <p>The following would be the typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.2</h4>
      <pre>Data Server:
  - URL: &lt;https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml&gt;
  - 7 Package Collections Available
  - 111 Individual Packages Available

Local Machine:
  - Data directory: /usr/local/share/nltk_data</pre>
    </div>
    <br/>
    <div id="para-div">
      <p>The prompt will change to <span class="hi-grey">Config&gt;</span> indicating the NLTK Config REPL mode.</p>
    </div>
    <div id="para-div">
      <p>Type the letter <span class="hi-grey">d</span> and press ENTER in the NLTK Config REPL as shown below:</p>
    </div>
    <div id="gen-cmd-div">
      <p>Config&gt; d</p>
    </div>
    <div id="para-div">
      <p>The prompt will change to <span class="hi-grey">New Directory&gt;</span>, where we will type the NLTK data directory and
        press ENTER shown below:</p>
    </div>
    <div id="gen-cmd-div">
      <p>New Directory&gt; /home/alice/nltk_data</p>
    </div>
    <div id="para-div">
      <p>The prompt will change to <span class="hi-grey">Config&gt;</span> indicating the NLTK Config REPL mode.</p>
    </div>
    <div id="para-div">
      <p>Type the letter <span class="hi-grey">m</span> and press ENTER in the NLTK Config REPL as shown below:</p>
    </div>
    <div id="gen-cmd-div">
      <p>Config&gt; m</p>
    </div>
    <div id="para-div">
      <p>The following would be the typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.3</h4>
      <pre>---------------------------------------------------------------------------
    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit
---------------------------------------------------------------------------</pre>
    </div>
    <br/>
    <div id="para-div">
      <p>The prompt will change to <span class="hi-grey">Downloader&gt;</span> indicating the NLTK REPL mode.</p>
    </div>
    <div id="para-div">
      <p>Type the letter <span class="hi-grey">l</span> and press ENTER in the NLTK REPL as shown below:</p>
    </div>
    <div id="gen-cmd-div">
      <p>Downloader&gt; l</p>
    </div>
    <div id="para-div">
      <p>The following would be the typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.4</h4>
      <pre>Packages:
  [ ] abc................. Australian Broadcasting Commission 2006
  [ ] alpino.............. Alpino Dutch Treebank
  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger
  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)
  [ ] basque_grammars..... Grammars for Basque
  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information
                            Extraction Systems in Biology)
  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model
  [ ] book_grammars....... Grammars from NLTK Book
  [ ] brown............... Brown Corpus
  [ ] brown_tei........... Brown Corpus (TEI XML Version)
  [ ] cess_cat............ CESS-CAT Treebank
  [ ] cess_esp............ CESS-ESP Treebank
  [ ] chat80.............. Chat-80 Data Files
  [ ] city_database....... City Database
  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)
  [ ] comparative_sentences Comparative Sentence Dataset
  [ ] comtrans............ ComTrans Corpus Sample
  [ ] conll2000........... CONLL 2000 Chunking Corpus
  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus
Hit Enter to continue: </pre>
    </div>
    <br/>
    <div id="para-div">
      <p>Press ENTER each time to page through the various NLTK packages. In the end one would end up in an output as show below:</p>
    </div>
    <div id="out-div">
      <h4>Output.5</h4>
      <pre>Collections:
  [ ] all-corpora......... All the corpora
Hit Enter to continue: 
  [ ] all-nltk............ All packages available on nltk_data gh-pages
                            branch
  [ ] all................. All packages
  [ ] book................ Everything used in the NLTK Book
  [ ] popular............. Popular packages
  [ ] tests............... Packages for running tests
  [ ] third-party......... Third-party data packages

([*] marks installed packages)

---------------------------------------------------------------------------
    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit
---------------------------------------------------------------------------</pre>
    </div>
    <br/>
    <div id="para-div">
      <p>Type the letter <span class="hi-grey">d</span> and press ENTER in the NLTK REPL as shown below:</p>
    </div>
    <div id="gen-cmd-div">
      <p>Downloader&gt; d</p>
    </div>
    <div id="para-div">
      <p>The following would be the typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.6</h4>
      <pre>-Download which package (l=list; x=cancel)?</pre>
    </div>
    <br/>
    <div id="para-div">
      <p>The prompt will change to <span class="hi-grey">Identifier&gt;</span> indicating the NLTK Download REPL mode.</p>
    </div>
    <div id="para-div">
      <p>Type the word <span class="hi-grey">all</span> and press ENTER in the NLTK Download REPL as shown below:</p>
    </div>
    <div id="gen-cmd-div">
      <p>Identifier&gt; all</p>
    </div>
    <div id="para-div">
      <p>This will download and setup of all the NLTK data packages and in the end the following would be the typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.7</h4>
      <pre>Downloading collection 'all'
      | 
      | Downloading package abc to /home/alice/nltk_data...
      |   Unzipping corpora/abc.zip.
      | Downloading package alpino to /home/alice/nltk_data...
      |   Unzipping corpora/alpino.zip.
      | Downloading package averaged_perceptron_tagger to /home/alice/nltk_data...
      |   Unzipping taggers/averaged_perceptron_tagger.zip.
... SNIP ...
      | Downloading package wordnet_ic to /home/alice/nltk_data...
      |   Unzipping corpora/wordnet_ic.zip.
      | Downloading package words to /home/alice/nltk_data...
      |   Unzipping corpora/words.zip.
      | Downloading package ycoe to /home/alice/nltk_data...
      |   Unzipping corpora/ycoe.zip.
      | 
    Done downloading collection all

---------------------------------------------------------------------------
    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit
---------------------------------------------------------------------------</pre>
    </div>
    <br/>
    <div id="para-div">
      <p>Type the letter <span class="hi-grey">q</span> and press ENTER in the NLTK REPL as shown below:</p>
    </div>
    <div id="gen-cmd-div">
      <p>Downloader&gt; q</p>
    </div>
    <div id="para-div">
      <p>The prompt will change to <span class="hi-grey">&gt;&gt;&gt;</span> indicating the Python REPL mode.</p>
    </div>
    <div id="para-div">
      <p>Execute the following command in the Python REPL to exit:</p>
    </div>
    <div id="gen-cmd-div">
      <p>&gt;&gt;&gt; exit()</p>
    </div>
    <div id="para-div">
      <p>We are now <span class="bold">DONE</span> with the installation and setup process.</p>
    </div>
    <br/>
    <div id="gen-step-div">
      <p>Hands-on NLTK</p>
    </div>
    <br/>
    <div id="para-div">
      <p>All the commands in this hands-on section will be using the <span class="hi-yellow">Jupyter</span> notebook.</p>
    </div>
    <div id="para-div">
      <p>To launch the Jupyter Notebook, execute the following command in the Terminal:</p>
    </div>
    <div id="gen-cmd-div">
      <p>$ jupyter notebook</p>
    </div>
    <div id="para-div">
      <p>To load the nltk Python module, run the following statement in the Jupyter cell:</p>
    </div>
    <div id="cmd-div">
      <p>import nltk</p>
    </div>
    <div id="para-div">
      <p>To set the correct path to the nltk data packages, run the following statement in the Jupyter cell:</p>
    </div>
    <div id="cmd-div">
      <p>nltk.data.path.append("/home/alice/nltk_data")</p>
    </div>
    <div id="para-div">
      <p>To list all the text from <span class="bold">Project Gutengerg</span> included in nltk, run the following statement in the
        Jupyter cell:</p>
    </div>
    <div id="cmd-div">
      <p>nltk.corpus.gutenberg.fileids()</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="NLTK Files" class="gen-img-cls" src="./images/nltk-01.png">
        <div class="gen-img-cap">Figure.1</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p><span class="hi-yellow">Tokenization</span> is the process of breaking a text into either its sentences or its words. For
        example, the text <span class="bold">Alice in the Wonderland</span> is tokenized into a list of words - ['Alice', 'in',
        'the', 'Wonderland'].</p>
    </div>
    <div id="para-div">
      <p>To load and get all the words from the text <span class="bold">Alice in the Wonderland</span> included in nltk, run the
        following statement in the Jupyter cell:</p>
    </div>
    <div id="cmd-div">
      <p>words = nltk.corpus.gutenberg.words('carroll-alice.txt')</p>
    </div>
    <div id="para-div">
      <p>In this demo, we will use a custom text file <span class="bold">charles-christmas_carol.txt</span> for <span class="bold">
        The Christmas Carol</span> from the Project Gutenberg.</p>
    </div>
    <div id="para-div">
      <p>To load and tokenize all the words from the custom text <span class="bold">charles-christmas_carol.txt</span> to the lower
        case, run the following statements in the Jupyter cell:</p>
    </div>
    <div id="cmd-div">
      <p>from nltk.tokenize import word_tokenize</p>
      <p>with open ('txt_data/charles-christmas_carol.txt') as fcc:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;all_tokens = word_tokenize(fcc.read().lower())</p>
    </div>
    <div id="para-div">
      <p><span class="hi-yellow">Stop Words</span> are the commonly used filler words (such as 'a', 'and', 'on', etc) that add little
        value to the context of the text.</p>
    </div>
    <div id="para-div">
      <p>To display all the Stop Words from the English language defined in nltk, run the following statements in the Jupyter cell:</p>
    </div>
    <div id="cmd-div">
      <p>from nltk.corpus import stopwords</p>
      <p>stop_words = stopwords.words('english')</p>
      <p>stop_words</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output showing an initial subset of entries:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="NLTK Stop Words" class="gen-img-cls" src="./images/nltk-02.png">
        <div class="gen-img-cap">Figure.2</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p><span class="hi-yellow">Normalization</span> is the process of cleaning the text to make it more uniform, such as removing
        the punctuations and the Stop Words.</p>
    </div>
    <div id="para-div">
      <p>To remove all the punctuations from our custom text, run the following statement in the Jupyter cell:</p>
    </div>
    <div id="cmd-div">
      <p>cc_tokens = [word for word in all_tokens if word.isalpha()]</p>
    </div>
    <div id="para-div">
      <p>To remove all the Stop Words from our custom text, run the following statement in the Jupyter cell:</p>
    </div>
    <div id="cmd-div">
      <p>all_words = [word for word in cc_tokens if word not in stop_words]</p>
    </div>
    <div id="para-div">
      <p><span class="hi-yellow">Frequency Distribution</span> is the count of each of the words from a text.</p>
    </div>
    <div id="para-div">
      <p>To display the Frequency Distribution of the words from our custom text, run the following statements in the Jupyter cell:</p>
    </div>
    <div id="cmd-div">
      <p>all_fd = nltk.FreqDist(all_words)</p>
      <p>all_fd</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output showing a subset of entries:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="NLTK Freq Dist" class="gen-img-cls" src="./images/nltk-03.png">
        <div class="gen-img-cap">Figure.3</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>To display the 20 most commonly used words from our custom text, run the following statement in the Jupyter cell:</p>
    </div>
    <div id="cmd-div">
      <p>all_fd.most_common(20)</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="NLTK Most Common" class="gen-img-cls" src="./images/nltk-04.png">
        <div class="gen-img-cap">Figure.4</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p><span class="hi-yellow">Hapaxes</span> are the unique words that occur only once in the entire text.</p>
    </div>
    <div id="para-div">
      <p>To display all the Hapaxes from our custom text, run the following statements in the Jupyter cell:</p>
    </div>
    <div id="cmd-div">
      <p>single_words = all_fd.hapaxes()</p>
      <p>single_words</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output showing an initial subset of entries:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="NLTK Hapaxes" class="gen-img-cls" src="./images/nltk-05.png">
        <div class="gen-img-cap">Figure.5</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p><span class="hi-yellow">Stemming</span> is the process of reducing words to their root forms. For example, the words
        <span class="bold">walked</span> and <span class="bold">walking</span> will be reduced to the root word <span class="bold">
        walk</span>.</p>
    </div>
    <div id="para-div">
      <p>To create and display the root words for all the words from our custom text, run the following statements in the Jupyter
        cell:</p>
    </div>
    <div id="cmd-div">
      <p>lancaster = nltk.LancasterStemmer()</p>
      <p>cc_stems = [lancaster.stem(word) for word in cc_words]</p>
      <p>cc_stems</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output showing an initial subset of entries:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="NLTK Root Words" class="gen-img-cls" src="./images/nltk-06.png">
        <div class="gen-img-cap">Figure.6</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p><span class="hi-yellow">Parts of Speech</span> is part of a language grammer and indicates the role of a word in the text.</p>
    </div>
    <div id="para-div">
      <p>The English language has 8 parts of speech, which are as follows:</p>
    </div>
    <table id="col3-table">
      <thead>
      <tr>
        <th>Part of Speech</th>
        <th>Role</th>
        <th>Example</th>
      </tr>
      </thead>
      <tbody>
        <tr>
          <td class="col3-c1-odd"><span class="bold">Noun</span></td>
          <td class="col3-c2-odd">A person, place, or thing</td>
          <td class="col3-c3-odd">Alice, New York, Apple</td>
        </tr>
        <tr>
          <td class="col3-c1-even"><span class="bold">Pronoun</span></td>
          <td class="col3-c2-even">Replaces a Noun</td>
          <td class="col3-c3-even">He, She, You</td>
        </tr>
        <tr>
          <td class="col3-c1-odd"><span class="bold">Adjective</span></td>
          <td class="col3-c2-odd">Describes a Noun</td>
          <td class="col3-c3-odd">Big, Colorful, Great</td>
        </tr>
        <tr>
          <td class="col3-c1-even"><span class="bold">Verb</span></td>
          <td class="col3-c2-even">An action or state of being</td>
          <td class="col3-c3-even">Can, Go, Learn</td>
        </tr>
        <tr>
          <td class="col3-c1-odd"><span class="bold">Adverb</span></td>
          <td class="col3-c2-odd">Describes a Verb, Adjective, or another Adverb</td>
          <td class="col3-c3-odd">Always, Silently, Very</td>
        </tr>
        <tr>
          <td class="col3-c1-even"><span class="bold">Preposition</span></td>
          <td class="col3-c2-even">Links a Noun or Pronoun to another word</td>
          <td class="col3-c3-even">At, From, To</td>
        </tr>
        <tr>
          <td class="col3-c1-odd"><span class="bold">Conjunction</span></td>
          <td class="col3-c2-odd">Joins words or phrases</td>
          <td class="col3-c3-odd">And, But, So</td>
        </tr>
        <tr>
          <td class="col3-c1-even"><span class="bold">Interjection</span></td>
          <td class="col3-c2-even">An Exclamation</td>
          <td class="col3-c3-even">Oh, Ouch, Wow</td>
        </tr>
      </tbody>
    </table>
    <div id="para-div">
      <p>To display all the abbreviations of the different Parts of Speech from the English language defined in nltk, run the following
        statement in the Jupyter cell:</p>
    </div>
    <div id="cmd-div">
      <p>nltk.help.upenn_tagset()</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output showing a subset of entries:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="NLTK Parts of Speech" class="gen-img-cls" src="./images/nltk-07.png">
        <div class="gen-img-cap">Figure.7</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>To determine and display the Parts of Speech for all the words from our custom text, run the following statements in the
        Jupyter cell:</p>
    </div>
    <div id="cmd-div">
      <p>cc_pos2 = nltk.pos_tag(cc_words, tagset='universal')</p>
      <p>cc_pos2</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output showing an initial subset of entries:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="NLTK POS" class="gen-img-cls" src="./images/nltk-08.png">
        <div class="gen-img-cap">Figure.8</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p><span class="hi-yellow">Chunking</span> is the process of identifying groups of words from a text that make sense to be
        together, such as, the noun phrases or verb phrases, etc. For example, given the text 'Alice likes to travel to New York
        City', the word Tokenization will split the words 'New', 'York', and 'City'. With Chunking they will be grouped together,
        which makes more sense.</p>
      <p>Chunking works on the words after they have been tagged with their corresponding Parts of Speech.</p>
    </div>
    <div id="para-div">
      <p>To determine and display the noun phrases for all the words (with their Parts of Speech tagged) from our custom text, run
        the following statements in the Jupyter cell:</p>
    </div>
    <div id="cmd-div">
      <p>parser = nltk.RegexpParser(r'NOUN_PHRASE: {<ADJ>*<NOUN>+}')</p>
      <p>cc_chunks = parser.parse(cc_pos2)</p>
      <p>print(cc_chunks)</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output showing an initial subset of entries:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="NLTK Chunks" class="gen-img-cls" src="./images/nltk-09.png">
        <div class="gen-img-cap">Figure.9</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p><span class="hi-yellow">Named Entity Recognition</span> is the process of identifying named entities such as people,
        locations, organizations, etc.</p>
      <p>Like Chunking, the Named Entity Recognition works on the words after they have been tagged with their corresponding Parts
        of Speech.</p>
    </div>
    <div id="para-div">
      <p>To determine and display the named entities for a given simple text, run the following statements in the Jupyter cell:</p>
    </div>
    <div id="cmd-div">
      <p>text = 'Alice is the CEO of Acme International and has been tasked with building a Space Ship for Mars'</p>
      <p>words = nltk.word_tokenize(text)</p>
      <p>tags = nltk.pos_tag(words)</p>
      <p>ner = nltk.ne_chunk(tags)</p>
      <p>print(ner)</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output showing all of the entries:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="NLTK Named Entities" class="gen-img-cls" src="./images/nltk-10.png">
        <div class="gen-img-cap">Figure.10</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>Until now, we have been processing words one at a time (referred to as <span class="hi-yellow">Unigrams</span>). Sometimes
        we may have to process words two at a time (referred to as <span class="hi-yellow">Bigrams</span>) or words three at a time
        (referred to as <span class="hi-yellow">Trigrams</span>) to extract the intent of the text. A more generic way of processing
        n-words at a time is referred to as <span class="hi-yellow">n-grams</span>.</p>
    </div>
    <div id="para-div">
      <p>To find and display the bigrams for from our custom text, run the following statements in the Jupyter cell:</p>
    </div>
    <div id="cmd-div">
      <p>from nltk.util import ngrams</p>
      <p>all_bigrams = list(ngrams(all_words, 2))</p>
      <p>all_bigrams</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output showing an initial subset of entries:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="NLTK Bigrams" class="gen-img-cls" src="./images/nltk-11.png">
        <div class="gen-img-cap">Figure.11</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The number argument in the <span class="hi-blue">ngrams(all_words, 2)</span> indicates the number of words to consider at
        a time.</p>
    </div>
    <br/>
    <div id="gen-step-div">
      <p>References</p>
    </div>
    <br/>
    <div id="para-div">
      <p><a href="https://github.com/bhaskars-repo/Datasets/blob/main/charles-christmas_carol.txt" target="_blank"><span class="bold">Christmas Carol Text</span></a></p>
      <p><a href="https://www.nltk.org/" target="_blank"><span class="bold">NLTK Documentation</span></a></p>
    </div>
    <br/>
    <hr class="gen-line-hr" />
    <div>
      <a id="gen-footer-a" href="https://polarsparc.github.io/">&copy;&nbsp;PolarSPARC</a>
    </div>
  </body>
</html>
