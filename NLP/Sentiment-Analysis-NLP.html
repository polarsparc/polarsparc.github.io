<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="content-type" content="application/xhtml+xml; charset=windows-1252" />
    <meta name="author" content="Bhaskar.S">
    <meta name="description" content="Textual Sentiment Analysis using NLTK and Scikit-Learn">
    <meta name="subject" content="Textual Sentiment Analysis using NLTK and Scikit-Learn">
    <meta name="keywords" content="python, nlp, nltk, scikit-learn">
    <meta name="robots" content="index, follow">
    <meta name="googlebot" content="index, follow">
    <title>Textual Sentiment Analysis using NLTK and Scikit-Learn</title>
    <link href="../css/polarsparc-v2.4.css" type="text/css" rel="stylesheet" />
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script>
      MathJax = {
        tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  </head>
  <body>
    <br/>
    <table borber="0">
      <tr>
        <td valign="bottom"><span id="gen-home"></span></td>
        <td valign="bottom"><span id="gen-home-a"><a id="gen-home-a" href="https://polarsparc.github.io/">PolarSPARC</a></span></td>
      </tr>
    </table>
    <br/>
    <div id="gen-title-div">
      <p>Textual Sentiment Analysis using NLTK and Scikit-Learn</p>
    </div>
    <br/>
    <table id="gen-ad-table">
      <tbody>
        <tr>
          <td class="author-td">Bhaskar S</td>
          <td class="date-td">02/11/2023</td>
        </tr>
      </tbody>
    </table>
    <hr class="gen-line-hr"/>
    <br/>
    <div id="gen-step-div">
      <p>Overview</p>
    </div>
    <br/>
    <div id="para-div">
      <p>In the articles, <a href="https://polarsparc.github.io/NLP/Python-NLTK.html" target="_blank"><span class="bold">Basics of
        Natural Language Processing using NLTK</span></a> and <a href="https://polarsparc.github.io/NLP/Feature-Extraction-NLP.html"
        target="_blank"><span class="bold">Feature Extraction for Natural Language Processing</span></a>, we covered the necessary
        ingredients of Natural Language Processing (or NLP for short).</p>
    </div>
    <div id="para-div">
      <p><span class="hi-yellow">Sentiment Analysis</span> in NLP is the process of determining if a textual data (especially the
        feedback from customers) is <span class="hi-green">POSITIVE</span> or <span class="hi-red">NEGATIVE</span>.</p>
    </div>
    <div id="para-div">
      <p>In this following sections, we will demonstrate how one can perform sentiment analysis (using nltk and scikit-learn) by
        leveraging the <a href="https://www.kaggle.com/datasets/d4rklucif3r/restaurant-reviews" target="_blank"><span class="bold">
        Restaurant Reviews</span></a> data set from Kaggle.</p>
    </div>
    <br/>
    <div id="gen-step-div">
      <p>Installation and Setup</p>
    </div>
    <br/>
    <div id="para-div">
      <p>Please refer to the article <a href="https://polarsparc.github.io/NLP/Feature-Extraction-NLP.html" target="_blank">
        <span class="bold">Feature Extraction for Natural Language Processing</span></a> for the environment installation and setup.</p>
    </div>
    <div id="para-div">
      <p>Open a <span class="bold">Terminal</span> window in which we will excute the various commands.</p>
    </div>
    <div id="para-div">
      <p>To launch the Jupyter Notebook, execute the following command in the Terminal:</p>
    </div>
    <div id="gen-cmd-div">
      <p>$ jupyter notebook</p>
    </div>
    <br/>
    <br/>
    <div id="gen-step-div">
      <p>Hands-On Sentiment Analysis</p>
    </div>
    <br/>
    <div id="para-div">
      <p>The first step is to import all the necessary Python modules such as, pandas, nltk, and scikit-learn by running the
        following statements in the Jupyter cell:</p>
    </div>
    <br/>
    <div id="gen-src-outer-div">
      <div class="gen-src-body">
<pre>import nltk
import pandas as pd
from collections import defaultdict
from nltk.tokenize import WordPunctTokenizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>To set the correct path to the nltk data packages, run the following statement in the Jupyter cell:</p>
    </div>
    <br/>
    <div id="gen-src-outer-div">
      <div class="gen-src-body">
<pre>nltk.data.path.append("/home/alice/nltk_data")</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>Download the <span class="bold">Kaggle Restaurant Reviews</span> data set to the directory /home/alice/txt_data.</p>
    </div>
    <div id="para-div">
      <p>To load the tab-separated restaurant reviews data set into pandas and display the first 10 rows, run the following statements
        in the Jupyter cell:</p>
    </div>
    <br/>
    <div id="gen-src-outer-div">
      <div class="gen-src-body">
<pre>reviews_df = pd.read_csv('./txt_data/Restaurant_Reviews.tsv', sep='\t')
reviews_df.head(10)</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Restaurant Reviews" class="gen-img-cls" src="./images/nlp-sentiment-01.png">
        <div class="gen-img-cap">Figure.1</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>To display basic information about the reviews dataframe, run the following statement in the Jupyter cell:</p>
    </div>
    <br/>
    <div id="gen-src-outer-div">
      <div class="gen-src-body">
<pre>reviews_df.info()</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Reviews Information" class="gen-img-cls" src="./images/nlp-sentiment-02.png">
        <div class="gen-img-cap">Figure.2</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>To extract all the text reviews as a list of sentences (corpus) and display a subset of the reviews from the end, run the
        following statements in the Jupyter cell:</p>
    </div>
    <br/>
    <div id="gen-src-outer-div">
      <div class="gen-src-body">
<pre>reviews_txt = reviews_df.Review.values.tolist()
reviews_txt</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Reviews as List" class="gen-img-cls" src="./images/nlp-sentiment-03.png">
        <div class="gen-img-cap">Figure.3</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>To create an instance of the word tokenizer and lemmatizer, run the following statements in the Jupyter cell:</p>
    </div>
    <br/>
    <div id="gen-src-outer-div">
      <div class="gen-src-body">
<pre>word_tokenizer = WordPunctTokenizer()
word_lemmatizer = nltk.WordNetLemmatizer()</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>To cleanse the sentences from the corpus by removing the punctuations, two-letter words, converting words to their roots,
        collecting all the unique words from the reviews corpus, and display a subset of the reviews from the end run the following
        statements in the Jupyter cell:</p>
    </div>
    <br/>
    <div id="gen-src-outer-div">
      <div class="gen-src-body">
<pre>vocabulary_dict = defaultdict(int)
cleansed_review_txt = []
for review in reviews_txt:
    tokens = word_tokenizer.tokenize(review)
    alpha_words = [word.lower() for word in tokens if word.isalpha() and len(word) > 2]
    final_words = [word_lemmatizer.lemmatize(word) for word in alpha_words]
    for word in final_words:
        vocabulary_dict[word] += 1
    cleansed_review = ' '.join(final_words)
    cleansed_review_txt.append(cleansed_review)
cleansed_review_txt</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Cleanse Corpus" class="gen-img-cls" src="./images/nlp-sentiment-04.png">
        <div class="gen-img-cap">Figure.4</div>
      </div>
    </div>
    <br/>
    <br/>
    <div id="warn-div">
      <h4>*** ATTENTION ***</h4>
      <pre>We are not <span class="underbold">REMOVING</span> the stop words as we will lose important context from the reviews. As an example, if we remove the stop word 'not', then the review 'Food was not good' would become 'Food was good'</pre>
    </div>
    <br/>
    <div id="para-div">
      <p>To update the original reviews in the reviews dataframe with the cleansed restaurant reviews and display the first 10 rows,
        run the following statements in the Jupyter cell:</p>
    </div>
    <br/>
    <div id="gen-src-outer-div">
      <div class="gen-src-body">
<pre>reviews_df['Review'] = cleansed_review_txt
reviews_df.head(10)</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Cleansed Dataframe" class="gen-img-cls" src="./images/nlp-sentiment-05.png">
        <div class="gen-img-cap">Figure.5</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>To display the number of unique words in our reviews corpus, run the following statement in the Jupyter cell:</p>
    </div>
    <br/>
    <div id="gen-src-outer-div">
      <div class="gen-src-body">
<pre>len(vocabulary_dict)</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Vocabulary Count" class="gen-img-cls" src="./images/nlp-sentiment-06.png">
        <div class="gen-img-cap">Figure.6</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>There are quite a lot of words in our reviews corpus. We will filter span class="underbold">OUT</span> words which occur
        less than 3 times in our corpus in order to manage the number of unique words and hence reduce the feature dimension.</p>
    </div>
    <div id="para-div">
      <p>To filter out words and display the final subset of the vocabulary entries from our corpus, run the following statements
        in the Jupyter cell:</p>
    </div>
    <br/>
    <div id="gen-src-outer-div">
      <div class="gen-src-body">
<pre>vocabulary = []
sorted_vocabulary = sorted(vocabulary_dict.items(), key=lambda kv: kv[1], reverse=True)
for word, count in sorted_vocabulary:
    if count > 2:
        vocabulary.append(word)
vocabulary</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Corpus Vocabulary" class="gen-img-cls" src="./images/nlp-sentiment-07.png">
        <div class="gen-img-cap">Figure.7</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>To display the number of unique words in our reviews corpus after filtering, run the following statement in the Jupyter cell:</p>
    </div>
    <br/>
    <div id="gen-src-outer-div">
      <div class="gen-src-body">
<pre>len(vocabulary)</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Vocabulary Count Final" class="gen-img-cls" src="./images/nlp-sentiment-08.png">
        <div class="gen-img-cap">Figure.8</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>To create an instance of the TF-IDF vectorizer, run the following statement in the Jupyter cell:</p>
    </div>
    <br/>
    <div id="gen-src-outer-div">
      <div class="gen-src-body">
<pre>word_vectorizer = TfidfVectorizer(vocabulary=vocabulary)</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>To create a new TF-IDF scores vector for our reviews corpus as a pandas dataframe, add the <span class="bold">Liked</span>
        column as the column <span class="bold">_pos_neg</span>, and display the first 10 rows of the dataframe, run the following
        statements in the Jupyter cell:</p>
    </div>
    <br/>
    <div id="gen-src-outer-div">
      <div class="gen-src-body">
<pre>matrix = word_vectorizer.fit_transform(reviews_df['Review']).toarray()
reviews_vector_df = pd.DataFrame(data=matrix, columns=vocabulary)
reviews_vector_df['_pos_neg'] = reviews_df['Liked']
reviews_vector_df.head(10)</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="TF-IDF with Liked" class="gen-img-cls" src="./images/nlp-sentiment-09.png">
        <div class="gen-img-cap">Figure.9</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The next step is to split the vectorized reviews dataframe into two parts - a training data set and a test data set. The
        training data set is used to train the different machine learning models and the test data set is used to evaluate the models.
        In this
        use case, we split 75% of the samples into the training dataset and remaining 25% into the test dataset as shown below:</p>
    </div>
    <div id="para-div">
      <p>To split 75% of the vectorized reviews dataframe into the training set and remaining 25% into the test set, run the following
        statements in the Jupyter cell:</p>
    </div>
    <br/>
    <div id="gen-src-outer-div">
      <div class="gen-src-body">
<pre>X_train, X_test, y_train, y_test = train_test_split(reviews_vector_df, reviews_vector_df['_pos_neg'], test_size=0.25, random_state=101)
X_train = X_train.drop('_pos_neg', axis=1)
X_test = X_test.drop('_pos_neg', axis=1)</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>In the articles, <a href="https://polarsparc.github.io/MachineLearning/Classification-2.html" target="_blank"><span class=
        "bold">Machine Learning - Logistic Regression using Scikit-Learn - Part 2</span></a>,
        <a href="https://polarsparc.github.io/MachineLearning/Classification-3.html" target="_blank"><span class="bold">Machine Learning - Naive
        Bayes using Scikit-Learn</span></a>, and <a href="https://polarsparc.github.io/MachineLearning/RandomForest.html" target=
        "_blank"><span class="bold">Machine Learning - Random Forest using Scikit-Learn</span></a>, we covered the necessary details
        for the three machine learning models - <span class="bold">Logistic Regression</span>, <span class="bold">Naive Bayes</span>,
        and <span class="bold">Random Forest</span>.</p>
    </div>
    <div id="para-div">
      <p>To initialize the three machine learning models, run the following statements in the Jupyter cell:</p>
    </div>
    <br/>
    <div id="gen-src-outer-div">
      <div class="gen-src-body">
<pre>model_names = ['Logistic Regression', 'Multinomial Naive Bayes', 'Random Forest']
model_instances = [LogisticRegression(), MultinomialNB(), RandomForestClassifier()]
ml_models = zip(model_names, model_instances)</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>To train each of the machine learning models using the training data, test the trained model using the test data, compute
        the accuracy score of the model, and display the results, run the following statements in the Jupyter cell:</p>
    </div>
    <br/>
    <div id="gen-src-outer-div">
      <div class="gen-src-body">
<pre>for name, model in ml_models:
  model.fit(X_train, y_train)
  y_predict = model.predict(X_test)
  score = accuracy_score(y_test, y_predict)
  print(f'Model: {name}, Accuracy: {score}')</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Model Results" class="gen-img-cls" src="./images/nlp-sentiment-10.png">
        <div class="gen-img-cap">Figure.10</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>As is evident from the Figure.10 above, the Logistic Regression model performed better for our restaurant reviews use-case.</p>
    </div>
    <br/>
    <div id="gen-step-div">
      <p>Jupyter Notebook</p>
    </div>
    <br/>
    <div id="para-div">
      <p>The following is the link to the <span class="bold">Jupyter Notebook</span> that provides an hands-on demo for this
        article:</p>
      <ul id="blue-sqr-ul">
        <li><p><a href="https://github.com/bhaskars-repo/TextAnalytics/blob/main/sentiment_analysis.ipynb" target="_blank">
          <span class="bold">Sentiment Analysis</span></a></p></li>
      </ul>
    </div>
    <br/>
    <div id="gen-step-div">
      <p>References</p>
    </div>
    <br/>
    <div id="para-div">
      <p><a href="https://polarsparc.github.io/NLP/Python-NLTK.html" target="_blank"><span class="bold">Basics of Natural Language Processing using NLTK</span></a></p>
      <p><a href="https://polarsparc.github.io/NLP/Feature-Extraction-NLP.html" target="_blank"><span class="bold">Feature Extraction for Natural Language Processing</span></a></p>
      <p><a href="https://www.nltk.org/" target="_blank"><span class="bold">NLTK Documentation</span></a></p>
      <p><a href="https://polarsparc.github.io/MachineLearning/Classification-2.html" target="_blank"><span class="bold">Machine Learning - Logistic Regression using Scikit-Learn - Part 2</span></a></p>
      <p><a href="https://polarsparc.github.io/MachineLearning/Classification-3.html" target="_blank"><span class="bold">Machine Learning - Naive Bayes using Scikit-Learn</span></a></p>
      <p><a href="https://polarsparc.github.io/MachineLearning/RandomForest.html" target="_blank"><span class="bold">Machine Learning - Random Forest using Scikit-Learn</span></a></p>
    </div>
    <br/>
    <hr class="gen-line-hr" />
    <div>
      <a id="gen-footer-a" href="https://polarsparc.github.io/">&copy;&nbsp;PolarSPARC</a>
    </div>
  </body>
</html>
