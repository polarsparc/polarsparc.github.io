<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="content-type" content="application/xhtml+xml; charset=windows-1252" />
    <meta name="author" content="Bhaskar.S">
    <meta name="description" content="Introduction to Linear Algebra - Part 3">
    <meta name="subject" content="Introduction to Linear Algebra - Part 3">
    <meta name="keywords" content="math, mathematics, linear algebra">
    <meta name="robots" content="index, follow">
    <meta name="googlebot" content="index, follow">
    <title>Introduction to Linear Algebra - Part 3</title>
    <link href="../css/polarsparc-v2.4.css" type="text/css" rel="stylesheet" />
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script>
      MathJax = {
        tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
      };
    </script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.0.5/es5/tex-chtml.js"></script>
    <!-- script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script -->
  </head>
  <body>
    <br/>
    <table borber="0">
      <tr>
        <td valign="bottom"><span id="ps-home-3"></span></td>
        <td valign="bottom"><span id="home-a-3"><a id="home-a-3" href="https://polarsparc.github.io/">PolarSPARC</a></span></td>
      </tr>
    </table>
    <br/>
    <div id="title-div-3">
      <p>Introduction to Linear Algebra - Part 3</p>
    </div>
    <br />
    <table id="ad-table-3">
      <tbody>
        <tr>
          <td class="author-td">Bhaskar S</td>
          <td class="date-td">02/13/2022</td>
        </tr>
      </tbody>
    </table>
    <hr class="line-hr-3" />
    <br/>
    <div id="para-div">
      <p>In <a href="https://polarsparc.github.io/Mathematics/LinearAlgebra-2.html">Part 2</a> of this series, we covered some of the
        basics of <span class="bold">Matrics</span>, in particular, some concepts, basic operations, and system of equations. In this
        part, we will continue with our journey on <span class="hi-yellow">Matrices</span>.</p>
    </div>
    <div id="section-div-3">
      <p>System of Linear Equations - 2</p>
    </div>
    <div id="para-div">
      <p>There are situations, when one will <span class="underbold">NOT</span> be able to find a solution for a system of equations.</p>
    </div>
    <div id="para-div">
      <p>Let us look at an example to illustrate this case.</p>
      <table id="row2-table-3">
        <thead>
          <tr>
            <th class="th-c1">Example-1</th>
            <th>Solve for the following three linear equations: $\begin{align*} & x - y + 2z = 4 \\ & x + z = 6 \\ & 2x - 3y + 5z =
              4 \end{align*}$</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td colspan="2">
              <p>Let us convert the three linear equations to an augmented matrix as follows:</p>
              <p>$\begin{bmatrix} 1 & -1 & 2 &\bigm| & 4 \\ 1 & 0 & 1 &\bigm| & 6 \\ 2 & -3 & 5 &\bigm| & 4 \end{bmatrix}$</p>
              <p>Performing the operation $R_2 + (-1)R_1 \rightarrow R_2$, we get the following:</p>
              <p>$\begin{bmatrix} 1 & -1 & 2 &\bigm| & 4 \\ 0 & 1 & -1 &\bigm| & 2 \\ 2 & -3 & 5 &\bigm| & 4 \end{bmatrix}$</p>
              <p>Performing the operation $R_3 + (-2)R_1 \rightarrow R_3$, we get the following:</p>
              <p>$\begin{bmatrix} 1 & -1 & 2 &\bigm| & 4 \\ 0 & 1 & -1 &\bigm| & 2 \\ 0 & -1 & 1 &\bigm| & -4 \end{bmatrix}$</p>
              <p>Performing the operation $R_3 + R_2 \rightarrow R_3$, we get the following:</p>
              <p>$\begin{bmatrix} 1 & -1 & 2 &\bigm| & 4 \\ 0 & 1 & -1 &\bigm| & 2 \\ 0 & 0 & 0 &\bigm| & -2 \end{bmatrix}$</p>
              <p>The last row of the matrix is all ZEROs and indicates $0.z = -2$, which is inconsistent.</p>
              <p>Hence, this example of system of equations has <span class="bold">NO</span> solution.</p>
            </td>
          </tr>
        </tbody>
      </table>
    </div>
    <br/>
    <div id="para-div">
      <p>One can continue the process of the Gaussian elimination on the augmented matrix, which is in a row echelon form to further
        reduce it to a matrix form, where all the elements are <span class="underbold">0</span>s, except for the elements along the
        diagonal, which are all <span class="underbold">1</span>s, shown as follows:</p>
      <p>$\begin{bmatrix} 1 & 0 & 0 &\bigm| & p \\ 0 & 1 & 0 &\bigm| & q \\ 0 & 0 & 1 &\bigm| & r \end{bmatrix}$</p>
      <p>In other words, the elements of the diagonal must be all ONEs, while all other elements above and below the diagonal must
        be ZEROs.</p>
      <p>This form of augmented matrix is called the <span class="hi-yellow">Reduced Row Echelon</span> form.</p>
    </div>
    <div id="para-div">
      <p>This process of finding the solution for a system of equations, by simplifying a given augmented matrix, to a reduced row
        echelon form is called <span class="hi-yellow">Gauss-Jordan Elimination</span>.</p>
    </div>
    <div id="para-div">
      <p>Let us look at an example using the Gauss-Jordan elimination.</p>
      <table id="row2-table-3">
        <thead>
          <tr>
            <th class="th-c1">Example-2</th>
            <th>Solve for the following three linear equations: $\begin{align*} & x + 4y + 2z = 1 \\ & 2x + 5y + z = 5 \\ & 4x + 10y
              - z = 1 \end{align*}$</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td colspan="2">
              <p>Let us convert the three linear equations to an augmented matrix as follows:</p>
              <p>$\begin{bmatrix} 1 & 4 & 2 &\bigm| & 1 \\ 2 & 5 & 1 &\bigm| & 5 \\ 4 & 10 & -1 &\bigm| & 1 \end{bmatrix}$</p>
              <p>Performing the operation $R_2 + (-2)R_1 \rightarrow R_2$, we get the following:</p>
              <p>$\begin{bmatrix} 1 & 4 & 2 &\bigm| & 1 \\ 0 & -3 & -3 &\bigm| & 3 \\ 4 & 10 & -1 &\bigm| & 1 \end{bmatrix}$</p>
              <p>Performing the operation $(-\frac{1}{3})R_2 \rightarrow R_2$, we get the following:</p>
              <p>$\begin{bmatrix} 1 & 4 & 2 &\bigm| & 1 \\ 0 & 1 & 1 &\bigm| & -1 \\ 4 & 10 & -1 &\bigm| & 1 \end{bmatrix}$</p>
              <p>Performing the operation $R_3 + (-4)R_1 \rightarrow R_3$, we get the following:</p>
              <p>$\begin{bmatrix} 1 & 4 & 2 &\bigm| & 1 \\ 0 & 1 & 1 &\bigm| & -1 \\ 0 & -6 & -9 &\bigm| & -3 \end{bmatrix}$</p>
              <p>Performing the operation $(-\frac{1}{3})R_3 \rightarrow R_3$, we get the following:</p>
              <p>$\begin{bmatrix} 1 & 4 & 2 &\bigm| & 1 \\ 0 & 1 & 1 &\bigm| & -1 \\ 0 & 2 & 3 &\bigm| & 1 \end{bmatrix}$</p>
              <p>Performing the operation $R_3 + (-2)R_2 \rightarrow R_3$, we get the following:</p>
              <p>$\begin{bmatrix} 1 & 4 & 2 &\bigm| & 1 \\ 0 & 1 & 1 &\bigm| & -1 \\ 0 & 0 & 1 &\bigm| & 3 \end{bmatrix}$</p>
              <p>Performing the operation $R_2 + (-1)R_3 \rightarrow R_2$, we get the following:</p>
              <p>$\begin{bmatrix} 1 & 4 & 2 &\bigm| & 1 \\ 0 & 1 & 0 &\bigm| & -4 \\ 0 & 0 & 1 &\bigm| & 3 \end{bmatrix}$</p>
              <p>Performing the operation $R_1 + (-2)R_3 \rightarrow R_1$, we get the following:</p>
              <p>$\begin{bmatrix} 1 & 4 & 0 &\bigm| & -5 \\ 0 & 1 & 0 &\bigm| & -4 \\ 0 & 0 & 1 &\bigm| & 3 \end{bmatrix}$</p>
              <p>Performing the operation $R_1 + (-4)R_2 \rightarrow R_1$, we get the following:</p>
              <p>$\begin{bmatrix} 1 & 0 & 0 &\bigm| & 11 \\ 0 & 1 & 0 &\bigm| & -4 \\ 0 & 0 & 1 &\bigm| & 3 \end{bmatrix}$</p>
              <p>Now, we can derive the solution by mapping the variables to the values directly: $x = 11$, $y = -4$, and $z = 3$.</p>
            </td>
          </tr>
        </tbody>
      </table>
    </div>
    <br/>
    <div id="section-div-3">
      <p>Inversion of Matrix</p>
    </div>
    <div id="para-div">
      <p>The multiplicative <span class="hi-yellow">Inverse</span> of a matrix $\textbf{A}$, denoted as $\textbf{A}^{-1}$, is another
        matrix, such that the multiplication of $\textbf{A}$ and its inverse $\textbf{A}^{-1}$ produces an identity matrix. In other
        words, $\textbf{A}^{-1}\textbf{A} = \mathbf{I}$.</p>
      <p>Just like in algebra, if we know the values for the two matrices $\textbf{A}$ and $\textbf{B}$ and we are give $\textbf{A}
        \textbf{X} = \textbf{B}$, then we can solve for matrix $\textbf{X}$ using the multiplicative inverse $\textbf{A}^{-1}$.</p>
      <p>In other words:</p>
      <p>$\textbf{A}\textbf{X} = \textbf{B}$</p>
      <p>Multiplying both side with the multiplicative inverse $\textbf{A}^{-1}$, we get:</p>
      <p>$\textbf{A}^{-1}\textbf{A}\textbf{X} = \textbf{A}^{-1}\textbf{B}$</p>
      <p>We know $\textbf{A}^{-1}\textbf{A} = \mathbf{I}$</p>
      <p>Therefore, $\mathbf{I}\textbf{X} = \textbf{A}^{-1}\textbf{B}$</p>
      <p>We also know $\mathbf{I}\textbf{X} = \textbf{X}$</p>
      <p>Hence, $\textbf{X} = \textbf{A}^{-1}\textbf{B}$</p>
    </div>
    <div id="para-div">
      <p>Note that <span class="underbold">ONLY</span> square matrices have multiplicative inverses and not all square matrices
        have inverses.</p>
    </div>
    <div id="para-div">
      <p>The following is an example of a multiplicative inverse for a 2 x 2 square matrix:</p>
      <p>$\textbf{A} = \begin{bmatrix} -1 & 2 \\ -1 & 1 \end{bmatrix}$</p>
      <p>$\textbf{A}^{-1} = \begin{bmatrix} 1 & -2 \\ 1 & -1 \end{bmatrix}$</p>
      <p>$\textbf{A}^{-1}\textbf{A} = \begin{bmatrix} -1 & 2 \\ -1 & 1 \end{bmatrix} \begin{bmatrix} 1 & -2 \\ 1 & -1 \end{bmatrix}
        = \begin{bmatrix} -1.1+2.1 & -1.-2+2.-1 \\ -1.1+1.1 & -1.-2+1.-1 \end{bmatrix} = \begin{bmatrix} -1+2 & 2-2 \\ -1+1 & 2-1
        \end{bmatrix} \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} = \mathbf{I_2}$</p>
    </div>
    <div id="para-div">
      <p>Let us look at an example for finding the matrix multiplicative inverse.</p>
      <table id="row2-table-3">
        <thead>
          <tr>
            <th class="th-c1">Example-3</th>
            <th>Find the multiplicative inverse for the matrix: $\textbf{A} = \begin{bmatrix} 1 & 4 \\ -1 & -3 \end{bmatrix}$</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td colspan="2">
              <p>Let $\textbf{A}^{-1} = \begin{bmatrix} a & b \\ c & d \end{bmatrix}$</p>
              <p>We know $\textbf{A}^{-1}\textbf{A} = \begin{bmatrix} 1 & 4 \\ -1 & -3 \end{bmatrix}\begin{bmatrix} a & b \\ c & d
                \end{bmatrix} = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$</p>
              <p>That is, $\textbf{A}^{-1}\textbf{A} = \begin{bmatrix} a+4c & b+4d \\ -a-3c & -b-3d \end{bmatrix} = \begin{bmatrix}
                1 & 0 \\ 0 & 1 \end{bmatrix}$</p>
              <p>Equating the corresponding entries we get the following system of equations:</p>
              <p>$\begin{align*} & a + 4c = 1 \\ & -a - 3c = 0 \\ & b + 4d = 0 \\ & -b - 3d = 1 \end{align*}$</p>
              <p>Solving the equations $\begin{align*} & a + 4c = 1 ; -a - 3c = 0 \end{align*}$, we get: $a = -3$ and $c = 1$</p>
              <p>Similaryly, solving the equations $\begin{align*} & b + 4d = 0 ; -b - 3d = 1 \end{align*}$, we get: $b = -4$ and
                $d = 1$</p>
              <p>Therefore, $\textbf{A}^{-1} = \begin{bmatrix} -3 & -4 \\ 1 & 1 \end{bmatrix}$</p>
            </td>
          </tr>
        </tbody>
      </table>
    </div>
    <br/>
    <div id="para-div">
      <p>In the Example-3 above, there were two system of equations to solve - one for <span class="hi-vanila">a</span> and
        <span class="hi-vanila">a</span>; the other for <span class="hi-vanila">b</span> and <span class="hi-vanila">d</span>.</p>
      <p>The coefficients for both the set of equations are the same - the only difference was in the constant values that come
        from the corresponding identity matrix elements.</p>
      <p>By <span class="hi-yellow">adjoining</span> the coefficient matrix with the identity matrix, one could use the Gauss-Jordan
        elimination process on this combined matrix to arrive at the inverse of the coefficient matrix.</p>
    </div>
    <div id="para-div">
      <p>We use the Gauss-Jordan elimination on the adjoined matrix in the following example.</p>
      <table id="row2-table-3">
        <thead>
          <tr>
            <th class="th-c1">Example-4</th>
            <th>Find the multiplicative inverse for the matrix: $\textbf{A} = \begin{bmatrix} 1 & 4 \\ -1 & -3 \end{bmatrix}$ by
              adjoining the coefficient matrix with the identity matrix</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td colspan="2">
              <p>Given $\textbf{A} = \begin{bmatrix} 1 & 4 \\ -1 & -3 \end{bmatrix}$</p>
              <p>The adjoined matrix is $\begin{bmatrix} 1 & 4 & 1 & 0 \\ -1 & -3 & 0 & 1\end{bmatrix}$</p>
              <p>We will use the Gauss-Jordan Elimination process on the adjoined matrix.</p>
              <p>Performing the operation $R_2 + R_1 \rightarrow R_2$, we get the following:</p>
              <p>$\begin{bmatrix} 1 & 4 & 1 & 0 \\ 0 & 1 & 1 & 1\end{bmatrix}$</p>
              <p>Performing the operation $R_1 + (-4)R_2 \rightarrow R_1$, we get the following:</p>
              <p>$\begin{bmatrix} 1 & 0 & -3 & -4 \\ 0 & 1 & 1 & 1\end{bmatrix}$</p>
              <p>Since the above adjoined matrix is in the form $\mathbf{I}\textbf{A}^{-1}$, we are done</p>
              <p>In other words, when the identity matrix is swapped to the left in the resulting adjoined matrix as above, we have
                the multiplicative inverse to the right.</p>
              <p>Therefore, $\textbf{A}^{-1} = \begin{bmatrix} -3 & -4 \\ 1 & 1 \end{bmatrix}$</p>
            </td>
          </tr>
        </tbody>
      </table>
    </div>
    <br/>
    <div id="para-div">
      <p>Let us look at an example for finding the matrix multiplicative inverse using matrix adjoining.</p>
      <table id="row2-table-3">
        <thead>
          <tr>
            <th class="th-c1">Example-5</th>
            <th>Find the multiplicative inverse for the matrix: $\textbf{A} = \begin{bmatrix} 1 & -1 & 0 \\ 1 & 0 & -1 \\ -6 & 2 & 3
              \end{bmatrix}$</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td colspan="2">
              <p>Given $\textbf{A} = \begin{bmatrix} 1 & -1 & 0 \\ 1 & 0 & -1 \\ -6 & 2 & 3 \end{bmatrix}$</p>
              <p>The adjoined matrix is $\begin{bmatrix} 1 & -1 & 0 & 1 & 0 & 0 \\ 1 & 0 & -1 & 0 & 1 & 0 \\ -6 & 2 & 3 & 0 & 0 & 1
                \end{bmatrix}$</p>
              <p>We will use the Gauss-Jordan Elimination process on the adjoined matrix.</p>
              <p>Performing the operation $R_2 + (-1)R_1 \rightarrow R_2$, we get the following:</p>
              <p>$\begin{bmatrix} 1 & -1 & 0 & 1 & 0 & 0 \\ 0 & 1 & -1 & -1 & 1 & 0 \\ -6 & 2 & 3 & 0 & 0 & 1 \end{bmatrix}$</p>
              <p>Performing the operation $R_3 + 6R_1 \rightarrow R_3$, we get the following:</p>
              <p>$\begin{bmatrix} 1 & -1 & 0 & 1 & 0 & 0 \\ 0 & 1 & -1 & -1 & 1 & 0 \\ 0 & -4 & 3 & 6 & 0 & 1 \end{bmatrix}$</p>
              <p>Performing the operation $R_3 + 4R_2 \rightarrow R_3$, we get the following:</p>
              <p>$\begin{bmatrix} 1 & -1 & 0 & 1 & 0 & 0 \\ 0 & 1 & -1 & -1 & 1 & 0 \\ 0 & 0 & -1 & 2 & 4 & 1 \end{bmatrix}$</p>
              <p>Performing the operation $(-1)R_3 \rightarrow R_3$, we get the following:</p>
              <p>$\begin{bmatrix} 1 & -1 & 0 & 1 & 0 & 0 \\ 0 & 1 & -1 & -1 & 1 & 0 \\ 0 & 0 & 1 & -2 & -4 & -1 \end{bmatrix}$</p>
              <p>Performing the operation $R_2 + R_3 \rightarrow R_2$, we get the following:</p>
              <p>$\begin{bmatrix} 1 & -1 & 0 & 1 & 0 & 0 \\ 0 & 1 & 0 & -3 & -3 & -1 \\ 0 & 0 & 1 & 2 & 4 & 1 \end{bmatrix}$</p>
              <p>Performing the operation $R_1 + R_1 \rightarrow R_1$, we get the following:</p>
              <p>$\begin{bmatrix} 1 & 0 & 0 & -2 & -3 & -1 \\ 0 & 1 & 0 & -3 & -3 & -1 \\ 0 & 0 & 1 & 2 & 4 & 1 \end{bmatrix}$</p>
              <p>Since the above adjoined matrix is in the form $\mathbf{I}\textbf{A}^{-1}$, we are done</p>
              <p>Therefore, $\textbf{A}^{-1} = \begin{bmatrix} -2 & -3 & -1 \\ -3 & -3 & -1 \\ 2 & 4 & 1 \end{bmatrix}$</p>
            </td>
          </tr>
        </tbody>
      </table>
    </div>
    <br/>
    <div id="step-div-3">
      <p>Orthogonal Matrix</p>
    </div>
    <div id="para-div">
      <p>A matrix $\textbf{A}$ that has the property $\textbf{A}^T\textbf{A} = \textbf{A}\textbf{A}^T = \textbf{I}$. This also means,
        $\textbf{A}^T = \textbf{A}^{-1}$.</p>
      <p>The following is an example of a 3 x 3 orthogonal matrix:</p>
      <p>$\begin{bmatrix} 1 & 0 & 0 \\ 0 & -1 & 0 \\ 0 & 0 & 1 \end{bmatrix}$</p>
    </div>
    <div id="section-div-3">
      <p>Determinant of Matrix</p>
    </div>
    <div id="para-div">
      <p>The <span class="hi-yellow">Determinant</span> of a square matrix $\textbf{A}$, denoted as $det(\textbf{A})$ or $\lvert
        \textbf{A} \rvert$, is a scalar (a single real number) that provides some insights about the matrix.</p>
      <p>Note that the determinant of a matrix is defined <span class="underbold">ONLY</span> for a square matrix.</p>
      <p>For a matrix $\textbf{A}$, if the determinant $det(\textbf{A}) = 0$, then it implies that the matrix $\textbf{A}$ is a 
        <span class="hi-yellow">Singular</span> matrix (meaning the matrix has columns or rows that are linearly dependent) and
        that the matrix is <span class="underbold">NOT</span> invertible (meaning $\textbf{A}^{-1}$ does not exist).</p>
      <p>The determinant of a 2 x 2 matrix $\textbf{A} = \begin{bmatrix} a & b \\ c & d \end{bmatrix}$ can be computed as:
        $det(\textbf{A}) = ad - bc$.</p>
      <p>Consider the following 2 x 2 matrix:</p>
      <p>$\textbf{A} = \begin{bmatrix} -2 & 1 \\ -4 & 2 \end{bmatrix}$</p>
      <p>The determinant $det(\textbf{A}) = (-2).2 - 1.(-4) = -4 + 4 = 0$</p>
      <p>Notice how the first column of the matrix $\textbf{A}$ is a multiple of the second column. This implies that the columns
        of the matrix $\textbf{A}$ is linearly dependent (or matrix $\textbf{A}$ is a singular matrix).</p>
      <p>Now, consider the following 2 x 2 matrix:</p>
      <p>$\textbf{B} = \begin{bmatrix} 2 & -3 \\ 1 & 2 \end{bmatrix}$</p>
      <p>The determinant $det(\textbf{B}) = 2.2 - (-3).1 = 4 + 3 = 7$</p>
    </div>
    <div id="para-div">
      <p>To find the determinant of a higher dimension matrix, we use a recursive approach.</p>
      <p>Consider the 3 x 3 matrix $\textbf{A} = \begin{bmatrix} a & b & c \\ d & e & f \\ g & h & i \end{bmatrix}$.</p>
      <p>The determinant $det(\textbf{A}) = a \begin{vmatrix} e & f \\ h & i \end{vmatrix} - b \begin{vmatrix} d & f \\ g & i
        \end{vmatrix} + c \begin{vmatrix} d & e \\ g & h \end{vmatrix}$</p>
      <p>That is, $det(\textbf{A}) = a (ei - fh) - b (di - fg) + c (dh - eg)$</p>
    </div>
    <div id="para-div">
      <p>The following is a pictorial illustration for finding the determinant of a 3 x 3 matrix:</p>
    </div>
    <div id="img-outer-div-3"> <img alt="Matrix Determinant" src="./images/linalgebra-5.png"
      class="img-cls-3" />
      <div class="img-cap-3">Fig.1</div>
    </div>
    <br/>
    <div id="para-div">
      <p>Now, consider the 4 x 4 matrix $\textbf{B} = \begin{bmatrix} a & b & c & d \\ e & f & g & h \\ i & j & k & l \\ m & n & o
        & p \end{bmatrix}$.</p>
      <p>The determinant $det(\textbf{B}) = a \begin{vmatrix} f & g & h \\ j & k & l \\ n & o & p \end{vmatrix} - b \begin{vmatrix}
        e & g & h \\ i & k & l \\ m & o & p \end{vmatrix} + c \begin{vmatrix} e & f & h \\ i & j & l \\ m & n & p \end{vmatrix} - d
        \begin{vmatrix} e & f & g \\ i & j & k \\ m & n & o \end{vmatrix}$</p>
      <p>That is, $det(\textbf{B}) = a [f (kp - lo) - g (jp - ln) + h (jo - kn)] - b [e (kp - lo) - g (ip - lm) + h (io - km)] +
        c [e (jp - ln) - f (ip - lm) + h (in - jm)] - d [e (jo - kn) - f (io - km) + g (in - jm)]$</p>
    </div>
    <div id="para-div">
      <p>Notice that the sign of the successive determinants of the sub-matrices alternates: -ve, +ve, -ve, and so on.</p>
    </div>
    <div id="para-div">
      <p>Let us look at an example for a 3 x 3 matrix.</p>
      <table id="row2-table-3">
        <thead>
          <tr>
            <th class="th-c1">Example-6</th>
            <th>Find the determinant of the matrix: $\textbf{A} = \begin{bmatrix} 0 & 2 & 1 \\ 3 & -1 & 2 \\ 4 & 0 & 1 \end{bmatrix}$</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td colspan="2">
              <p>Given $\textbf{A} = \begin{bmatrix} 0 & 2 & 1 \\ 3 & -1 & 2 \\ 4 & 0 & 1 \end{bmatrix}$</p>
              <p>The determinant $det(\textbf{A}) = 0.\begin{vmatrix} -1 & 2 \\ 0 & 1 \end{vmatrix} - 2.\begin{vmatrix} 3 & 2 \\ 4 & 1
                \end{vmatrix} + 1.\begin{vmatrix} 3 & -1 \\ 4 & 0 \end{vmatrix}$</p>
              <p>That is, $det(\textbf{A}) = 0.((-1).1 - 2.0) - 2.(3.1 - 2.4) + 1.(3.0 - (-1).4) = 0 - 2.(-5) + 1.(4) = 14$</p>
              <p>Therefore, $det(\textbf{A}) = 14$</p>
            </td>
          </tr>
        </tbody>
      </table>
    </div>
    <br/>
    <div id="section-div-3">
      <p>References</p>
    </div>
    <div id="para-div">
      <p><a href="https://polarsparc.github.io/Mathematics/LinearAlgebra-2.html" target="_blank"><span class="bold">Introduction to Linear Algebra - Part 2</span></a></p>
      <p><a href="https://polarsparc.github.io/Mathematics/LinearAlgebra-1.html" target="_blank"><span class="bold">Introduction to Linear Algebra - Part 1</span></a></p>
    </div>
    <hr class="line-hr-3" />
    <div>
      <a id="footer-a-3" href="https://polarsparc.github.io/">&copy;&nbsp;PolarSPARC</a>
    </div>
  </body>
</html>
