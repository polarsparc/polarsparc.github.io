<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="content-type" content="application/xhtml+xml; charset=windows-1252" />
    <meta name="author" content="Bhaskar.S">
    <meta name="description" content="Univariate Gaussian Distribution Derivation">
    <meta name="subject" content="Univariate Gaussian Distribution Derivation">
    <meta name="keywords" content="math, mathematics, statistics">
    <meta name="robots" content="index, follow">
    <meta name="googlebot" content="index, follow">
    <title>Univariate Gaussian Distribution Derivation</title>
    <link href="../css/polarsparc-v2.4.css" type="text/css" rel="stylesheet" />
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script>
      MathJax = {
        tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
      };
    </script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.0.5/es5/tex-chtml.js"></script>
    <!-- script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script -->
  </head>
  <body>
    <br/>
    <table borber="0">
      <tr>
        <td valign="bottom"><span id="ps-home-3"></span></td>
        <td valign="bottom"><span id="home-a-3"><a id="home-a-3" href="https://polarsparc.github.io/">PolarSPARC</a></span></td>
      </tr>
    </table>
    <br/>
    <div id="title-div-3">
      <p>Univariate Gaussian Distribution Derivation</p>
    </div>
    <br />
    <table id="ad-table-3">
      <tbody>
        <tr>
          <td class="author-td">Bhaskar S</td>
          <td class="date-td">11/26/2024</td>
        </tr>
      </tbody>
    </table>
    <hr class="line-hr-3" />
    <div id="para-div">
      <p>The <span class="hi-yellow">Gaussian Distribution</span> (also known as the <span class="hi-vanila">Normal Distribution</span>)
        mimics most of the real-life, naturally occuring situations and hence is quite heavily used in the AI/ML space. For example,
        the Gaussian or Normal distribution is used to generate synthetic data or introduce noise in the data for training the AI/ML
        models.</p>
    </div>
    <div id="para-div">
      <p>From <span class="bold">Statistics</span>, we know that the Gaussian or Normal distribution is a continuous probability
        distribution with a symmetrical bell-shaped curve plot, such that new samples tend to cluster around the mean ($\mu$) that
        are within one, two, or three standard deviations ($\sigma$) from the mean ($\mu$).</p>
      <p>The following illustration depicts the Gaussian or Normal distribution:</p>
      <br/>
      <div id="img-outer-div-3">
        <img class="img-cls-3" alt="Normal Distribution" src="./images/gaussian-1.png" />
        <div class="img-cap-3">Figure.1</div>
      </div>
      <br/>
      <p>For example, given a typical family, assume the mean height of a female is about $65$ inches and that of a male is about
        $70$ inches. Given a standard deviation of $2$ inches, a newborn in that family, could grow to a height anywhere between
        $59$ inches to $76$ inches.</p>
    </div>
    <div id="para-div">
      <p>A <span class="hi-yellow">Probability Density Function</span> (or <span class="hi-vanila">PDF</span>) for a continuous
        random variable is a function that predicts the probability of a random sample falling within a specifc range, which is
        mathematically represented as $P(a \lt X \lt b) = \int_{a}^{b} f(x) dx$, where $f(x)$ is the PDF.</p>
      <p>For example, consider a sandwich shop offering a half-foot ($6$ inches) long subway sandwich. A randomly selected subway
        sandwich would be anwhere between $5.5$ inches and $6.5$ inches.</p>
    </div>
    <div id="para-div">
      <p>The equation for a Gaussian or Normal PDF with a mean $\mu$ and standard deviation $\sigma$ is defined as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$f(x,\mu,\sigma) = \Large{\frac{1}{\sigma\sqrt{2.\pi}}}$ $e^{-\frac{1}{2}.(\frac{x-\mu}{\sigma})^2}$.</p>
      <p>We will now derive the mathematical equation for the Gaussian or Normal PDF.</p>
    </div>
    <div id="para-div">
      <p>In order to derive the Gaussian or Normal PDF, let us consider a two-dimensional square dart board on the (x, y) coordinate
        system with the origin (0, 0) at the center (the bullseye) as shown in the illustration below:</p>
      <br/>
      <div id="img-outer-div-3">
        <img class="img-cls-3" alt="Dart Board" src="./images/gaussian-2.png" />
        <div class="img-cap-3">Figure.2</div>
      </div>
      <br/>
      <p>When one throws a dart many number of times, the majority of them will typically land around the center and probably inside
        the blue circle (in accordance with the Normal distribution) as shown in the illustration below:</p>
      <br/>
      <div id="img-outer-div-3">
        <img class="img-cls-3" alt="Dart Simulation" src="./images/gaussian-3.png" />
        <div class="img-cap-3">Figure.3</div>
      </div>
      <br/>
      <p>Consider the three regions $A$, $B$, and $C$ along the circumference of the blue circle as shown in the illustration below:</p>
      <br/>
      <div id="img-outer-div-3">
        <img class="img-cls-3" alt="Three Regions" src="./images/gaussian-4.png" />
        <div class="img-cap-3">Figure.4</div>
      </div>
      <br/>
      <p>For a dart to land on any point along the circumference of a given circle, the probability will be the same irrespective of
        the orientation. In other words, from the illustration in Figure.4 above, the probability is the same whether the dart falls
        in the region $A$, $B$, or $C$.</p>
      <p>This also implies that the probability of the dart landing on any coordinate point $(x, y)$ along the circumference of a
        given circle is <span class="underbold">NOT</span> influenced by either the $x$ axis or the $y$ axis. They are completely
        independent of each other.</p>
    </div>
    <div id="para-div">
      <p>Assume the throwing of the dart to land in the infinitesimally small red square region $A$ of length $\Delta{x}$ and width
        $\Delta{y}$ with area $dA = \Delta{x}.\Delta{y}$.</p>
      <p>If $r$ is the distance from the origin to the red square region $A$ and if $p(r)$ is the PDF, then the probability of the
        dart landing in the red square region $A$ is given as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$p(r).dA$ ..... $\color{red}(1)$</p>
      <p>Earlier on, we indicated that the position of $x$ is independent of $y$. If we consider a different PDF $f$ in the $(x, y)$
        coordinate system, then the probability of the dart landing in the red square region $A$ is given as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$f(x).f(y).dA$ ..... $\color{red}(2)$</p>
      <p>The equations $\color{red}(1)$ and $\color{red}(2)$ both are the probability of a dart landing in the red square region $A$.</p>
      <p>Therefore, we can arrive at the following equation:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$p(r).dA = f(x).f(y).dA$</p>
      <p>Simplifying the above equation, we get:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$p(r) = f(x).f(y)$ ..... $\color{red}(3)$</p>
    </div>
    <div id="para-div">
      <p>Now, considering that the dart lands in the red square region $A$, which is $r$ units away from the origin and at an angle
        $\theta$ from the $x$ axis as shown in the illustration below:</p>
      <br/>
      <div id="img-outer-div-3">
        <img class="img-cls-3" alt="Red Region" src="./images/gaussian-5.png" />
        <div class="img-cap-3">Figure.5</div>
      </div>
      <br/>
      <p>Differentiating the equation (3) with respect to $\theta$ gives us the following equation:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\frac{dp(r)}{d\theta}}$ $= \Large{\frac{df(x)}{d\theta}}$ $.f(y) + \Large{\frac{df(y)}{d
        \theta}}$ $.f(x)$ ..... $\color{red}(4)$</p>
      <p>The equation $\color{red}(4)$ can be re-written as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\frac{dp(r)}{d\theta}}$ $= \Large{\frac{df(x)}{dx}}$ $.\Large{\frac{dx}{d\theta}}$ $.f(y)
        + \Large{\frac{df(y)}{dy}}$ $.\Large{\frac{dy}{d\theta}}$ $.f(x)$ ..... $\color{red}(5)$</p>
    </div>
    <div id="para-div">
      <p>Since the PDF $p(r)$ is independent of where the dart lands on any point along the circumference of a given circle, it is
        independent of the angle of rotation $\theta$.</p>
      <p>Therefore, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\frac{dp(r)}{d\theta}}$ $= 0$ ..... $\color{red}(6)$</p>
      <p>From the equations $\color{red}(5)$ and $\color{red}(6)$, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\frac{df(x)}{dx}}$ $.\Large{\frac{dx}{d\theta}}$ $.f(y) + \Large{\frac{df(y)}{dy}}$ $.
        \Large{\frac{dy}{d\theta}}$ $.f(x)$ $= 0$ ..... $\color{red}(7)$</p>
    </div>
    <div id="para-div">
      <p>From Trigonometry, using the information from Figure.5 we get $x = r.cos(\theta)$.</p>
      <p>By differentiating the above equation, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\frac{dx}{d\theta}}$ $= -r.sin(\theta)$ ..... $\color{red}(8)$</p>
      <p>Simarly, using the information from Figure.5 we get $y = r.sin(\theta)$.</p>
      <p>By differentiating the above equation, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\frac{dy}{d\theta}}$ $= r.cos(\theta)$ ..... $\color{red}(9)$</p>
    </div>
    <div id="para-div">
      <p>Plugging equations $\color{red}(8)$ and $\color{red}(9)$ into equation $\color{red}(7)$, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\frac{df(x)}{dx}}$ $(-r.sin(\theta)).f(y) + \Large{\frac{df(y)}{dy}}$ $(r.cos(\theta)).
        f(x)$ $= 0$ ..... $\color{red}(10)$</p>
      <p>Given $x = r.cos(\theta)$ and $y = r.sin(\theta)$, equation $\color{red}(10)$ can be re-written as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\frac{df(x)}{dx}}$ $(-y).f(y) + \Large{\frac{df(y)}{dy}}$ $(x).f(x)$ $= 0$ ..... $\color
        {red}(11)$</p>
    </div>
    <div id="para-div">
      <p>The derivative of the PDF $f(x)$ is represented as $\Large{\frac{df(x)}{dx}}$, which can also be represented as $f'(x)$.</p>
      <p>Therefore equation $\color{red}(11)$ can be re-written as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$f'(x).(-y).f(y) + f'(y).(x).f(x)$ $= 0$</p>
      <p>Simplifying, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$x.f(x).f'(y) - y.f'(x).f(y) = 0$</p>
      <p>Re-arranging, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$x.f(x).f'(y) = y.f'(x).f(y)$ ..... $\color{red}(12)$</p>
      <p>Re-arranging the terms in equation $\color{red}(12)$, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\frac{f'(x)}{x.f(x)}}$ $= \Large{\frac{f'(y)}{y.f(y)}}$ ..... $\color{red}(13)$</p>
    </div>
    <div id="para-div">
      <p>We know that the Gaussion or Normal PDF is an exponential distribution function given that it has a bell-shaped curve. From
        Calculus, we know that the ratio of a function $f(x)$ to its derivative $f'(x)$ for an exponential function is a constant.</p>
      <p>For example, consider the following exponential function:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$f(x) = a^x$</p>
      <p>Differentiating the above function $f(x)$, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$f'(x) = log_e{a}.a^x$</p>
      <p>Re-writing the above equation, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$f'(x) = log_e{a}.f(x)$</p>
      <p>In other words:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\frac{f'(x)}{f(x)}}$ $= log_e{a}$</p>
      <p>Note that $log_e{a}$ is a constant.</p>
    </div>
    <div id="para-div">
      <p>If we use $k$ to represent a constant, then equation $\color{red}(13)$ can be written as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\frac{f'(x)}{x.f(x)}}$ $= \Large{\frac{f'(y)}{y.f(y)}}$ $= k$ ..... $\color{red}(14)$</p>
      <p>As indicated earlier, both $x$ and $y$ are independent and from equation $\color{red}(14)$, we observe that both $x$ and
        $y$ differential equations yield the same result of the constant $k$.</p>
      <p>So, let us go with $x$ as shown below:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\frac{f'(x)}{x.f(x)}}$ $= k$</p>
      <p>Re-arranging the aboive equation, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\frac{f'(x)}{f(x)}}$ $= k.x$ ..... $\color{red}(15)$</p>
    </div>
    <div id="para-div">
      <p>Integrating equation $\color{red}(15)$ on both sides, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$log_e{f(x)} = \Large{\frac{k.x^2}{2}}$ $+ c$</p>
      <p>where $c$ is another constant from the integration.</p>
      <p>Applying logarithm on both sides of the above equation, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$f(x) = e^{\Large{\frac{k}{2}}.\normalsize{x^2+c}}$</p>
      <p>The above equation can be re-written as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$f(x) = e^{\Large{\frac{k}{2}}.\normalsize{x^2}}.e^c$</p>
      <p>Given that $e^c$ is some constant, say, $A$, then we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$f(x) = A.e^{\Large{\frac{k}{2}}.\normalsize{x^2}}$ ..... $\color{red}(16)$</p>
      <p>As we can infer from equation $\color{red}(16)$ above, $f(x)$ is an exponential distribution function and its plot is as
        shown in the illustration below (with $A = 1$ and $k = 1$):</p>
      <br/>
      <div id="img-outer-div-3">
        <img class="img-cls-3" alt="Exponential Plot" src="./images/gaussian-6.png" />
        <div class="img-cap-3">Figure.6</div>
      </div>
      <br/>
      <p>However, the Gaussian or Normal distribution plot is flipped (a beel-curve).</p>
      <p>To fix that, we need to introduce a negative sign ($-$) in the exponent of equation $\color{red}(16)$ above, so we get
        the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$f(x) = A.e^{-\Large{\frac{k}{2}}.\normalsize{x^2}}$ ..... $\color{red}(17)$</p>
      <p>The following illustration depicts the plot of the equation $\color{red}(17)$ (with $A = 1$ and $k = 1$):</p>
      <br/>
      <div id="img-outer-div-3">
        <img class="img-cls-3" alt="Gaussian Plot" src="./images/gaussian-7.png" />
        <div class="img-cap-3">Figure.7</div>
      </div>
      <br/>
      <p><span class="bold">YIPPE</span> - we have now figured the foundational exponential function that represents the Gaussian
        (or Normal) PDF. We still need to determine the values for the constants $A$ and $k$.</p>
    </div>
    <div id="para-div">
      <p>Given that we know the total area under a curve for a PDF has to be equal to $1$, we can rewrite equation $\color{red}(17)$
        as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\int_{\small{-\infty}}^{\small{\infty}}}$ $A.e^{-\Large{\frac{k}{2}}.\normalsize{x^2}} dx
        = 1$</p>
      <p>The above equation can be re-written as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\int_{\small{-\infty}}^{\small{\infty}}}$ $e^{-\Large{\frac{k}{2}}.\normalsize{x^2}} dx =
        \Large{\frac{1}{A}}$</p>
      <p>Given that the Gaussian or Normal PDF is symmetrical bell-shaped curve, we can rewrite the above equation as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$2.\Large{\int_{\small{0}}^{\small{\infty}}}$ $e^{-\Large{\frac{k}{2}}.\normalsize{x^2}} dx =
        \Large{\frac{1}{A}}$</p>
      <p>Re-arranging the above equation, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\int_{\small{0}}^{\small{\infty}}}$ $e^{-\Large{\frac{k}{2}}.\normalsize{x^2}} dx =
        \Large{\frac{1}{2.A}}$ ..... $\color{red}(18)$</p>
    </div>
    <div id="para-div">
      <p>The above equation is not easy to integrate, so we will play a little bit of a trick here.</p>
      <p>Squaring on both sides of the above equation, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{(\int_{\small{0}}^{\small{\infty}}}$ $e^{-\Large{\frac{k}{2}}.\normalsize{x^2}} dx \Large
        {)} \Large{(\int_{\small{0}}^{\small{\infty}}}$ $e^{-\Large{\frac{k}{2}}.\normalsize{x^2}} dx \Large{)} = \Large{\frac{1}
        {4.A^2}}$</p>
      <p>As indicated earlier, both $x$ and $y$ are independent and as observed from equation $\color{red}(14)$, both $x$ and $y$
        variables yield the similar results.</p>
      <p>Hence we can rewrite the above equation as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{(\int_{\small{0}}^{\small{\infty}}}$ $e^{-\Large{\frac{k}{2}}.\normalsize{x^2}} dx \Large
        {)} \Large{(\int_{\small{0}}^{\small{\infty}}}$ $e^{-\Large{\frac{k}{2}}.\normalsize{y^2}} dy \Large{)} = \Large{\frac{1}
        {4.A^2}}$</p>
      <p>Rewriting the above equation, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\int_{\small{0}}^{\small{\infty}}}$ $\Large{\int_{\small{0}}^{\small{\infty}}}$ $e^{-
        \Large{\frac{k}{2}}.\normalsize{x^2}}$.$e^{-\Large{\frac{k}{2}}.\normalsize{y^2}} \normalsize{dy\:dx} = \Large{\frac{1}
        {4.A^2}}$</p>
      <p>Simplifying the above equation, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\int_{\small{0}}^{\small{\infty}}}$ $\Large{\int_{\small{0}}^{\small{\infty}}}$ $e^{-
        \Large{\frac{k}{2}}.\normalsize{(x^2+y^2)}} \normalsize{dy\:dx} = \Large{\frac{1}{4.A^2}}$ ..... $\color{red}(19)$</p>
    </div>
    <div id="para-div">
      <p>Integrating equation $\color{red}(19)$, which is in the $(x, y)$ coordinate system will be very complicated and we could
        make that easier by moving to the polar coordinate system.</p>
      <p>When one transitions from a $(x, y)$ coordinate system to a polar coordinate system, the red square region $A$ becomes
        more like a segment with an arc, where the length is $\Delta r$ and the width is $r.\Delta \theta$ (because of the arc).</p>
      <p>Also, in the $(x, y)$ coordinate system, we are integrating both over the range $(0, \infty)$. In the polar coordinate
        system, we will have the radius $r$ in the range $(0, \infty)$ and the angle $\theta$ in the range $(0, \Large{\frac{\pi}
        {2}})$.</p>
      <p>With that, we can rewrite equation $\color{red}(19)$ into the polar coordinate system to get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\int_{\small{0}}^{\normalsize{\frac{\pi}{2}}}}$ $\Large{\int_{\small{0}}^{\small{\infty}}}$
        $e^{-\Large{\frac{k}{2}}.\normalsize{r^2}} \normalsize{.r\:dr\:d{\theta}} = \Large{\frac{1}{4.A^2}}$ ..... $\color{red}(20)$</p>
    </div>
    <div id="para-div">
      <p>Let us try to simplify equation $\color{red}(20)$ using the following substitution:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$u = -\Large{\frac{k}{2}}.\normalsize{r^2}$</p>
      <p>Differentiating the above equation on both sides, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$du = -k.r\:dr$</p>
      <p>Re-arranging, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$r\:dr = - \Large{\frac{1}{k}}\:\normalsize{du}$</p>
      <p>Note that the range of $u$ will be $(0, -\infty)$, since the $u = 0$ when $r = 0$ and $u = -\infty$ when $r = \infty$.</p>
    </div>
    <div id="para-div">
      <p>Now to simplify equation $\color{red}(20)$ using $u$, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$-\Large{\frac{1}{k}}$ $\Large{\int_{\small{0}}^{\normalsize{\frac{\pi}{2}}}}$ $\Large{\int_{\small
        {0}}^{\small{-\infty}}}$ $e^{u} \normalsize{\:du\:d{\theta}} = \Large{\frac{1}{4.A^2}}$ ..... $\color{red}(21)$</p>
      <p>Let us focus on the following integral term:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\int_{\small {0}}^{\small{-\infty}}}$ $e^{u} \normalsize{\:du}$</p>
      <p>If $g(u) = e^u$, then we know $g'(u) = e^u$ too. Therefore, the above equation can be re-written as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\int_{\small {0}}^{\small{-\infty}}}$ $g'(u) \normalsize{\:du} = g(\infty) - g(0) = e^{
        \infty} - e^0 = 0 - 1 = -1$ ..... $\color{red}(22)$</p>
      <p>Using the results from equation $\color{red}(22)$ into equation $\color{red}(21)$, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$-\Large{\frac{1}{k}}$ $\Large{\int_{\small{0}}^{\normalsize{\frac{\pi}{2}}}}$ $(-1)\:d{\theta} =
        \Large{\frac{1}{4.A^2}}$ ..... $\color{red}(23)$</p>
      <p>The equation $\color{red}(23)$ then reduces to the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\frac{\pi}{2.k}}$ $= \Large{\frac{1}{4.A^2}}$</p>
      <p>Simplifying the above equation, we get the value of $A$ as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$A = \Large{\sqrt{\frac{k}{2.\pi}}}$ ..... $\color{red}(24)$</p>
      <p>Substituiting equation $\color{red}(24)$ into equation $\color{red}(17)$, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$f(x) = \Large{\sqrt{\frac{k}{2.\pi}}}$ $.e^{-\Large{\frac{k}{2}}.\normalsize{x^2}}$ ..... $\color
        {red}(25)$</p>
      <p><span class="bold">WALLA</span> - the only task now remaining is to find the value for $k$ !!!</p>
    </div>
    <div id="para-div">
      <p>Given that the Gaussian or Normal PDF is about the continuous random variable $x$, the next items to discuss would be about
        the mean ($\mu$) and the standard deviation ($\sigma$).</p>
      <p>The mean ($\mu$) for a PDF is defined as the cumulation of all the expected values ($x.f(x)$) in a given range $(-\infty,
        \infty)$. For Gaussian or Normal PDF, it is defined as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\int_{\small {-\infty}}^{\small{\infty}}}$ $\:x.f(x)\:dx$ ..... $\color{red}(26)$</p>
      <p>Plugging in equation $\color{red}(25)$ into equation $\color{red}(26)$, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\mu = \Large{\sqrt{\frac{k}{2.\pi}}}$ $\Large{\int_{\small {-\infty}}^{\small{\infty}}}$ $x.e^{-
        \Large{\frac{k}{2}}.\normalsize{x^2}}\:dx$ ..... $\color{red}(27)$</p>
      <p>Equation $\color{red}(27)$ is an odd function since we have both the odd term $x$ and the even term $x^2$ and as a result
        every value of $x$ in the range $(-\infty, 0)$ will cancel out with every value of $x$ in the range $(0, \infty)$ due to
        the symmetrical nature of the Gaussian or Normal PDF.</p>
      <p>The following illustration depicts this situation:</p>
      <br/>
      <div id="img-outer-div-3">
        <img class="img-cls-3" alt="Symmetric Plot" src="./images/gaussian-8.png" />
        <div class="img-cap-3">Figure.8</div>
      </div>
      <br/>
      <p>The cummulative expected value in the region <span class="hi-green">X</span> cancel out the cummulative expected value in
        the region <span class="hi-red">-X</span>.</p>
      <p>Hence, the mean ($\mu$) of the Gaussian or Normal PDF is zero ($0$).</p>
    </div>
    <div id="para-div">
      <p>Moving on to the variance ($\sigma^{2}$) for the Gaussian or Normal PDF.</p>
      <p>The variance ($\sigma^{2}$) for a PDF is defined as the cumulation of all the expected values [$(x-\mu)^2.f(x)$] in a given
        range $(-\infty, \infty)$. For Gaussian or Normal PDF, it is defined as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\int_{\small {-\infty}}^{\small{\infty}}}$ $\:(x-\mu)^2.f(x)\:dx$</p>
      <p>Given that the mean ($\mu$) is equal to $0$, we can rewrite the above equation as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\int_{\small {-\infty}}^{\small{\infty}}}$ $\:x^2.f(x)\:dx$ ..... $\color{red}(28)$</p>
      <p>Plugging in equation $\color{red}(25)$ into equation $\color{red}(28)$, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\sigma^{2} = \Large{\sqrt{\frac{k}{2.\pi}}}$ $\Large{\int_{\small {-\infty}}^{\small{\infty}}}$
        $x^2.e^{-\Large{\frac{k}{2}}.\normalsize{x^2}}\:dx$</p>
      <p>We know that the Gaussian or Normal PDF is symmetrical curve, so we can rewrite the above equation as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\sigma^{2} = 2.\Large{\sqrt{\frac{k}{2.\pi}}}$ $\Large{\int_{\small {0}}^{\small{\infty}}}$
        $x^2.e^{-\Large{\frac{k}{2}}.\normalsize{x^2}}\:dx$</p>
      <p>We can rewrite the above equation as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\sigma^{2} = 2.\Large{\sqrt{\frac{k}{2.\pi}}}$ $\Large{\int_{\small {0}}^{\small{\infty}}}$
        $x.x.e^{-\Large{\frac{k}{2}}.\normalsize{x^2}}\:dx$ ..... $\color{red}(29)$</p>
    </div>
    <div id="para-div">
      <p>To solve the equation $\color{red}(29)$, we will use the technique called <span class="bold">Integration by Parts</span>,
        which uses the following formula:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\int}$ $\:u\:dv = u.v\:-$ $\Large{\int}$ $\:v\:du$ ..... $\color{red}(30)$</p>
      <p>Let us assign $u$ the following value:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$u = x$..... $\color{red}(31)$</p>
      <p>By differentiating both sides of equation $\color{red}(31)$, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$du = dx$ ..... $\color{red}(32)$</p>
      <p>Similarly, let us assign $dv$ the following value:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$dv = x.e^{-\Large{\frac{k}{2}}.\normalsize{x^2}}$..... $\color{red}(33)$</p>
      <p>By integrating both sidesof the equation $\color{red}(33)$, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$v = -\Large{\frac{1}{k}}$ $e^{-\Large{\frac{k}{2}}.\normalsize{x^2}}$ ..... $\color{red}(34)$</p>
    </div>
    <div id="para-div">
      <p>With $u$ and $dv$ defined as in equations $\color{red}(31)$ and $\color{red}(33)$, the integration part of equation $\color
        {red}(29)$ is in the form of equation $\color{red}(30)$ and can be re-written as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\sigma^{2} = 2.{\sqrt{\frac{k}{2.\pi}}}$ $\Large{[}$ $-\Large{\frac{x}{k}}$ $.e^{-\Large{\frac{k}
        {2}}.\normalsize{x^2}}$ $\Large{\rvert_{\small0}^{\small\infty}}$ $+ \Large{\frac{1}{k}}$ $\Large{\int_{\small {0}}^{\small
        {\infty}}}$ $e^{-\Large{\frac{k}{2}}.\normalsize{x^2}}\:dx$ $\Large{]}$ ..... $\color{red}(35)$</p>
      <p>Note that the symbol $\Large{\rvert_{\small0}^{\small\infty}}$ is referred to as the integral <span class="bold">Evaluation
        Bar</span> at the two limits $0$ and $\infty$.</p>
      <p>The first term $-\Large{\frac{x}{k}}$ $.e^{-\Large{\frac{k}{2}}.\normalsize{x^2}}$ $\Large{\rvert_{\small0}^{\small\infty}}$
        of the equation $\color{red}(35)$ basically evaluates to a zero ($0$) because for $x = 0$, the term is $0$ and for $x = \infty$,
        $e^{\infty}$ is $0$. Hence, the first term drops off and the equation simply becomes the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\sigma^{2} = 2.{\sqrt{\frac{k}{2.\pi}}}$ $\Large{[}$ $\Large{\frac{1}{k}}$ $\Large{\int_{\small {0}}
        ^{\small{\infty}}}$ $e^{-\Large{\frac{k}{2}}.\normalsize{x^2}}\:dx$ $\Large{]}$ ..... $\color{red}(36)$</p>
      <p>From equation $\color{red}(18)$, we know the integral term of the equation $\color{red}(36)$ equals $\Large{\frac{1}{2.A}}$.</p>
      <p>Therefore, the equation $\color{red}(36)$ can be written as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\sigma^{2} = 2.{\sqrt{\frac{k}{2.\pi}}}$ $.\Large{\frac{1}{k}}$ $.\Large{\frac{1}{2.A}}$ .....
        $\color{red}(37)$</p>
      <p>From equation $\color{red}(24)$, we know the value for $A$.</p>
      <p>Therefore the equation $\color{red}(37)$ can be written as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\sigma^{2} = 2.{\sqrt{\frac{k}{2.\pi}}}$ $.\Large{\frac{1}{2.k}}$ $.{\sqrt{\frac{2.\pi}{k}}}$</p>
      <p>Simplifying the above equation, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$k = \Large{\frac{1}{\sigma^2}}$ ..... $\color{red}(38)$</p>
      <p>Substituiting equation $\color{red}(38)$ into equation $\color{red}(25)$, we get the following:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$f(x) = \Large{\frac{1}{\sigma\sqrt{2.\pi}}}$ $e^{-\frac{1}{2}.(\frac{x}{\sigma})^2}$.</p>
      <p>Given that the mean ($\mu$) is zero ($0$) in our case for Gaussian or Normal PDF, one can rewrite the above equation as
        follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$f(x) = \Large{\frac{1}{\sigma\sqrt{2.\pi}}}$ $e^{-\frac{1}{2}.(\frac{x-\mu}{\sigma})^2}$.</p>
      <p><span class="bold">BINGO</span> !!! We have successfully derived the equation for the Gaussian or Normal PDF !!!</p>
    </div>
    <br/>
    <div id="section-div-3">
      <p>References</p>
    </div>
    <div id="para-div">
      <p><a href="https://polarsparc.github.io/Mathematics/Statistics-2.html" target="_blank"><span class="bold">Introduction to
        Statistics - Part 2</span></a></p>
      <p><a href="https://polarsparc.github.io/Mathematics/Calculus-2.html" target="_blank"><span class="bold">Introduction to
        Calculus - Part 2</span></a></p>
    </div>
    <hr class="line-hr-3" />
    <div>
      <a id="footer-a-3" href="https://polarsparc.github.io/">&copy;&nbsp;PolarSPARC</a>
    </div>
  </body>
</html>
