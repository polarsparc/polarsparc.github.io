<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
  <head>
    <meta http-equiv="content-type" content="application/xhtml+xml; charset=windows-1252" />
    <meta name="author" content="Bhaskar.S">
    <meta name="description" content="AWS Application Integration - Quick Notes">
    <meta name="subject" content="AWS Application Integration - Quick Notes">
    <meta name="keywords" content="aws, cloud">
    <meta name="robots" content="index, follow">
    <meta name="googlebot" content="index, follow">
    <title>AWS Application Integration - Quick Notes</title>
    <link href="../css/polarsparc-v2.4.css" type="text/css" rel="stylesheet" />
  </head>
  <body>
    <br/>
    <table borber="0">
      <tr>
        <td valign="bottom"><span id="ps-home"></span></td>
        <td valign="bottom"><span id="home-a"><a id="home-a" href="https://polarsparc.github.io/">PolarSPARC</a></span></td>
      </tr>
    </table>
    <br/>
    <div id="title-div">
      <p>AWS Application Integration - Quick Notes</p>
    </div>
    <br />
    <table id="ad-table">
      <tbody>
        <tr>
          <td class="author-td">Bhaskar S</td>
          <td class="date-td">01/05/2024</td>
        </tr>
      </tbody>
    </table>
    <hr class="line-hr" />
    <br/>
    <div id="section-div">
      <p>Amazon MQ</p>
    </div>
    <div id="para-div">
      <p>The following is the summary of the various features/capabilities of Amazon MQ:</p>
      <ul id="blue-sqr-ul">
        <li><p>Is a managed message broker service that can be used to migrate an existing message broker to the cloud</p></li>
        <li><p>Provides compatibility with many popular message brokers such as the <span class="bold">ActiveMQ</span> and the <span
          class="bold">RabbitMQ</span></p></li>
        <li><p>Facilitates the communication between applications and components written in different programming languages</p></li>
        <li><p>Allows for lift-and-shift of existing on-prem applications using message brokers without the need to manage, operate,
          or maintain their own messaging system</p></li>
        <li><p>For high availability within a Region, one will have to deploy an active instance in one availabilty zone and a then
          a standby instance in another availabilty zone backed by Elastic File System (EFS)</p></li>
      </ul>
    </div>
    <div id="section-div">
      <p>Amazon Simple Queue Service (SQS)</p>
    </div>
    <div id="para-div">
      <p>The following is the summary of the various features/capabilities of Amazon SQS:</p>
      <ul id="blue-sqr-ul">
        <li><p>Offers a secure, durable, and available hosted queue that lets one integrate and decouple distributed software systems
          and components</p></li>
        <li><p>A <span class="hi-vanila">Queue</span> holds messages (data)</p></li>
        <li><p><span class="hi-vanila">Producers</span> send messages to one or more queues</p></li>
        <li><p><span class="hi-vanila">Consumers</span> poll (pull) for messages from one or more queues</p></li>
        <li><p>There can be only <span class="underbold">ONE</span> consumer per queue</p></li>
        <li><p>A consumer may received upto <span class="hi-red">10</span> messages at a time from a poll</p></li>
        <li><p>Messages are retained until processed and <span class="underbold">EXPLICITLY</span> deleted by consumers</p></li>
        <li><p>Support for unlimited number of messages in a queue</p></li>
        <li><p>Unlimited throughput</p></li>
        <li><p>Low latency to publish or consume (less than 10 ms)</p></li>
        <li><p>The default retention period for messages is <span class="hi-red">4</span> days (to a maximum of <span class="hi-red">
          14</span> days)</p></li>
        <li><p>Maximum message size of <span class="hi-red">256</span> KB</p></li>
        <li><p>At least once delivery semantics (meaning a consumer can see duplicates)</p></li>
        <li><p>No message ordering guarantees (best effort ordering)</p></li>
        <li><p>One can monitor the CloudWatch metric for queue length and dispatch an CloudWatch Alarm if a threshold is breached</p></li>
        <li><p>Pay only based on the usage</p></li>
        <li><p>For encryption in-flight, one can use the HTTPS API</p></li>
        <li><p>For encryption at-rest, it is enabled by default and uses AWS created/managed key</p></li>
        <li><p>For controlling access to SQS service, one can leverage either the IAM Policies or the SQS Access Policies (managed
          in SQS)</p></li>
        <li><p>SQS Access Policies allow for cross-account access</p></li>
        <li>
          <p>Message Visibility Timeout</p>
          <ul id="blue-arw-ul">
            <li><p>When a message is pulled by a consumer, that specific message becomes invisible to other consumers</p></li>
            <li><p>The visibility timeout is what controls the invisible period which is <span class="hi-red">30</span> secs by
              default</p></li>
            <li><p>Before the visibility timeout elapses, the consumer must process and delete the message, else the next consumer
              will see the same message again and result in duplicate processing</p></li>
            <li><p>If a consumer processing a message knows it needs more time to process the message, it can prevent duplicate
              processing by invoking the <span class="hi-green">ChangeMessageVisibility</span> API</p></li>
          </ul>
        </li>
        <li>
          <p>Long Polling</p>
          <ul id="blue-arw-ul">
            <li><p>When a consumer requests for messages from a queue by polling, it can optionally request to <span class="underbold">
              WAIT</span> for messages to arrive if there are <span class="underbold">NONE</span> in the queue</p></li>
            <li><p>Reduces the number of API calls made to SQS while increasing the efficiency of the application</p></li>
            <li><p>The poll wait timeout can be between <span class="hi-red">1</span> sec and <span class="hi-red">20</span> secs</span></p></li>
          </ul>
        </li>
        <li><p>The default queue is called a <span class="hi-vanila">Standard Queue</span></p></li>
        <li>
          <p>FIFO Queue</p>
          <ul id="blue-arw-ul">
            <li><p>First In First Out (FIFO) queue that guarantees the ordering of messages</p></li>
            <li><p>Ordering by <span class="hi-vanila">Message Group ID</span> (all messages in a group are ordered)</span></p></li>
            <li><p>Limited throughput of <span class="hi-red">300</span> messages per sec without batching AND <span class="hi-red">
              3000</span> messages per sec WITH batching of <span class="hi-red">10</span> messages</p></li>
            <li><p>Exactly once delivery semantics (meaning a consumer will NOT see duplicates using <span class="hi-vanila">Message
              Deduplication ID</span>)</p></li>
          </ul>
        </li>
        <li><p>A <span class="hi-vanila">Dead Letter Queue</span> is for error handling. If a consumer cannot process a message due
          to some error, the message is not deleted and will be received again by the consumer. After receiving the same message a
          certain number of times, the message can be moved to this queue</p></li>
        <li><p>Useful when we need an durable and relaible event-driven solution that guarantees the processing of all the messages</p></li>
      </ul>
    </div>
    <div id="section-div">
      <p>Amazon Simple Notification Service (SNS)</p>
    </div>
    <div id="para-div">
      <p>The following is the summary of the various features/capabilities of Amazon SNS:</p>
      <ul id="blue-sqr-ul">
        <li><p>Is a managed service that provides a <span class="underbold">PUSH</span> based message delivery from publishers to
          subscribers</p></li>
        <li><p>Publishers communicate asynchronously with subscribers by sending messages to a <span class="hi-vanila">Topic</span></p></li>
        <li><p>A topic is a logical access point that acts as a communication channel</p></li>
        <li><p>There can be many subscribers listening on a topic</p></li>
        <li><p>Each subscriber of a topic will receive all the messages</p></li>
        <li><p>When a publisher sends a message to a topic, the message is pushed to all the subscribers on that topic</p></li>
        <li><p>There can be up to <span class="hi-red">12.5</span> million subscribers per topic</p></li>
        <li><p>There can be up to <span class="hi-red">100</span> K topics per account</p></li>
        <li><p>One can subscribe to a topic and receive published messages using a supported endpoint type, such as SQS, Lambda,
          Kinesis Data Firehose (<span class="underbold">NOT</span> Kinesis Data Streams), HTTP/HTTPS, email, mobile text messages
          (SMS), etc</p></li>
        <li><p>Can receive messages from various AWS services, such as CloudWatch Alarm, S3 Bucket, Lambda, DynamoDB, etc</p></li>
        <li><p>A subscriber can do message filtering on a topic using a JSON based <span class="hi-vanila">Filter Policy</span> that
          defines the filtering criteria for the message</p></li>
        <li><p>For encryption in-flight, one can use the HTTPS API</p></li>
        <li><p>For encryption at-rest, it is enabled by default and uses AWS created/managed key</p></li>
        <li><p>For controlling access to SNS service, one can leverage either the IAM Policies or the SNS Access Policies (managed
          in SNS)</p></li>
        <li><p>The published messages are <span class="underbold">NOT</span> persisted in the topic</p></li>
        <li><p>Integrates with SQS for <span class="underbold">FAN-OUT</span> architecture pattern with no data loss</p></li>
        <li><p>Cross-region message delivery possible from SNS in one Region to SQS in another Region</p></li>
        <li>
          <p>FIFO Topic</p>
          <ul id="blue-arw-ul">
            <li><p>First In First Out (FIFO) topic that guarantees the ordering of messages</p></li>
            <li><p>Ordering by <span class="hi-vanila">Message Group ID</span> (all messages in a group are ordered)</span></p></li>
            <li><p>Exactly once delivery semantics (using <span class="hi-vanila">Message Deduplication ID</span>)</p></li>
            <li><p>Limited throughput of <span class="hi-red">300</span> messages per sec</p></li>
          </ul>
        </li>
        <li><p>Useful when we need an event-driven solution that can deliver messages asynchronously to many consumers without any
          strong delivery guarantees</p></li>
      </ul>
    </div>
    <div id="section-div">
      <p>Amazon Step Functions</p>
    </div>
    <div id="para-div">
      <p>The following is the summary of the various features/capabilities of Step Functions:</p>
      <ul id="blue-sqr-ul">
        <li><p>Is a serverless orchestration service that lets one integrate with Lambda functions and other AWS services to build
          business-critical workflow applications</p></li>
        <li><p>A <span class="hi-vanila">Workflow</span> is nothing more than a state machine, where each step in a workflow is
          called a <span class="hi-vanila">State</span></p></li>
        <li><p>A <span class="hi-vanila">Task</span> is a state that represents a unit of work that a Lambda function or a AWS
          service performs</p></li>
        <li><p>Allows one to build a distributed workflow application as a series of event-driven steps and see the visual workflow
          via the graphical console</p></li>
        <li><p>Workflow has features for - sequencial tasks, parallel tasks, branching, conditions, error handling, timeout, human
          approval, etc</p></li>
        <li><p>Can integrate with many AWS services (EC2, ECS, API Gateway, SQS, etc) as well as on-prem services</p></li>
        <li><p>An <span class="hi-vanila">Execution</span> is an instance of a running workflow to perform the series of tasks</p></li>
        <li><p>There are two workflow types - <span class="hi-vanila">Standard Workflows</span> AND <span class="hi-vanila">Express
          Workflows</span></p></li>
        <li>
          <p>Standard Workflows</p>
          <ul id="blue-arw-ul">
            <li><p>At-most-once workflow execution with retry and can run for up to one year</p></li>
            <li><p>Used for long-running, auditable workflows which show execution history and visual debugging</p></li>
            <li><p>Can execute up to <span class="hi-red">2000</span> per sec</p></li>
            <li><p>Can have up to <span class="hi-red">4000</span> state transitions</p></li>
            <li><p>Cost per state transition</p></li>
          </ul>
        </li>
        <li>
          <p>Express Workflows</p>
          <ul id="blue-arw-ul">
            <li><p>At-least-once workflow execution and can run for up to 5 mins</p></li>
            <li><p>Used for high-event rate workloads such as streaming data processing</p></li>
            <li><p>Can execute up to <span class="hi-red">100000</span> per sec</p></li>
            <li><p>Can have <span class="underbold">UNLIMITED</span> state transitions</p></li>
            <li><p>Cost per state transition and duration of execution</p></li>
            <li><p>Sends execution history to CloudWatch</p></li>
          </ul>
        </li>
        <li><p>There are two types of Express Workflows - <span class="hi-vanila">Asynchronous</span> AND <span class="hi-vanila">
          Synchronous</span></p></li>
        <li>
          <p>Asynchronous Express Workflows</p>
          <ul id="blue-arw-ul">
            <li><p>Return confirmation once the workflow starts and does not wait for the workflow to complete</p></li>
            <li><p>One must poll the workflow to get the result</p></li>
            <li><p>Triggered by an event or by calling the StartExecution API</p></li>
          </ul>
        </li>
        <li>
          <p>Synchronous Express Workflows</p>
          <ul id="blue-arw-ul">
            <li><p>Start the workflow and wait for the completion and the returned result</p></li>
            <li><p>Invoked from the API Gateway, Lambda function, or by calling the StartSyncExecution API</p></li>
          </ul>
        </li>
      </ul>
    </div>
    <div id="section-div">
      <p>Amazon EventBridge</p>
    </div>
    <div id="para-div">
      <p>The following is the summary of the various features/capabilities of EventBridge:</p>
      <ul id="blue-sqr-ul">
        <li><p>Previously was referred to as <span class="hi-vanila">CloudWatch Events</span></p></li>
        <li><p>Is a serverless event bus that routes events to connect application components together, making it easier for one to
          build scalable event-driven applications</p></li>
        <li><p>An <span class="hi-vanila">Event Bus</span> is a router that receive events from Event Sources and delivers them to
          zero or more Event Targets (Lambda functions, SNS, Kinesis Data Stream, etc)</p></li>
        <li><p>One can create custom a event bus for sending events from services and applications from an AWS account</p></li>
        <li><p>Event Sources can be AWS services, custom applications, or third-party SaaS applications</p></li>
        <li><p>State changes in the event sources are sent as events to the event bus, which are processed by <span class="hi-vanila">
          Rules</span>, before routing them to specific event targets</p></li>
        <li><p>Provides simple and consistent ways to ingest, filter, transform, and deliver events which allows one to build and
          test applications quickly</p></li>
        <li><p>Are well-suited for routing events from many sources to many targets, with optional transformation of events prior
          to delivery to a target</p></li>
        <li><p>The <span class="bold">default</span> event bus (created for an AWS account) receives events from the AWS services</p></li>
        <li><p>Support for Archives to backup events for future replay during testing</p></li>
        <li><p>Support for <span class="hi-vanila">Event Schema Registry</span></p></li>
      </ul>
    </div>
    <div id="section-div">
      <p>Amazon API Gateway</p>
    </div>
    <div id="para-div">
      <p>The following is the summary of the various features/capabilities of the API Gateway:</p>
      <ul id="blue-sqr-ul">
        <li><p>Is a service for creating, publishing, maintaining, monitoring, and securing REST, HTTP, and WebSocket APIs at any
          scale</p></li>
        <li><p>Enables stateless HTTP-based client-server communication to the backend HTTP or RESTful API services</p></li>
        <li><p>Enables stateful full-duplex communication between client and server using the WebSocket protocol</p></li>
        <li><p>Can be used to expose backend HTTP endpoints, Lambda functions, or other AWS services</p></li>
        <li><p>Can integrate with Lambda functions (through a Lambda Proxy) to create a fully managed serverless API service</p></li>
        <li><p>Can handle multiple environments (dev, test, prod)</p></li>
        <li><p>Can handle security (authentication and authorization)</p></li>
        <li><p>Support for rate limiting via request throttling. By default, limits the steady-state requests to <span class="hi-red">
          10000</span> requests per sec and maximum concurrent requests of <span class="hi-red">5000</span> per sec across all APIs
          in an AWS account</p></li>
        <li><p>Support for Swagger/OpenAPI standards to define APIs</p></li>
        <li><p>Can transform and validate requests and responses</p></li>
        <li><p>Support for caching API responses (with a TTL)</p></li>
        <li><p>Support for Usage Plans for the end users using API Keys (allows for custom throttling based on the API keys)</p></li>
        <li><p>Default timeout is <span class="hi-red">30</span> secs</p></li>
        <li>
          <p>The following are the supported API Gateway Deployment Types:</p>
          <div id="step-div">
            <p>Edge-Optimized</p>
          </div>
          <ul id="blue-arw-ul">
            <li><p>The default hostname of an API Gateway that is deployed to the specified Region while using CloudFront to facilitate
              client access typically from across AWS Regions</p></li>
            <li><p>Useful when the clients are global</p></li>
            <li><p>Requests come through CloudFront edge locations</p></li>
            <li><p>API Gateway still in a single Region</p></li>
          </ul>
          <div id="step-div">
            <p>Regional</p>
          </div>
          <ul id="blue-arw-ul">
            <li><p>The host name of an API that is deployed to the specific Region and intended to serve clients, such as EC2 instances,
              in the same AWS Region</p></li>
            <li><p>Useful when the clients are in a Region</p></li>
            <li><p>Can manually combine with CloudFront (for caching and distribution)</p></li>
          </ul>
          <div id="step-div">
            <p>Private</p>
          </div>
          <ul id="blue-arw-ul">
            <li><p>An API endpoint that is exposed through interface VPC endpoints and allows a client to securely access private API
              resources inside a VPC</p></li>
            <li><p>Can only be accessed from a VPC using the interface VPC endpoint (via ENI)</p></li>
            <li><p>One needs to configure a resource policy to control access</p></li>
          </ul>
        </li>
        <li>
          <p>The following are few points related to API Gateway Security:</p>
          <div id="step-div">
            <p>User Authentication</p>
          </div>
          <ul id="blue-arw-ul">
            <li><p>Via IAM Roles - useful for internal applications</p></li>
            <li><p>Using AWS Cognito - identity for external users</p></li>
            <li><p>Via a Custom Authorizer - for custom logic</p></li>
          </ul>
          <div id="step-div">
            <p>Custom Domain Name (HTTPS)</p>
          </div>
          <ul id="blue-arw-ul">
            <li><p>Must setup a CNAME or an Alias in Route 53</p></li>
            <li><p>If using Edge-Optimized endpoint, the certificate <span class="underbold">MUST</span> be in us-east-1</p></li>
            <li><p>If using Regional endpoint, the certificate <span class="underbold">MUST</span> be the API Gateway in the same
              Region</p></li>
          </ul>
        </li>
      </ul>
    </div>
    <div id="section-div">
      <p>Amazon Kinesis Data Streams</p>
    </div>
    <div id="para-div">
      <p>The following is the summary of the various features/capabilities of Kinesis Data Streams:</p>
      <ul id="blue-sqr-ul">
        <li><p>Used for collecting and processing <span class="underbold">LARGE</span> streams of data records in real-time</p></li>
        <li><p>One can use it for rapid and continuous data intake and aggregation</p></li>
        <li><p>Type of data can be infrastructure logs, application logs, IoT feeds, web clickstream, etc</p></li>
        <li><p>It is a collection of one or more <span class="hi-vanila">Shards</span>, where each shard is a uniquely identified
          sequence of data records with a fixed unit of capacity</p></li>
        <li><p>A <span class="hi-vanila">Data Record</span> is the unit of data stored and is composed of a sequence number, a
          partition key, and a data blob (immutable sequence of bytes)</p></li>
        <li><p>Data records with the same partition key go into the <span class="underbold">SAME</span> shard, ensuring ordering
          within a shard</p></li>
        <li><p>The total capacity of a data stream is the sum of the capacities of its shards in terms of ingestion and consumption
          rates</p></li>
        <li><p>Producers send data records into a data stream</p></li>
        <li><p>Each producer can send data records at a rate of up to <span class="hi-red">1000</span> records per sec or <span class
          ="hi-red">1</span> MB per sec into a shard</p></li>
        <li><p>There can be <span class="underbold">MANY</span> consumers (processing concurrently) receiving the data records from a
          data stream</p></li>
        <li>
          <p>The following are two modes of data consumption:</p>
          <ul id="blue-arw-ul">
            <li><p><span class="bold">Standard</span> - Consumer have to pull data</p></li>
            <li><p><span class="bold">Enhanced Fan-out</span> - Data is pushed to consumers</p></li>
          </ul>
        </li>
        <li><p>Consumers can receive data records at a rate of up to <span class="hi-red">2</span> MB per sec from a shard for all
          consumers in a shared mode OR per consumer in an enhanced fan-out mode</p></li>
        <li><p>Retention period is between <span class="hi-red">1</span> day (default) to <span class="hi-red">365</span> days</span></p></li>
        <li><p>Latency is around <span class="hi-red">200</span> ms (real-time)</p></li>
        <li><p>Ability to replay (or reprocess) previously processed data records (in the same order)</p></li>
        <li>
          <p>The following are the two supported Capacity Modes:</p>
          <div id="step-div">
            <p>Provisioned Mode</p>
          </div>
          <ul id="blue-arw-ul">
            <li><p>Choose the number of shards and scale them manually or using API</p></li>
            <li><p>Each shard has a write rate limit of <span class="hi-red">1000</span> records per sec or <span class="hi-red">
              1</span> MB per sec</p></li>
            <li><p>Each shard has a read rate limit of <span class="hi-red">2</span> MB per sec</p></li>
            <li><p>Pay per shard per hour</p></li>
          </ul>
          <div id="step-div">
            <p>On-demand Mode</p>
          </div>
          <ul id="blue-arw-ul">
            <li><p>No need to provision or manage capacity</p></li>
            <li><p>Default capacity has a write rate limit of <span class="hi-red">200000</span> records per sec or <span class="hi-red">
              200</span> MB per sec</p></li>
            <li><p>Default capacity has a read rate limit of <span class="hi-red">400</span> MB per sec of up to <span class="hi-red">
              2</span> default consumers OR up to <span class="hi-red">20</span> consumers in the enhanced fan-out mode</p></li>
            <li><p>Automatic scaling based on the observed throughput peak over the last <span class="hi-red">30</span> days period</p></li>
            <li><p>Pay per stream per hour <span class="underbold">PLUS</span> data in/out per GB</p></li>
          </ul>
        </li>
      </ul>
    </div>
    <div id="section-div">
      <p>Amazon Kinesis Data Firehose</p>
    </div>
    <div id="para-div">
      <p>The following is the summary of the various features/capabilities of Kinesis Data Firehose:</p>
      <ul id="blue-sqr-ul">
        <li><p>Is a fully managed, auto scaled service for delivering <span class="underbold">NEAR</span> real-time streaming data
          to destinations such as any custom HTTP endpoint, third-party services like Datadog, Splunk, etc, OR other AWS services
          such as S3, Redshift (via S3), OpenSearch etc</p></li>
        <li><p>Buffers incoming streaming data in memory to a certain size or for a certain period of time before delivering it to
          destinations</p></li>
        <li><p>The data record sent into data firehose can be up to 1 MB in size</p></li>
        <li><p>Producers send data records into a data firehose</p></li>
        <li><p>Producers can be any custom application, Kinesis Data Streams, CloudWatch, etc</p></li>
        <li><p>Can perform data transformations on the data records using Lambda functions before delivering to destinations</p></li>
        <li><p>Support for many data formats, data conversions, and data compression</p></li>
        <li><p>The data records sent to data firehose is NOT persisted or stored</p></li>
        <li><p>Data can be written to destinations in batches via buffering (default of <span class="hi-red">300</span> secs buffer
          interval OR <span class="hi-red">5</span> MB of buffer size)</p></li>
        <li><p>Data records that failed reach a destination can be written to a S3 backup bucket for analysis</p></li>
        <li><p>Pay only for the data going through data firehose</p></li>
      </ul>
    </div>
    <br/>
    <div id="section-div">
      <p>References</p>
    </div>
    <div id="para-div">
      <p><a href="https://docs.aws.amazon.com/amazon-mq/latest/developer-guide/welcome.html" target="_blank"><span class="bold">Official AWS MQ Documentation</span></a></p>
      <p><a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html" target="_blank"><span class="bold">Official AWS SQS Documentation</span></a></p>
      <p><a href="https://docs.aws.amazon.com/sns/latest/dg/welcome.html" target="_blank"><span class="bold">Official AWS SNS Documentation</span></a></p>
      <p><a href="https://docs.aws.amazon.com/step-functions/latest/dg/welcome.html" target="_blank"><span class="bold">Official AWS Step Functions Documentation</span></a></p>
      <p><a href="https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-what-is.html" target="_blank"><span class="bold">Official AWS EventBridge Documentation</span></a></p>
      <p><a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/welcome.html" target="_blank"><span class="bold">Official AWS API Gateway Documentation</span></a></p>
      <p><a href="https://docs.aws.amazon.com/streams/latest/dev/introduction.html" target="_blank"><span class="bold">Official AWS Kinesis Data Streams Documentation</span></a></p>
      <p><a href="https://docs.aws.amazon.com/firehose/latest/dev/what-is-this-service.html" target="_blank"><span class="bold">Official AWS Kinesis Data Firehose Documentation</span></a></p>
    </div>
    <hr class="line-hr" />
    <div>
      <a id="footer-a" href="https://polarsparc.github.io/">&copy;&nbsp;PolarSPARC</a>
    </div>
  </body>
</html>
