<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="content-type" content="application/xhtml+xml; charset=windows-1252" />
    <meta name="author" content="Bhaskar.S">
    <meta name="description" content="Machine Learning - Understanding Cross Validation">
    <meta name="subject" content="Machine Learning - Understanding Cross Validation">
    <meta name="keywords" content="python, machine_learning, cross_validation, scikit-learn">
    <meta name="robots" content="index, follow">
    <meta name="googlebot" content="index, follow">
    <title>Machine Learning - Understanding Cross Validation</title>
    <link href="../css/polarsparc-v2.4.css" type="text/css" rel="stylesheet" />
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script>
      MathJax = {
        tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  </head>
  <body>
    <br />
    <table borber="0">
      <tr>
        <td valign="bottom"><span id="ps-home"></span></td>
        <td valign="bottom"><span id="home-a"><a id="home-a" href="https://polarsparc.github.io/">PolarSPARC</a></span></td>
      </tr>
    </table>
    <br/>
    <div id="title-div">
      <p>Machine Learning - Understanding Cross Validation</p>
    </div>
    <br />
    <table id="ad-table">
      <tbody>
        <tr>
          <td class="author-td">Bhaskar S</td>
          <td class="date-td">06/03/2022</td>
        </tr>
      </tbody>
    </table>
    <hr class="line-hr" />
    <br />
    <div id="section-div">
      <p>Overview</p>
    </div>
    <div id="para-div">
      <p>Until now in this series, the approach taken to build and evaluate a machine learning model was to split the given data set
        into two sets - a training set and a test set. The training set typically comprises of about 70% to 80% of the data from the
        original data set.</p>
    </div>
    <div id="para-div">
      <p>The following illustration depicts this train-test split:</p>
    </div>
    <div id="img-outer-div"> <img alt="Train-Test Split" src="./images/cross-validation-01.png" class="img-cls" />
      <div class="img-cap">Figure.1</div>
    </div>
    <br/>
    <div id="para-div">
      <p>The question - why do we take this approach ??? The hypothesis is that, we train the model on one data set and evaluate the
        model using a different data set that the model has never seen before, with the belief that the result from the test data set
        would mimic the behavior of the model with an unseen data in the future.</p>
    </div>
    <div id="para-div">
      <p><span class="hi-yellow">Cross Validation</span> is the process of evaluating the accuracy of any machine learning model with
        new unseen data, so that the model is generalized enough for future predictions.</p>
      <p>The simple cross validation approach of splitting a given data set into a training set and a test set that we have been using
        until now is often referred to as the <span class="hi-blue">Hold Out</span> cross validation method.</p>
    </div>
    <div id="para-div">
      <p>A typical machine learning pipeline is to build a generalized model (for the given problem space) that can predict with a
        reasonably high accurately on the future data points. The pipeline involves the following steps:</p>
    </div>
    <div id="para-div">
      <ol id="blue-ol">
        <li><p>Train-test split</p></li>
        <li><p>Fit model using train set</p></li>
        <li><p>Evaluate model using test set</p></li>
        <li><p>Measure model accuracy</p></li>
        <li><p>Select new model if accuracy low</p></li>
        <li><p>Go to Step 2</p></li>
      </ol>
    </div>
    <div id="para-div">
      <p>The following illustration depicts this machine learning pipeline:</p>
    </div>
    <div id="img-outer-div"> <img alt="Machine Learning Pipeline" src="./images/cross-validation-02.png" class="img-cls" />
      <div class="img-cap">Figure.2</div>
    </div>
    <br/>
    <div id="para-div">
      <p>Note that the selection of the new model could be either adjusting the hyperparameters or choosing a different algorithm.</p>
      <p>However, there is an issue with the pipeline described above - we do *<span class="underbold">NOT</span>* have any separate
        truly unseen data (that is different from the test set) to evaluate the final model selected from the pipeline.</p>
    </div>
    <div id="para-div">
      <p>An enhancement to the simple cross validation hold out method is to split the given data set into three sets - a training
        set, a validation set, and a test set. The training set typically comprises of about 70% of the data from the original data
        set and the validation set typically comprises of about 15% of the remaining data.</p>
    </div>
    <div id="para-div">
      <p>The following illustration depicts this train-validate-test split:</p>
    </div>
    <div id="img-outer-div"> <img alt="Train-Validate-Test Split" src="./images/cross-validation-03.png" class="img-cls" />
      <div class="img-cap">Figure.3</div>
    </div>
    <br/>
    <div id="para-div">
      <p>The following illustration depicts the enhanced machine learning pipeline:</p>
    </div>
    <div id="img-outer-div"> <img alt="Enhanced ML Pipeline" src="./images/cross-validation-04.png" class="img-cls" />
      <div class="img-cap">Figure.4</div>
    </div>
    <br/>
    <div id="para-div">
      <p>One of the challenges with the Hold Out cross validation method is that the model accuracy measure from the test set may
        have high variance depending on what samples end up in the test set. In other words, the model accuracy measure depends on
        what data samples end up in the test set.</p>
    </div>
    <div id="para-div">
      <p>In order to address the variation challenges from the uneven distribution of the data samples in the test set, the
        <span class="hi-blue">k-Fold</span> cross validation method is used.</p>
      <p>In the k-Fold cross validation method, the given data set is first split into the training and test sets. Then, the training
        set is split into into $k$ parts (or folds) of equal size. The value of $k$ is typically 5 or 10. In each iteration, use the
        next fold from the $k$ folds as the validation set and the combination of the remaining $k-1$ folds as the training set.</p>
    </div>
    <div id="para-div">
      <p>For $k = 5$, the following illustration depicts the k-fold cross validation:</p>
    </div>
    <div id="img-outer-div"> <img alt="k-Fold Cross Validation" src="./images/cross-validation-05.png" class="img-cls" />
      <div class="img-cap">Figure.5</div>
    </div>
    <br/>
    <div id="para-div">
      <p>The pipeline with the k-fold cross validation involves the following steps:</p>
      <ol id="blue-ol">
        <li><p>Perform a Train-test split</p></li>
        <li><p>Split the training set into $k$ folds</p></li>
        <li><p>Select the next fold from $k$ folds as the validation set</p></li>
        <li><p>New training set is the combination remaining $k-1$ folds</p></li>
        <li><p>Fit model using the new training set</p></li>
        <li><p>Evaluate the model using the validation set</p></li>
        <li><p>Measure the model accuracy and save the result</p></li>
        <li><p>Continue Steps 3 through 7 for $k$ iterations</p></li>
        <li><p>Compute the average of the $k$ model accuracy scores</p></li>
        <li><p>Select new model if the average model accuracy is low</p></li>
        <li><p>Go to Step 3</p></li>
        <li><p>Finally evaluate selected model using the test set</p></li>
      </ol>
    </div>
    <div id="para-div">
      <p>The following illustration depicts the k-fold cross validation machine learning pipeline:</p>
    </div>
    <div id="img-outer-div"> <img alt="k-Fold ML Pipeline" src="./images/cross-validation-06.png" class="img-cls" />
      <div class="img-cap">Figure.6</div>
    </div>
    <br/>
    <div id="section-div">
      <p>Cross Validation using Scikit-Learn</p>
    </div>
    <div id="para-div">
      <p>In this article, we will use the <span class="hi-yellow">Diamond Prices</span> data set to demonstrate cross validation
        for selecting model hyperparameter(s).</p>
    </div>
    <div id="para-div">
      <p>The first step is to import all the necessary Python modules such as, pandas, and scikit-learn as shown below:</p>
    </div>
    <br/>
    <div id="src-outer-div-1">
      <div class="src-body-1">
<pre>import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.linear_model import Ridge
from sklearn.metrics import r2_score</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The next step is to load and display the Diamond Prices dataset into a pandas dataframe as shown below:</p>
    </div>
    <br/>
    <div id="src-outer-div-1">
      <div class="src-body-1">
<pre>url = './data/diamond-prices.csv'
diamond_prices_df = pd.read_csv(url, usecols=['carat', 'colour', 'clarity', 'certification', 'price'])
diamond_prices_df</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The following illustration shows the few rows of the diamond prices dataframe:</p>
    </div>
    <div id="img-outer-div"> <img alt="Dataframe Rows" src="./images/cross-validation-07.png" class="img-cls" />
      <div class="img-cap">Figure.7</div>
    </div>
    <br/>
    <div id="para-div">
      <p>The next step is to display the count for all the missing values from the diamond prices dataframe as shown below:</p>
    </div>
    <br/>
    <div id="src-outer-div-1">
      <div class="src-body-1">
<pre>diamond_prices_df.isnull().sum()</pre>
      </div>
    </div>
    <div id="para-div">
      <p>The following illustration shows the count for all the missing values from the diamond prices dataframe:</p>
    </div>
    <div id="img-outer-div"> <img alt="Count Missing" src="./images/cross-validation-08.png" class="img-cls" />
      <div class="img-cap">Figure.8</div>
    </div>
    <br/>
    <div id="para-div">
      <p>This is to ensure we have no missing values in the diamond prices data set.</p>
    </div>
    <div id="para-div">
      <p>The next step is to identify all the ordinal features from the diamond prices and creating a Python dictionary whose keys
        are the names of the ordinal features and their values are a Python dictionary of the mapping between the labels (of the
        ordinal feature) to the corresponding numerical values as shown below:</p>
    </div>
    <br/>
    <div id="src-outer-div-1">
      <div class="src-body-1">
<pre>ord_features_dict = {
  'colour': {'D': 6, 'E': 5, 'F': 4, 'G': 3, 'H': 2 , 'I': 1},
  'clarity': {'IF': 5, 'VVS1': 4, 'VVS2': 3, 'VS1': 2, 'VS2': 1}
}</pre>
      </div>
    </div>
    <div id="para-div">
      <p>The next step is to map the categorical labels for each of the ordinal features from the diamond prices dataframe into
        their their numerical representation using the Python dictionary from above as shown below:</p>
    </div>
    <br/>
    <div id="src-outer-div-1">
      <div class="src-body-1">
<pre>for key, val in ord_features_dict.items():
  diamond_prices_df[key] = diamond_prices_df[key].map(val)
diamond_prices_df</pre>
      </div>
    </div>
    <div id="para-div">
      <p>The following illustration shows the few rows of the transformed diamond prices dataframe:</p>
    </div>
    <div id="img-outer-div"> <img alt="Transformed Ordinals" src="./images/cross-validation-09.png" class="img-cls" />
      <div class="img-cap">Figure.9</div>
    </div>
    <br/>
    <div id="para-div">
      <p>Notice the annotated columns with transformed ordinal feature values - they are all numerical now.</p>
    </div>
    <div id="para-div">
      <p>The next step is to create dummy binary variables for the nominal feature 'certification' from the diamond prices data set
        as shown below:</p>
    </div>
    <br/>
    <div id="src-outer-div-1">
      <div class="src-body-1">
<pre>cert_encoded_df = pd.get_dummies(diamond_prices_df[['certification']], prefix_sep='.', sparse=False)
cert_encoded_df</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The following illustration displays the dataframe of all dummy binary variables for the nominal feature 'certification'
        from the diamond prices dataframe:</p>
    </div>
    <div id="img-outer-div"> <img alt="Dummy Variables" src="./images/cross-validation-10.png" class="img-cls" />
      <div class="img-cap">Figure.10</div>
    </div>
    <br/>
    <div id="para-div">
      <p>Notice that, with the dummy binary variables generation, we have created <span class="hi-red">3</span> additional features
        above.</p>
    </div>
    <div id="para-div">
      <p>The next step is to drop the nominal feature from the diamond prices dataframe, merge the dataframe of dummy binary variables
        we created earlier, and display the merged diamond prices dataframe as shown below:</p>
    </div>
    <br/>
    <div id="src-outer-div-1">
      <div class="src-body-1">
<pre>diamond_prices_df = diamond_prices_df.drop('certification', axis=1)
diamond_prices_df = pd.concat([diamond_prices_df, cert_encoded_df], axis=1)
diamond_prices_df</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The following illustration displays few rows from the merged diamond prices dataframe:</p>
    </div>
    <div id="img-outer-div"> <img alt="Dropped Nominal" src="./images/cross-validation-11.png" class="img-cls" />
      <div class="img-cap">Figure.11</div>
    </div>
    <br/>
    <div id="para-div">
      <p>The next step is to first split the diamond prices dataframe into two parts - a other data set and a test data set. Then,
        we split the other data set into the training data set (used to train the regression model) and the validation data set used
        to evaluate the regression model as shown below:</p>
    </div>
    <br/>
    <div id="src-outer-div-1">
      <div class="src-body-1">
<pre>X_other, X_test, y_other, y_test = train_test_split(diamond_prices_df[['carat', 'colour', 'clarity', 'certification.GIA', 'certification.HRD', 'certification.IGI']], diamond_prices_df['price'], test_size=0.15, random_state=101)
X_train, X_val, y_train, y_val = train_test_split(X_other, y_other, test_size=0.15, random_state=101)</pre>
      </div>
    </div>
    <div id="para-div">
      <p>The next step is to create an instance of the standardization scaler to scale all the feature variables from the other,
        training, validation, and test data set as shown below:</p>
    </div>
    <br/>
    <div id="src-outer-div-1">
      <div class="src-body-1">
<pre>scaler = StandardScaler()
X_other_s = pd.DataFrame(scaler.fit_transform(X_other), columns=X_other.columns, index=X_other.index)
X_train_s = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)
X_val_s = pd.DataFrame(scaler.transform(X_val), columns=X_val.columns, index=X_val.index)
X_test_s = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)
X_train_s</pre>
      </div>
    </div>
    <div id="para-div">
      <p>The following illustration displays few rows from the scaled diamond prices dataframe:</p>
    </div>
    <div id="img-outer-div"> <img alt="Scaled Features" src="./images/cross-validation-12.png" class="img-cls" />
      <div class="img-cap">Figure.12</div>
    </div>
    <br/>
    <div id="para-div">
      <p>In the following sections, we will demonstrate the two cross validation approaches - the Hold Out Train-Validate-Test method
        and the k-Fold method, using the regularized Ridge regression model.</p>
    </div>
    <div id="step-div">
      <p>Hold Out Train-Validate-Test</p>
    </div>
    <div id="para-div">
      <p>The next step is to perform the Ridge regression with the hyperparamter 'alpha' set to $100$. We fit the model using the
        training data set, evaluate the model using the validation data set, and display the $R2$ score as shown below:</p>
    </div>
    <div id="src-outer-div-1">
      <div class="src-body-1">
<pre>model_one = Ridge(alpha=100)
model_one.fit(X_train_s, y_train)
y_val_pred1 = model_one.predict(X_val_s)
r2_score(y_val, y_val_pred1)</pre>
      </div>
    </div>
    <div id="para-div">
      <p>The following illustration displays the $R2$ score for the Ridge regression with the hyperparamter 'alpha' set to $100$:</p>
    </div>
    <div id="img-outer-div"> <img alt="Ridge Alpha 100" src="./images/cross-validation-13.png" class="img-cls" />
      <div class="img-cap">Figure.13</div>
    </div>
    <br/>
    <div id="para-div">
      <p>The next step is to perform the next iteration of the Ridge regression with the hyperparamter 'alpha' set to $5$. Again, we
        fit the model using the training data set, evaluate the model using the validation data set, and display the $R2$ score as
        shown below:</p>
    </div>
    <div id="src-outer-div-1">
      <div class="src-body-1">
<pre>model_two = Ridge(alpha=5)
model_two.fit(X_train_s, y_train)
y_val_pred2 = model_two.predict(X_val_s)
r2_score(y_val, y_val_pred2)</pre>
      </div>
    </div>
    <div id="para-div">
      <p>The following illustration displays the $R2$ score for the Ridge regression with the hyperparamter 'alpha' set to $5$:</p>
    </div>
    <div id="img-outer-div"> <img alt="Ridge Alpha 5" src="./images/cross-validation-14.png" class="img-cls" />
      <div class="img-cap">Figure.14</div>
    </div>
    <br/>
    <div id="para-div">
      <p>Given the $R2$ score for the second model is better, the next step is to perform a final model evaluation using the test
        data set and display the $R2$ score as shown below:</p>
    </div>
    <div id="src-outer-div-1">
      <div class="src-body-1">
<pre>y_pred = model_two.predict(X_test_s)
r2_score(y_test, y_pred)</pre>
      </div>
    </div>
    <div id="para-div">
      <p>The following illustration displays the $R2$ score from the final model evaluation using the test data set:</p>
    </div>
    <div id="img-outer-div"> <img alt="Final Test" src="./images/cross-validation-15.png" class="img-cls" />
      <div class="img-cap">Figure.15</div>
    </div>
    <br/>
    <div id="step-div">
      <p>k-Fold</p>
    </div>
    <div id="para-div">
      <p>The next step is to create an instance of KFold with $5$ folds as shown below:</p>
    </div>
    <div id="src-outer-div-1">
      <div class="src-body-1">
<pre>folds_5 = KFold(n_splits=5, random_state=101, shuffle=True)</pre>
      </div>
    </div>
    <div id="para-div">
      <p>The next step is to perform a 5-fold cross validation on the Ridge regression model with the hyperparamter 'alpha' set to
        $100$. One needs to specify an instance of the model, the other data set, and the scoring method ($R2$ in our case) to the
        function <span class="hi-blue">cross_val_score</span>, which under-the-hood performs the necessary 5-fold cross validation.
        On completion, it returns an array of $R2$ scores (one for each of the 5 iterations). We then perform an average on the
        scores as shown below:</p>
    </div>
    <div id="src-outer-div-1">
      <div class="src-body-1">
<pre>model_one = Ridge(alpha=100)
scores = cross_val_score(model_one, X_other_s, y_other, scoring='r2', cv=folds_5)
scores.mean()</pre>
      </div>
    </div>
    <div id="para-div">
      <p>The following illustration displays the average $R2$ score for the Ridge regression with the hyperparamter 'alpha' set to
        $100$:</p>
    </div>
    <div id="img-outer-div"> <img alt="5-Fold Ridge Alpha 100" src="./images/cross-validation-16.png" class="img-cls" />
      <div class="img-cap">Figure.16</div>
    </div>
    <br/>
    <div id="para-div">
      <p>The next step is to perform another iteration of the 5-fold cross validation on the Ridge regression model with the
        hyperparamter 'alpha' set to $5$. Once again, we specify the model, the other data set, and the scoring method ($R2$ in our
        case) to the cross_val_score function, which returns an array of $R2$ scores. We then perform an average on the scores as
        shown below:</p>
    </div>
    <div id="src-outer-div-1">
      <div class="src-body-1">
<pre>model_two = Ridge(alpha=5)
scores2 = cross_val_score(model_two, X_other_s, y_other, scoring='r2', cv=folds_5)
scores2.mean()</pre>
      </div>
    </div>
    <div id="para-div">
      <p>The following illustration displays the average $R2$ score for the Ridge regression with the hyperparamter 'alpha' set to
        $5$:</p>
    </div>
    <div id="img-outer-div"> <img alt="5-Fold Ridge Alpha 5" src="./images/cross-validation-17.png" class="img-cls" />
      <div class="img-cap">Figure.17</div>
    </div>
    <br/>
    <div id="para-div">
      <p>Given the $R2$ score for the second model is better, the next step is to perform a final model evaluation using the test
        data set and display the $R2$ score as shown below:</p>
    </div>
    <div id="src-outer-div-1">
      <div class="src-body-1">
<pre>model_two.fit(X_other_s, y_other)
y_pred = model_two.predict(X_test_s)
r2_score(y_test, y_pred)</pre>
      </div>
    </div>
    <div id="para-div">
      <p>Notice that we have to fit the model using the other data set before using the model to predict.</p>
      <p>The following illustration displays the $R2$ score from the final model evaluation using the test data set:</p>
    </div>
    <div id="img-outer-div"> <img alt="Final Test 2" src="./images/cross-validation-18.png" class="img-cls" />
      <div class="img-cap">Figure.18</div>
    </div>
    <br/>
    <div id="section-div">
      <p>Hands-on Demo</p>
    </div>
    <div id="para-div">
      <p>The following is the link to the <span class="bold">Jupyter Notebooks</span> that provides an hands-on demo for this
        article:</p>
      <ul id="blue-sqr-ul">
        <li><p><a href="https://github.com/bhaskars-repo/MachineLearning/blob/main/P12-CrossValidation.ipynb" target="_blank">
          <span class="bold">Cross Validation</span></a></p></li>
      </ul>
    </div>
    <br/>
    <hr class="line-hr" />
    <div>
      <a id="footer-a" href="https://polarsparc.github.io/">&copy;&nbsp;PolarSPARC</a>
    </div>
  </body>
</html>
