<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
  <head>
    <meta http-equiv="content-type" content="application/xhtml+xml; charset=windows-1252" />
    <meta name="author" content="Bhaskar.S">
    <meta name="description" content="Quick Test :: Text-to-Image using Qwen-Image on a Local Machine">
    <meta name="subject" content="Quick Test :: Text-to-Image using Qwen-Image on a Local Machine">
    <meta name="keywords" content="diffusion, flux-1">
    <meta name="robots" content="index, follow">
    <meta name="googlebot" content="index, follow">
    <title>Quick Test :: Text-to-Image using Qwen-Image on a Local Machine</title>
    <link href="../css/polarsparc-v2.4.css" type="text/css" rel="stylesheet" />
  </head>
  <body>
    <br/>
    <table borber="0">
      <tr>
        <td valign="bottom"><span id="ps-home"></span></td>
        <td valign="bottom"><span id="home-a"><a id="home-a" href="https://polarsparc.github.io/">PolarSPARC</a></span></td>
      </tr>
    </table>
    <br/>
    <div id="title-div">
      <p>Quick Test :: Text-to-Image using Qwen-Image on a Local Machine</p>
    </div>
    <br/>
    <table id="ad-table">
      <tbody>
        <tr>
          <td class="author-td">Bhaskar S</td>
          <td class="date-td">08/23/2025</td>
        </tr>
      </tbody>
    </table>
    <hr class="line-hr" />
    <br/>
    <div id="para-div">
      <p>This quick test demonstrates how one can run the recently released <span class="hi-purple">Qwen-Image</span> text-to-image
        <span class="hi-yellow">Diffusion</span> model on a decent <span class="bold">8-core</span> desktop with <span class="bold">
        64gb</span> RAM and <span class="bold">16gb</span> VRAM <span class="bold">NVidia</span> GPU.</p>
    </div>
    <div id="para-div">
      <p>Ensure that <span class="bold">Python 3.1x</span> programming language is installed and setup on the desktop.</p>
    </div>
    <div id="para-div">
      <p>In addition, install the following necessary <span class="bold">Python</span> modules by executing the following command:</p>
    </div>
    <br/>
    <div id="cmd-div">
      <p>$ pip install accelerate diffusers huggingface_hub pillow torch</p>
    </div>
    <br/>
    <div id="para-div">
      <p>The first step is to download the <span class="bold">Qwen-Image</span> model from the <span class="bold">HuggingFace</span>
        repository to a directory on the desktop.</p>
      <p>Create a directory called <span class="bold">/tmp/qwen-image</span> and then execute the following <span class="bold">Python
        </span> code snippet:</p>
    </div>
    <br/>
    <div id="src-outer-div-1">
      <div class="gen-src-body">
<pre>from huggingface_hub import snapshot_download

qwen_image_dir = '/tmp/qwen-image'
snapshot_download(repo_id='Qwen/Qwen-Image', local_dir=qwen_image_dir)</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The above code execution will take a few minutes to complete as the model needs to be downloaded to the desktop over the
        Internet.</p>
    </div>
    <br/>
    <div id="warn-div">
      <h4>!!! ATTENTION !!!</h4>
      <pre>With a 1 Gbps internet speed, the 'snapshot_download' command will take between <span class="underbold">10 to 15</span> minutes to download the model !!!</pre>
    </div>
    <br/>
    <div id="para-div">
      <p>Create a directory called <span class="bold">/tmp/images</span> where the model generated image would be stored.</p>
    </div>
    <div id="para-div">
      <p>Execute the following <span class="bold">Python</span> code snippet to run the text-to-image diffusion model:</p>
    </div>
    <br/>
    <div id="src-outer-div-1">
      <div class="gen-src-body">
<pre>from diffusers import DiffusionPipeline
import os
import torch

device = 'cpu'
qwen_image_dir = '/tmp/qwen-image'
torch_bfloat16 = torch.bfloat16
pipe = DiffusionPipeline.from_pretrained(qwen_image_dir, torch_dtype=torch_bfloat16)
pipe = pipe.to(device)
pipe.enable_sequential_cpu_offload()

prompt = '''
A digital art of a robot and a tiger walking together, in a forest filled with snow, with mountains in the background
'''

num_inference_steps = 16
image = pipe(
    prompt,
    output_type='pil',
    num_inference_steps=num_inference_steps,
    height=640,
    width=720,
    generator=torch.Generator(device).manual_seed(7)
).images[0]

image.save('/tmp/images/robot-tiger.jpg')</pre>
      </div>
    </div>
    <br/>
    <br/>
    <div id="warn-div">
      <h4>!!! ATTENTION !!!</h4>
      <pre>It is <span class="underbold">VERY IMPORTANT</span> to use the float type of <span class="underbold">torch.bfloat16</span>. Else will encounter <span class="underbold">RUNTIME ERRORS</span> !!!</pre>
    </div>
    <br/>
    <div id="para-div">
      <p>On the desktop with the specified specs, the model will leverage the CPU memory and typically run for about 5 mins before
        generating the desired image !!!</p>
    </div>
    <div id="para-div">
      <p>The following is the image generated by the <span class="bold">Qwen-Image</span> model for the specific prompt:</p>
    </div>
    <br/>
    <div id="img-outer-div"> <img class="img-cls" src="./images/robot-tiger.jpg" alt="Robot and Tiger" />
    </div>
    <br/>
    <div id="para-div">
      <p>Execute the following <span class="bold">Python</span> code snippet to run the text-to-image diffusion model:</p>
    </div>
    <br/>
    <div id="src-outer-div-1">
      <div class="gen-src-body">
<pre>prompt = '''
A panda performing a dance in the center of Rome colosseum, with people clapping and showering flowers in the air. Render the image
in van gogh style
'''

image = pipe(
    prompt,
    output_type='pil',
    num_inference_steps=num_inference_steps,
    height=640,
    width=720,
    generator=torch.Generator(device).manual_seed(7)
).images[0]

image.save('/tmp/images/panda-dance.jpg')</pre>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The following is the image generated by the <span class="bold">Qwen-Image</span> model for the specific prompt:</p>
    </div>
    <br/>
    <div id="img-outer-div"> <img class="img-cls" src="./images/panda-dance.jpg" alt="Panda Dance Rome" />
    </div>
    <br/>
    <div id="para-div">
      <p>The <span class="bold">Qwen-Image</span> model is pretty impressive in image generation !!!</p>
    </div>
    <br/>
    <div id="warn-div">
      <h4>!!! ATTENTION !!!</h4>
      <pre>The Qwen-Image also has an ability to edit input images - however was <span class="underbold">UNABLE</span> to perform the edit task !!!</pre>
    </div>
    <br/>
    <br/>
    <div id="section-div">
      <p>References</p>
    </div>
    <div id="para-div">
      <p><a href="https://huggingface.co/Qwen/Qwen-Image" target="_blank"><span class="bold">HuggingFace Qwen-Image</span></a></p>
    </div>
    <br/>
    <hr class="line-hr" />
    <div>
      <a id="footer-a" href="https://polarsparc.github.io/">&copy;&nbsp;PolarSPARC</a>
    </div>
  </body>
</html>
