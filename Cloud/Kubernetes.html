<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="content-type" content="application/xhtml+xml; charset=windows-1252" />
    <meta name="Introduction to Kubernetes (ARM Edition)" content="author: Bhaskar.S, category: arm, docker, kubernetes">
    <title>Introduction to Kubernetes (ARM Edition)</title>
    <link href="../css/polarsparc-v2.4.css" type="text/css" rel="stylesheet" />
  </head>
  <body>
    <br/>
    <table borber="0">
      <tr>
        <td valign="bottom"><span id="ps-home"></span></td>
        <td valign="bottom"><span id="home-a"><a id="home-a" href="https://polarsparc.github.io/">PolarSPARC</a></span></td>
      </tr>
    </table>
    <br/>
    <div id="title-div">
      <p>Introduction to Kubernetes (ARM Edition)</p>
    </div>
    <br />
    <table id="ad-table">
      <tbody>
        <tr>
          <td class="author-td">Bhaskar S</td>
          <td class="date-td">01/21/2019</td>
        </tr>
      </tbody>
    </table>
    <hr class="line-hr" /> <br />
    <div id="section-div">
      <p>Overview</p>
    </div>
    <div id="para-div">
      <p><span class="hi-yellow">Kubernetes</span> (or <span class="hi-yellow">k8s</span> for short) is an extensible open
        source container orchestration platform designed for managing containerized workloads and services at scale. It helps
        in automated deployment, scaling, and management of container centric application workloads across a cluster of nodes
        (bare-metal, virtual, or cloud) by orchestrating compute, network, and storage infrastructure on behalf of those user
        workloads.</p>
      <p>The two main types of nodes in a <span class="bold">Kubernetes</span> cluster are:</p>
      <ul id="blue-sqr-ul">
        <li>
          <p><span class="hi-yellow">Master</span> :: a node that acts as the <span class="bold">Control Plane</span> for the
            cluster. It is responsible for all application workload deployment, scheduling, and placement decisions as well as
            detecting and managing changes to the state of deployed applications</p>
        </li>
        <li>
          <p><span class="hi-yellow">Node</span>(s) :: node(s) that actually run the application containers. They are also on
            occasions referred to as <span class="hi-yellow">Minion</span>(s). The <span class="bold">master</span> is also a
            node, but is not targeted for application deployment</p>
        </li>
      </ul>
    </div>
    <div id="para-div">
      <p>The following Figure-1 illustrates the high-level architectural overview of <span class="bold">Kubernetes</span>:</p>
    </div>
    <div id="img-outer-div"> <img src="./images/Kubernetes-1.png" class="img-cls" alt="Kubernetes" />
      <div class="img-cap">Figure-1</div>
    </div>
    <div id="para-div">
      <p>The core components that make <span class="bold">Kubernetes</span> cluster are as follows:</p>
      <ul id="blue-sqr-ul">
        <li>
          <p><span class="hi-yellow">Store</span> :: a highly reliable, distributed, and consistent key-value data store used for
            persisting and maintaining state information about the various components of the <span class="bold">Kubernetes</span>
            cluster. By default, <span class="bold">Kubernetes</span> uses <span class="hi-blue">etcd</span> as the key-value
            store</p>
        </li>
        <li>
          <p><span class="hi-yellow">API Server</span> :: acts as the entry point for the <span class="bold">Control Plane</span>
            by exposing an API endpoint for all interactions with and within the <span class="bold">Kubernetes</span> cluster. It
            is through the <span class="bold">API Server</span> that requests are made for deployment, administration, management,
            and operation of container based applications. It uses the key-value <span class="bold">store</span> to persist and
            maintain state information about all the components of the <span class="bold">Kubernetes</span> cluster</p>
        </li>
        <li>
          <p><span class="hi-yellow">kubectl</span> :: command line tool used for interfacing with the <span class="bold">
            API Server</span>. Used by administrators (or operators) for deployment and scaling of applications, as well as for
            management of the <span class="bold">Kubernetes</span> cluster</p>
        </li>
        <li>
          <p><span class="hi-yellow">Pod</span>(s) :: One or more containers run inside it. It is the smallest unit of deployment
            in <span class="bold">Kubernetes</span>. Think of it as a logical host with shared network and storage. Application
            <span class="bold">pod</span>s are scheduled to run on different <span class="bold">node</span>s of the
            <span class="bold">Kubernetes</span> cluster based on the resource needs and application constraints. Every
            <span class="bold">pod</span> within the cluster gets its own unique <span class="hi-vanila">ip-address</span>. The
            application containers within a <span class="bold">pod</span> communicate with each other using
            <span class="hi-blue">localhost</span></p>
        </li>
        <li>
          <p><span class="hi-yellow">kubelet</span> :: an agent that runs on every <span class="bold">node</span> of the
            <span class="bold">Kubernetes</span> cluster. It is responsible for creating and starting an application
            <span class="bold">pod</span> on the <span class="bold">node</span> and making sure all the application containers
            are up and running within the <span class="bold">pod</span>. In addition, it is also responsible for reporting the
            state and health of the <span class="bold">node</span>, as well as all the running <span class="bold">pod</span>s
            to the <span class="bold">master</span> via the <span class="bold">API server</span></p>
        </li>
        <li>
          <p><span class="hi-yellow">Scheduler</span> :: responsible for scheduling application <span class="bold">pod</span>(s)
            to run on the selected <span class="bold">node</span>(s) of the <span class="bold">Kubernetes</span> cluster based on
            the application resource requirements as well as application specific affinity constraints</p>
        </li>
        <li>
          <p><span class="hi-yellow">Service</span> :: is a logical networking abstraction for the group of <span class="bold">
            pod</span>(s) (based on a label related to an application) running on the <span class="bold">node</span>(s) of the
            <span class="bold">Kubernetes</span> cluster. They enable access to an application via service-discovery and spread
            the requests through load-balancing. To access an application, each <span class="bold">service</span> is assigned a
            cluster-wide internal ip-address:port</p>
        </li>
        <li>
          <p><span class="hi-yellow">Controller Manager</span> :: manages different types of controllers that are responsible for
            monitoring and detecting changes to the state of the <span class="bold">Kubernetes</span> cluster (via the
            <span class="bold">API server</span>) and ensuring that the cluster is moved to the desired state. The different
            types of controllers are:</p>
          <ul>
            <li>
              <p><span class="hi-blue">Node Controller</span> =&gt; responsible for monitoring and detecting the state &amp;
                health (up or down) of the <span class="bold">node</span>(s) in the <span class="bold">Kubernetes</span> cluster</p>
            </li>
            <li>
              <p><span class="hi-blue">ReplicaSet</span> =&gt; previously referred to as the <span class="hi-blue">Replication
                Controller</span> and is responsible for maintaining the desired number of <span class="bold">pod</span>
                replicas in the cluster</p>
            </li>
            <li>
              <p><span class="hi-blue">Endpoints Controller</span> =&gt; responsible for detecting and managing changes to the
                application <span class="bold">service</span> access endpoints (list of ip-address:port)</p>
            </li>
          </ul>
        </li>
        <li>
          <p><span class="hi-yellow">kube-proxy</span> :: a network proxy that runs on each of the <span class="bold">node</span>(s)
            of the <span class="bold">Kubernetes</span> cluster and acts as an entry point for access to the various application
            <span class="bold">service</span> endpoints. It routes requests to the appropriate <span class="bold">pod</span>(s) in
            the cluster</p>
        </li>
        <li>
          <p><span class="hi-yellow">Plugin Network</span> :: acts as the bridge (overlay network) that enables communication
            between the <span class="bold">pod</span>(s) running on different <span class="bold">node</span>(s) of the cluster.
            There are different implementations of this component by various 3rd-parties such as <span class="hi-blue">
            calico</span>, <span class="hi-blue">flannel</span>, <span class="hi-blue">weave-net</span>, etc. They all need
            to adhere to a common specification called the <span class="hi-vanila">Container Network Interface</span> or
            <span class="hi-vanila">CNI</span> for short</p>
        </li>
      </ul>
    </div>
    <div id="section-div">
      <p>Installation and Setup</p>
    </div>
    <div id="para-div">
      <p>The installation will be on a 5-node <span class="bold">Raspberry Pi Cluster</span> running Linux.</p>
    </div>
    <div id="para-div">
      <p>The following Figure-2 illustrates the 5-node <span class="bold">Raspberry Pi</span> cluster in operation:</p>
    </div>
    <div id="img-outer-div"> <img src="./images/Kubernetes-2.png" class="img-cls" alt="Raspberry Pi Cluster" />
      <div class="img-cap">Figure-2</div>
    </div>
    <div id="para-div">
      <p>For this tutorial, let us assume the 5-nodes in the cluster to have the following host names and ip addresses:</p>
    </div>
    <table id="col2-table">
    <thead>
    <tr>
      <th>Host name</th>
      <th>IP Address</th>
    </tr>
    </thead>
    <tbody>
      <tr>
        <td class="col2-c1-odd">my-node-1</td>
        <td class="col2-c2-odd">192.168.1.201</td>
      </tr>
      <tr>
        <td class="col2-c1-even">my-node-2</td>
        <td class="col2-c2-even">192.168.1.202</td>
      </tr>
      <tr>
        <td class="col2-c1-odd">my-node-3</td>
        <td class="col2-c2-odd">192.168.1.203</td>
      </tr>
      <tr>
        <td class="col2-c1-even">my-node-4</td>
        <td class="col2-c2-even">192.168.1.204</td>
      </tr>
      <tr>
        <td class="col2-c1-odd">my-node-5</td>
        <td class="col2-c2-odd">192.168.1.205</td>
      </tr>
    </tbody>
    </table>
    <div id="para-div">
      <p>Open a Terminal window and open a tab for each of the 5 nodes my-node-1 thru my-node-5. In each of the Terminal tabs,
        <span class="bold">ssh</span> into the corresponding node.</p>
    </div>
    <div id="error-div">
      <h4>ATTENTION: Docker CE 18.09 (and above) Users</h4>
      <pre><span class="underbold">Ensure</span> the version of <span class="bold">Docker</span> installed is *<span class="underbold">17.09</span>*. Else will encounter the following error:<br/><br/><span class="bold">[ERROR SystemVerification]: unsupported docker version: 18.09.0</span></pre>
    </div>
    <div id="para-div">
      <p>First we need to install <span class="bold">Docker</span> version <span class="bold">17.09</span> (in a round about way)
        on each of the nodes my-node-&lt;N&gt;, where &lt;N&gt; ranges from 1 thru 5, execute the following commands:</p>
    </div>
    <div id="cmd-div">
      <p>$ curl -fsSL https://get.docker.com -o get-docker.sh</p>
      <p>$ sudo sh get-docker.sh</p>
      <p>$ sudo usermod -aG docker $USER</p>
      <p>$ sudo systemctl stop docker</p>
      <p>$ sudo apt remove docker-ce</p>
      <p>$ sudo apt-get install docker-ce=17.09.0~ce-0~raspbian</p>
      <p>$ sudo shutdown -r now</p>
    </div>
    <div id="para-div">
      <p>Once <span class="bold">reboot</span> completes, execute the following command to check everything was ok:</p>
    </div>
    <div id="cmd-div">
      <p>$ docker version</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.1</h4>
      <pre>Client:
 Version:      17.09.0-ce
 API version:  1.32
 Go version:   go1.8.3
 Git commit:   afdb6d4
 Built:        Tue Sep 26 22:58:36 2017
 OS/Arch:      linux/arm

Server:
 Version:      17.09.0-ce
 API version:  1.32 (minimum version 1.12)
 Go version:   go1.8.3
 Git commit:   afdb6d4
 Built:        Tue Sep 26 22:52:15 2017
 OS/Arch:      linux/arm
 Experimental: false</pre>
    </div>
    <div id="para-div">
      <p>Next, we need to disable disk based <span class="hi-yellow">swap</span>. To do that on each of the nodes my-node-&lt;N&gt;,
        where &lt;N&gt; ranges from 1 thru 5, execute the following commands:</p>
    </div>
    <div id="cmd-div">
      <p>$ sudo systemctl disable dphys-swapfile</p>
      <p>$ sudo dphys-swapfile swapoff</p>
      <p>$ sudo dphys-swapfile uninstall</p>
      <p>$ sudo update-rc.d dphys-swapfile remove</p>
    </div>
    <div id="para-div">
      <p>Next, we need to enable and enforce cpu and memory limits (quotas) in <span class="bold">Docker</span>. To do that on each of
        the nodes my-node-&lt;N&gt;, where &lt;N&gt; ranges from 1 thru 5, execute the following commands:</p>
    </div>
    <div id="cmd-div">
      <p>$ sudo cp /boot/cmdline.txt /boot/cmdline_backup.txt</p>
      <p>$ line="$(head -n1 /boot/cmdline.txt) cgroup_enable=cpuset cgroup_enable=memory"</p>
      <p>$ echo $line | sudo tee /boot/cmdline.txt</p>
    </div>
    <div id="para-div">
      <p>Next, we need to install <span class="bold">Kubernetes</span>. To do that on each of the nodes my-node-&lt;N&gt;, where &lt;N&gt;
        ranges from 1 thru 5, execute the following commands:</p>
    </div>
    <div id="cmd-div">
      <p>$ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -</p>
      <p>$ echo "deb http://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list</p>
      <p>$ sudo apt-get update</p>
      <p>$ sudo apt-get install -y kubeadm</p>
      <p>$ sudo reboot now</p>
    </div>
    <div id="para-div">
      <p>Once <span class="bold">reboot</span> completes, execute the following command to check everything was ok:</p>
    </div>
    <div id="cmd-div">
      <p>$ kubeadm version</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.2</h4>
      <pre>kubeadm version: &version.Info{Major:"1", Minor:"13", GitVersion:"v1.13.2", GitCommit:"cff46ab41ff0bb44d8584413b598ad8360ec1def", GitTreeState:"clean", BuildDate:"2019-01-10T23:33:30Z", GoVersion:"go1.11.4", Compiler:"gc", Platform:"linux/arm"}</pre>
    </div>
    <div id="para-div">
      <p>Then, execute the following command:</p>
    </div>
    <div id="cmd-div">
      <p>$ kubectl version</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.3</h4>
      <pre>Client Version: version.Info{Major:"1", Minor:"13", GitVersion:"v1.13.2", GitCommit:"cff46ab41ff0bb44d8584413b598ad8360ec1def", GitTreeState:"clean", BuildDate:"2019-01-10T23:35:51Z", GoVersion:"go1.11.4", Compiler:"gc", Platform:"linux/arm"}
The connection to the server localhost:8080 was refused - did you specify the right host or port?</pre>
    </div>
    <div id="para-div">
      <p>Finally, we need to disable the updates to <span class="bold">Docker</span> and <span class="bold">Kubernetes</span>. To
        do that on each of the nodes my-node-&lt;N&gt;, where &lt;N&gt; ranges from 1 thru 5, execute the following command:</p>
    </div>
    <div id="cmd-div">
      <p>$ sudo apt-mark hold kubelet kubeadm kubectl docker-ce</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.4</h4>
      <pre>kubelet set on hold.
kubeadm set on hold.
kubectl set on hold.
docker-ce set on hold.</pre>
    </div>
    <div id="para-div">
      <p><span class="bold">Thats it</span> !!! This completes the installation and setup process.</p>
    </div>
    <div id="section-div">
      <p>Hands-on with Kubernetes</p>
    </div>
    <div id="para-div">
      <p>For get started, we need make the node <span class="bold">my-node-1</span> the <span class="bold">master</span> node
        and setup the control plane. To do that, execute the following command on <span class="bold">my-node-1</span>:</p>
    </div>
    <div id="cmd-div">
      <p>$ sudo kubeadm init</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.5</h4>
      <pre>[init] Using Kubernetes version: v1.13.2
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'

[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
[kubelet-start] Activating the kubelet service
[certs] Using certificateDir folder "/etc/kubernetes/pki"
[certs] Generating "etcd/ca" certificate and key
[certs] Generating "etcd/server" certificate and key
[certs] etcd/server serving cert is signed for DNS names [my-node-1 localhost] and IPs [192.168.1.201 127.0.0.1 ::1]
[certs] Generating "apiserver-etcd-client" certificate and key
[certs] Generating "etcd/peer" certificate and key
[certs] etcd/peer serving cert is signed for DNS names [my-node-1 localhost] and IPs [192.168.1.201 127.0.0.1 ::1]
[certs] Generating "etcd/healthcheck-client" certificate and key
[certs] Generating "front-proxy-ca" certificate and key
[certs] Generating "front-proxy-client" certificate and key
[certs] Generating "ca" certificate and key
[certs] Generating "apiserver" certificate and key
[certs] apiserver serving cert is signed for DNS names [my-node-1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.1.201]
[certs] Generating "apiserver-kubelet-client" certificate and key
[certs] Generating "sa" key and public key
[kubeconfig] Using kubeconfig folder "/etc/kubernetes"
[kubeconfig] Writing "admin.conf" kubeconfig file
[kubeconfig] Writing "kubelet.conf" kubeconfig file
[kubeconfig] Writing "controller-manager.conf" kubeconfig file
[kubeconfig] Writing "scheduler.conf" kubeconfig file
[control-plane] Using manifest folder "/etc/kubernetes/manifests"
[control-plane] Creating static Pod manifest for "kube-apiserver"
[control-plane] Creating static Pod manifest for "kube-controller-manager"
[control-plane] Creating static Pod manifest for "kube-scheduler"
[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s
[kubelet-check] Initial timeout of 40s passed.
[apiclient] All control plane components are healthy after 175.514425 seconds
[uploadconfig] storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
[kubelet] Creating a ConfigMap "kubelet-config-1.13" in namespace kube-system with the configuration for the kubelets in the cluster
[patchnode] Uploading the CRI Socket information "/var/run/dockershim.sock" to the Node API object "my-node-1" as an annotation
[mark-control-plane] Marking the node my-node-1 as control-plane by adding the label "node-role.kubernetes.io/master=''"
[mark-control-plane] Marking the node my-node-1 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
[bootstrap-token] Using token: j99kcz.pfwryj2hhhcnmbrb
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstraptoken] creating the "cluster-info" ConfigMap in the "kube-public" namespace
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes master has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of machines by running the following on each node
as root:

  kubeadm join 192.168.1.201:6443 --token j99kcz.pfwryj2hhhcnmbrb --discovery-token-ca-cert-hash sha256:af11197f74a71890faa275f42f4e2d6c0e9da2fe34bc360d3c21f83994255d76</pre>
    </div>
    <div id="para-div">
      <p>In order to use the <span class="bold">kubectl</span> command-line tool as a non-<span class="bold">root</span>
        user on the <span class="bold">master</span> node (<span class="bold">my-node-1</span>), execute the following
        commands on <span class="bold">my-node-1</span>:</p>
    </div>
    <div id="cmd-div">
      <p>$ mkdir -p $HOME/.kube</p>
      <p>$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</p>
      <p>$ sudo chown $(id -u):$(id -g) $HOME/.kube/config</p>
    </div>
    <div id="para-div">
      <p>To list all the node(s) in <span class="bold">Kubernetes</span> cluster, execute the following command on
        <span class="bold">my-node-1</span>:</p>
    </div>
    <div id="cmd-div">
      <p>$ kubectl get nodes</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.6</h4>
      <pre>NAME        STATUS     ROLES    AGE   VERSION
my-node-1   NotReady   master   12m   v1.13.2</pre>
    </div>
    <div id="para-div">
      <p>We need to install an overlay <span class="bold">Plugin Network</span> for inter-<span class="bold">pod</span>
        communication. For our demonstration, we will choose the <span class="bold">weave-net</span> implementation. To
        install the overlay network, execute the following command on <span class="bold">my-node-1</span>:</p>
    </div>
    <div id="cmd-div">
      <p>$ kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.7</h4>
      <pre>serviceaccount/weave-net created
clusterrole.rbac.authorization.k8s.io/weave-net created
clusterrolebinding.rbac.authorization.k8s.io/weave-net created
role.rbac.authorization.k8s.io/weave-net created
rolebinding.rbac.authorization.k8s.io/weave-net created
daemonset.extensions/weave-net created</pre>
    </div>
    <div id="para-div">
      <p>To list all the <span class="bold">pod</span>(s) running in <span class="bold">Kubernetes</span> cluster, execute
        the following command on <span class="bold">my-node-1</span>:</p>
    </div>
    <div id="cmd-div">
      <p>$ kubectl get pods --all-namespaces</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.8</h4>
      <pre>NAMESPACE     NAME                                READY   STATUS    RESTARTS   AGE
kube-system   coredns-86c58d9df4-9vdq6            1/1     Running   0          13m
kube-system   coredns-86c58d9df4-wrhzw            1/1     Running   0          13m
kube-system   etcd-my-node-1                      1/1     Running   0          13m
kube-system   kube-apiserver-my-node-1            1/1     Running   1          14m
kube-system   kube-controller-manager-my-node-1   1/1     Running   0          13m
kube-system   kube-proxy-bsmlw                    1/1     Running   0          13m
kube-system   kube-scheduler-my-node-1            1/1     Running   0          12m
kube-system   weave-net-s8pp6                     2/2     Running   0          66s</pre>
    </div>
    <div id="para-div">
      <p>As is evident from Output.8 above, we see an instance for <span class="bold">API Server</span>, <span class="bold">
        etcd</span>, <span class="bold">Controller Manager</span>, <span class="bold">Scheduler</span>, and <span class="bold">
        Plugin Network</span> (<span class="bold">weave-net</span>) all up and running.</p>
    </div>
    <div id="para-div">
      <p>For this tutorial, we desire that nodes <span class="bold">my-node-2</span> thru <span class="bold">my-node-5</span>
        be the <span class="bold">node</span>s (<span class="bold">minion</span>s) of the <span class="bold">Kubernetes</span>
        cluster. From Output.5 above, we can determine the <span class="hi-green">kubeadm join</span> command to use. For each
        of the nodes <span class="bold">my-node-2</span> thru <span class="bold">my-node-5</span> (in their respective Terminal
        tabs), execute the following command:</p>
    </div>
    <div id="cmd-div">
      <p>$ sudo kubeadm join 192.168.1.201:6443 --token j99kcz.pfwryj2hhhcnmbrb --discovery-token-ca-cert-hash sha256:af11197f74a71890faa275f42f4e2d6c0e9da2fe34bc360d3c21f83994255d76</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.9</h4>
      <pre>[preflight] Running pre-flight checks
[discovery] Trying to connect to API Server "192.168.1.201:6443"
[discovery] Created cluster-info discovery client, requesting info from "https://192.168.1.201:6443"
[discovery] Requesting info from "https://192.168.1.201:6443" again to validate TLS against the pinned public key
[discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server "192.168.1.201:6443"
[discovery] Successfully established connection with API Server "192.168.1.201:6443"
[join] Reading configuration from the cluster...
[join] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'
[kubelet] Downloading configuration for the kubelet from the "kubelet-config-1.13" ConfigMap in the kube-system namespace
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
[kubelet-start] Activating the kubelet service
[tlsbootstrap] Waiting for the kubelet to perform the TLS Bootstrap...
[patchnode] Uploading the CRI Socket information "/var/run/dockershim.sock" to the Node API object "my-node-2" as an annotation

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run 'kubectl get nodes' on the master to see this node join the cluster.</pre>
    </div>
    <div id="para-div">
      <p>To list all the active nodes in the <span class="bold">Kubernetes</span> cluster, execute the following command
        on <span class="bold">my-node-1</span> (after waiting for about 2 to 3 minutes):</p>
    </div>
    <div id="cmd-div">
      <p>$ kubectl get nodes</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.10</h4>
      <pre>NAME        STATUS   ROLES    AGE     VERSION
my-node-1   Ready    master   20m     v1.13.2
my-node-2   Ready    &lt;none&gt;   3m56s   v1.13.2
my-node-3   Ready    &lt;none&gt;   2m39s   v1.13.2
my-node-4   Ready    &lt;none&gt;   2m29s   v1.13.2
my-node-5   Ready    &lt;none&gt;   2m20s   v1.13.2</pre>
    </div>
    <div id="para-div">
      <p>To display detailed information about any <span class="bold">pod</span> (say the <span class="bold">Controller Manager</span>)
        in the <span class="bold">Kubernetes</span> cluster, execute the following command on <span class="bold">my-node-1</span>:</p>
    </div>
    <div id="cmd-div">
      <p>$ kubectl describe pod kube-controller-manager-my-node-1 -n kube-system</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.11</h4>
      <pre>Name:               kube-controller-manager-my-node-1
Namespace:          kube-system
Priority:           2000000000
PriorityClassName:  system-cluster-critical
Node:               my-node-1/192.168.1.201
Start Time:         Sun, 20 Jan 2019 02:16:01 +0000
Labels:             component=kube-controller-manager
                    tier=control-plane
Annotations:        kubernetes.io/config.hash: 6e90d91dfeef5212bdb942dae8aa1816
                    kubernetes.io/config.mirror: 6e90d91dfeef5212bdb942dae8aa1816
                    kubernetes.io/config.seen: 2019-01-20T02:16:00.660478136Z
                    kubernetes.io/config.source: file
                    scheduler.alpha.kubernetes.io/critical-pod: 
Status:             Running
IP:                 192.168.1.201
Containers:
  kube-controller-manager:
    Container ID:  docker://5964861e5ee0fcb489fa915446b7f500c726f7446f6a779ab7b343fe5464a599
    Image:         k8s.gcr.io/kube-controller-manager:v1.13.2
    Image ID:      docker-pullable://k8s.gcr.io/kube-controller-manager@sha256:649c68d0798123187c1b1fbad3f4494372f4a6304e6e19f957a03dd2e59bc858
    Port:          &lt;none&gt;
    Host Port:     &lt;none&gt;
    Command:
      kube-controller-manager
      --address=127.0.0.1
      --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
      --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
      --client-ca-file=/etc/kubernetes/pki/ca.crt
      --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
      --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
      --controllers=*,bootstrapsigner,tokencleaner
      --kubeconfig=/etc/kubernetes/controller-manager.conf
      --leader-elect=true
      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      --root-ca-file=/etc/kubernetes/pki/ca.crt
      --service-account-private-key-file=/etc/kubernetes/pki/sa.key
      --use-service-account-credentials=true
    State:          Running
      Started:      Sun, 20 Jan 2019 02:16:04 +0000
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:        200m
    Liveness:     http-get http://127.0.0.1:10252/healthz delay=15s timeout=15s period=10s #success=1 #failure=8
    Environment:  &lt;none&gt;
    Mounts:
      /etc/ca-certificates from etc-ca-certificates (ro)
      /etc/kubernetes/controller-manager.conf from kubeconfig (ro)
      /etc/kubernetes/pki from k8s-certs (ro)
      /etc/ssl/certs from ca-certs (ro)
      /usr/libexec/kubernetes/kubelet-plugins/volume/exec from flexvolume-dir (rw)
      /usr/local/share/ca-certificates from usr-local-share-ca-certificates (ro)
      /usr/share/ca-certificates from usr-share-ca-certificates (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  ca-certs:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/ssl/certs
    HostPathType:  DirectoryOrCreate
  etc-ca-certificates:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/ca-certificates
    HostPathType:  DirectoryOrCreate
  flexvolume-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /usr/libexec/kubernetes/kubelet-plugins/volume/exec
    HostPathType:  DirectoryOrCreate
  k8s-certs:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/kubernetes/pki
    HostPathType:  DirectoryOrCreate
  kubeconfig:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/kubernetes/controller-manager.conf
    HostPathType:  FileOrCreate
  usr-local-share-ca-certificates:
    Type:          HostPath (bare host directory volume)
    Path:          /usr/local/share/ca-certificates
    HostPathType:  DirectoryOrCreate
  usr-share-ca-certificates:
    Type:          HostPath (bare host directory volume)
    Path:          /usr/share/ca-certificates
    HostPathType:  DirectoryOrCreate
QoS Class:         Burstable
Node-Selectors:    &lt;none&gt;
Tolerations:       :NoExecute
Events:            &lt;none&gt;</pre>
    </div>
    <div id="para-div">
      <p>To list all the application <span class="bold">pod</span>(s) running in <span class="bold">Kubernetes</span> cluster,
        execute the following command on <span class="bold">my-node-1</span>:</p>
    </div>
    <div id="cmd-div">
      <p>$ kubectl get pods</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.12</h4>
      <pre>No resources found.</pre>
    </div>
    <div id="para-div">
      <p>To list all the <span class="bold">service</span>(s) running in <span class="bold">Kubernetes</span> cluster, execute
        the following command on <span class="bold">my-node-1</span>:</p>
    </div>
    <div id="cmd-div">
      <p>$ kubectl get services</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.13</h4>
      <pre>NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   16h</pre>
    </div>
    <div id="para-div">
      <p>To start 2 replicas of the Raspberry Pi compatible <span class="hi-yellow">httpd</span> server in our <span class="bold">
        Kubernetes</span> cluster, execute the following command on <span class="bold">my-node-1</span>:</p>
    </div>
    <div id="cmd-div">
      <p>kubectl run pi-httpd --image=hypriot/rpi-busybox-httpd --port=80 --replicas=2</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.14</h4>
      <pre>kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.
deployment.apps/pi-httpd created</pre>
    </div>
    <div id="para-div">
      <p>Note we named the application deployment as <span class="hi-green">pi-httpd</span>.</p>
    </div>
    <div id="para-div">
      <p>To list all the application deployments running in <span class="bold">Kubernetes</span> cluster, execute the following
        command on <span class="bold">my-node-1</span>:</p>
    </div>
    <div id="cmd-div">
      <p>$ kubectl get deployments pi-httpd -o wide</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.15</h4>
      <pre>NAME       READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS   IMAGES                      SELECTOR
pi-httpd   2/2     2            2           78s     pi-httpd     hypriot/rpi-busybox-httpd   run=pi-httpd</pre>
    </div>
    <div id="para-div">
      <p>To display detailed information about the application deployment <span class="bold">pi-httpd</span>, execute the following
        command on <span class="bold">my-node-1</span>:</p>
    </div>
    <div id="cmd-div">
      <p>$ kubectl describe deployments pi-httpd</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.16</h4>
      <pre>Name:                   pi-httpd
Namespace:              default
CreationTimestamp:      Sun, 20 Jan 2019 19:28:20 +0000
Labels:                 run=pi-httpd
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               run=pi-httpd
Replicas:               2 desired | 2 updated | 2 total | 2 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  run=pi-httpd
  Containers:
   pi-httpd:
    Image:        hypriot/rpi-busybox-httpd
    Port:         80/TCP
    Host Port:    0/TCP
    Environment:  &lt;none&gt;
    Mounts:       &lt;none&gt;
  Volumes:        &lt;none&gt;
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  &lt;none&gt;
NewReplicaSet:   pi-httpd-7ddbfdd6b9 (2/2 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  17m   deployment-controller  Scaled up replica set pi-httpd-7ddbfdd6b9 to 2</pre>
    </div>
    <div id="para-div">
      <p>To list all the application <span class="bold">pod</span>(s) running in <span class="bold">Kubernetes</span> cluster,
        execute the following command on <span class="bold">my-node-1</span>:</p>
    </div>
    <div id="cmd-div">
      <p>$ kubectl get pods -o wide</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.17</h4>
      <pre>NAME                        READY   STATUS    RESTARTS   AGE     IP          NODE        NOMINATED NODE   READINESS GATES
pi-httpd-7ddbfdd6b9-bnlbt   1/1     Running   0          5m45s   10.36.0.1   my-node-4   &lt;none&gt;           &lt;none&gt;
pi-httpd-7ddbfdd6b9-rtgd9   1/1     Running   0          5m45s   10.44.0.1   my-node-2   &lt;none&gt;           &lt;none&gt;</pre>
    </div>
    <div id="para-div">
      <p>From Output.17, we see that our application <span class="bold">pod</span>(s) have been deployed on the nodes
        <span class="bold">my-node-2</span> and <span class="bold">my-node-4</span> of our <span class="bold">Kubernetes</span>
        cluster.</p>
    </div>
    <div id="para-div">
      <p>To display detailed information about the application <span class="bold">pod</span> labeled <span class="bold">pi-httpd</span>,
        execute the following command on <span class="bold">my-node-1</span>:</p>
    </div>
    <div id="cmd-div">
      <p>$ kubectl describe pods pi-httpd</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.18</h4>
      <pre>Name:               pi-httpd-7ddbfdd6b9-bnlbt
Namespace:          default
Priority:           0
PriorityClassName:  &lt;none&gt;
Node:               my-node-4/192.168.1.204
Start Time:         Sun, 20 Jan 2019 19:28:20 +0000
Labels:             pod-template-hash=7ddbfdd6b9
                    run=pi-httpd
Annotations:        &lt;none&gt;
Status:             Running
IP:                 10.36.0.1
Controlled By:      ReplicaSet/pi-httpd-7ddbfdd6b9
Containers:
  pi-httpd:
    Container ID:   docker://fc950488400e0d8f5ff948c40a1e456084a74fae2ad130de9feb79bcbc795c31
    Image:          hypriot/rpi-busybox-httpd
    Image ID:       docker-pullable://hypriot/rpi-busybox-httpd@sha256:c00342f952d97628bf5dda457d3b409c37df687c859df82b9424f61264f54cd1
    Port:           80/TCP
    Host Port:      0/TCP
    State:          Running
      Started:      Sun, 20 Jan 2019 19:28:27 +0000
    Ready:          True
    Restart Count:  0
    Environment:    &lt;none&gt;
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-ps5d4 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  default-token-ps5d4:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-ps5d4
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  &lt;none&gt;
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age   From                Message
  ----    ------     ----  ----                -------
  Normal  Scheduled  10m   default-scheduler   Successfully assigned default/pi-httpd-7ddbfdd6b9-bnlbt to my-node-4
  Normal  Pulling    10m   kubelet, my-node-4  pulling image "hypriot/rpi-busybox-httpd"
  Normal  Pulled     10m   kubelet, my-node-4  Successfully pulled image "hypriot/rpi-busybox-httpd"
  Normal  Created    10m   kubelet, my-node-4  Created container
  Normal  Started    10m   kubelet, my-node-4  Started container

Name:               pi-httpd-7ddbfdd6b9-rtgd9
Namespace:          default
Priority:           0
PriorityClassName:  &lt;none&gt;
Node:               my-node-2/192.168.1.202
Start Time:         Sun, 20 Jan 2019 19:28:20 +0000
Labels:             pod-template-hash=7ddbfdd6b9
                    run=pi-httpd
Annotations:        &lt;none&gt;
Status:             Running
IP:                 10.44.0.1
Controlled By:      ReplicaSet/pi-httpd-7ddbfdd6b9
Containers:
  pi-httpd:
    Container ID:   docker://03723ba3ece33e62e4c4667ab8fd89efe90f718b777ef815a9f5566f392ad9f8
    Image:          hypriot/rpi-busybox-httpd
    Image ID:       docker-pullable://hypriot/rpi-busybox-httpd@sha256:c00342f952d97628bf5dda457d3b409c37df687c859df82b9424f61264f54cd1
    Port:           80/TCP
    Host Port:      0/TCP
    State:          Running
      Started:      Sun, 20 Jan 2019 19:28:27 +0000
    Ready:          True
    Restart Count:  0
    Environment:    &lt;none&gt;
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-ps5d4 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  default-token-ps5d4:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-ps5d4
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  &lt;none&gt;
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age   From                Message
  ----    ------     ----  ----                -------
  Normal  Scheduled  10m   default-scheduler   Successfully assigned default/pi-httpd-7ddbfdd6b9-rtgd9 to my-node-2
  Normal  Pulling    10m   kubelet, my-node-2  pulling image "hypriot/rpi-busybox-httpd"
  Normal  Pulled     10m   kubelet, my-node-2  Successfully pulled image "hypriot/rpi-busybox-httpd"
  Normal  Created    10m   kubelet, my-node-2  Created container
  Normal  Started    10m   kubelet, my-node-2  Started container</pre>
    </div>
    <div id="para-div">
      <p>From the Output.18 above, we see the <span class="bold">pod</span>s are running on nodes <span class="bold">
        my-node-2</span> and <span class="bold">my-node-4</span> with unique ip-addresses <span class="bold">10.44.0.1</span>
        and <span class="bold">10.36.0.1</span> respectively.</p>
    </div>
    <div id="para-div">
      <p>To list all the <span class="bold">replicaset</span>s for our cluster, execute the following command on
        <span class="bold">my-node-1</span>:</p>
    </div>
    <div id="cmd-div">
      <p>$ kubectl get replicasets -o wide</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.19</h4>
      <pre>NAME                  DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES                      SELECTOR
pi-httpd-7ddbfdd6b9   2         2         2       18m   pi-httpd     hypriot/rpi-busybox-httpd   pod-template-hash=7ddbfdd6b9,run=pi-httpd</pre>
    </div>
    <div id="para-div">
      <p>To display detailed information about the <span class="bold">replicaset</span>s for our cluster, execute the following command
        on <span class="bold">my-node-1</span>:</p>
    </div>
    <div id="cmd-div">
      <p>$ kubectl describe replicasets</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.20</h4>
      <pre>Name:           pi-httpd-7ddbfdd6b9
Namespace:      default
Selector:       pod-template-hash=7ddbfdd6b9,run=pi-httpd
Labels:         pod-template-hash=7ddbfdd6b9
                run=pi-httpd
Annotations:    deployment.kubernetes.io/desired-replicas: 2
                deployment.kubernetes.io/max-replicas: 3
                deployment.kubernetes.io/revision: 1
Controlled By:  Deployment/pi-httpd
Replicas:       2 current / 2 desired
Pods Status:    2 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:  pod-template-hash=7ddbfdd6b9
           run=pi-httpd
  Containers:
   pi-httpd:
    Image:        hypriot/rpi-busybox-httpd
    Port:         80/TCP
    Host Port:    0/TCP
    Environment:  &lt;none&gt;
    Mounts:       &lt;none&gt;
  Volumes:        &lt;none&gt;
Events:
  Type    Reason            Age   From                   Message
  ----    ------            ----  ----                   -------
  Normal  SuccessfulCreate  19m   replicaset-controller  Created pod: pi-httpd-7ddbfdd6b9-rtgd9
  Normal  SuccessfulCreate  19m   replicaset-controller  Created pod: pi-httpd-7ddbfdd6b9-bnlbt</pre>
    </div>
    <div id="para-div">
      <p>To create a <span class="bold">service</span> endpoint (virtual ip-address:port) for the deployed application
        labeled <span class="bold">pi-httpd</span>, so that the application can be accessed from any node on the cluster,
        execute the following command on <span class="bold">my-node-1</span>:</p>
    </div>
    <div id="cmd-div">
      <p>$ kubectl expose deployment pi-httpd --port=8080 --target-port=80 --type=NodePort</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.21</h4>
      <pre>service/pi-httpd exposed</pre>
    </div>
    <div id="para-div">
      <p>With the above command, <span class="bold">kube-proxy</span> watches the <span class="bold">master</span> (via the
        <span class="bold">API Server</span>) for any <span class="bold">service</span> endpoint creations or modifications
        and creates a route from the <span class="bold">service</span> endpoint ip-address:port to map to the list of
        ip-address:port of the <span class="bold">pod</span> instances deployed for the application.</p>
    </div>
    <div id="para-div">
      <p>To list all the <span class="bold">service</span>(s) running in <span class="bold">Kubernetes</span> cluster, execute
        the following command on <span class="bold">my-node-1</span>:</p>
    </div>
    <div id="cmd-div">
      <p>$ kubectl get services</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.22</h4>
      <pre>NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
kubernetes   ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP          18h
pi-httpd     NodePort    10.111.215.159   &lt;none&gt;        8080:31275/TCP   62s</pre>
    </div>
    <div id="para-div">
      <p>From the Output.22 above, we see the application <span class="bold">pi-httpd</span> can be accessed from anywhere in
        the cluster via the ip-address <span class="hi-green">10.111.215.159</span> and port <span class="hi-green">8080</span>.</p>
    </div>
    <div id="para-div">
      <p>To display detailed information about the <span class="bold">service</span> endpoint labeled <span class="bold">
        pi-httpd</span>, execute the following command on <span class="bold">my-node-1</span>:</p>
    </div>
    <div id="cmd-div">
      <p>$ kubectl describe service pi-httpd</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.23</h4>
      <pre>Name:                     pi-httpd
Namespace:                default
Labels:                   run=pi-httpd
Annotations:              &lt;none&gt;
Selector:                 run=pi-httpd
Type:                     NodePort
IP:                       10.111.215.159
Port:                     &lt;unset&gt;  8080/TCP
TargetPort:               80/TCP
NodePort:                 &lt;unset&gt;  31275/TCP
Endpoints:                10.36.0.1:80,10.44.0.1:80
Session Affinity:         None
External Traffic Policy:  Cluster
Events:                   &lt;none&gt;</pre>
    </div>
    <div id="para-div">
      <p>From any of the nodes my-node-&lt;N&gt;, where &lt;N&gt; ranges from 1 thru 5, execute the following command:</p>
    </div>
    <div id="cmd-div">
      <p>$ curl http://10.111.215.159:8080</p>
    </div>
    <div id="para-div">
      <p>The following would be a typical output:</p>
    </div>
    <div id="out-div">
      <h4>Output.24</h4>
      <pre>&lt;html&gt;
&lt;head>&lt;title&gt;Pi armed with Docker by Hypriot&lt;/title&gt;
  &lt;body style="width: 100%; background-color: black;"&gt;
    &lt;div id="main" style="margin: 100px auto 0 auto; width: 800px;"&gt;
      &lt;img src="pi_armed_with_docker.jpg" alt="pi armed with docker" style="width: 800px"&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;</pre>
    </div>
    <div id="para-div">
      <p>With this, we conclude the basic exercises we performed on our <span class="bold">Kubernetes</span> cluster.</p>
    </div>
    <div id="section-div">
      <p>References</p>
    </div>
    <div id="para-div">
      <p><a href="https://kubernetes.io/docs/home/?path=browse" target="_blank"><span class="bold">Official Kubernetes Documentation</span></a></p>
    </div>
    <br/>
    <hr class="line-hr" />
    <div>
      <a id="footer-a" href="https://polarsparc.github.io/">&copy;&nbsp;PolarSPARC</a>
    </div>
  </body>
</html>
