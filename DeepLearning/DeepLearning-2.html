<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
  <head>
    <meta http-equiv="content-type" content="application/xhtml+xml; charset=windows-1252" />
    <meta name="author" content="Bhaskar.S">
    <meta name="description" content="Introduction to Deep Learning - Part 2">
    <meta name="subject" content="Introduction to Deep Learning - Part 2">
    <meta name="keywords" content="artificial-intelligence, deep-learning, neural-network">
    <meta name="robots" content="index, follow">
    <meta name="googlebot" content="index, follow">
    <title>Introduction to Deep Learning - Part 2</title>
    <link href="../css/polarsparc-v2.4.css" type="text/css" rel="stylesheet" />
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script>
      MathJax = {
        tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
      };
    </script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.0.5/es5/tex-chtml.js"></script>
    <!-- script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script -->
  </head>
  <body>
    <br/>
    <table borber="0">
      <tr>
        <td valign="bottom"><span id="gen-home"></span></td>
        <td valign="bottom"><span id="gen-home-a"><a id="gen-home-a" href="https://polarsparc.github.io/">PolarSPARC</a></span></td>
      </tr>
    </table>
    <br/>
    <div id="gen-title-div">
      <p>Introduction to Deep Learning - Part 2</p>
    </div>
    <br />
    <table id="gen-ad-table">
      <tbody>
        <tr>
          <td class="author-td">Bhaskar S</td>
          <td class="date-td">05/29/2023</td>
        </tr>
      </tbody>
    </table>
    <hr class="gen-line-hr" />
    <br/>
    <div id="gen-step-div">
      <p>Introduction</p>
    </div>
    <br/>
    <div id="para-div">
      <p>In <a href="https://polarsparc.github.io/DeepLearning/DeepLearning-1.html" target="_blank"><span class="bold">Introduction
        to Deep Learning - Part 1</span></a> of this series, we introduced the concept of a <span class="bold">perceptron</span>,
        followed by the concept of a <span class="bold">neural network</span>, and finally the concept of an <span class="bold">
        activation function</span>.</p>
      <p>In this article, we will continue the journey, diving deeper into the core of <span class="bold">neural network</span> to
        get a better intuition of its inner workings.</p>
    </div>
    <br/>
    <div id="gen-step-div">
      <p>Feed Forward Network</p>
    </div>
    <br/>
    <div id="para-div">
      <p>From the previous article, we know that a <span class="bold">neural network</span> is an artificial equivalent of a human
        brain, with a complex network <span class="bold">perceptron</span>s, arranged in layers.</p>
    </div>
    <div id="para-div">
      <p>The following illustration depicts the structure of an artificial <span class="bold">neural network</span>:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Feed Forward Network" class="gen-img-cls" src="./images/deep-learning-08.png">
        <div class="gen-img-cap">Figure.1</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>With this type of <span class="bold">neural network</span> structure, the input data moves from the <span class="bold">
        input layer</span> to one or more <span class="bold">hidden layer</span>(s), before coming off the <span class="bold">output
        layer</span> as a final prediction. In other words, the input flows forward without any feedback cycle between the nodes
        of the <span class="bold">neural network</span>.</p>
    </div>
    <div id="para-div">
      <p>At this point, one may have a question - how does one begin to train a <span class="bold">neural network</span> model to
        be effective at future predictions ???</p>
      <p>For that one needs a large amount of training data with the actual predictions tagged.</p>
    </div>
    <div id="para-div">
      <p>The following are the high-level steps to train a <span class="bold">neural network</span> model:</p>
    </div>
    <div id="para-div">
      <ul id="gen-sqr-ul">
        <li>
          <p>Initialize the <span class="bold">weight</span> and the <span class="bold">bias</span> (<span class="bold">parameter
            </span>) for each of the connections between the nodes of the <span class="bold">neural network</span> to some random
            value</p>
        </li>
        <li>
          <p>Feed each sample from the training dataset to the <span class="bold">neural network</span> model and measure the error
            made by the model in making the prediction versus the actual prediction</p>
        </li>
        <li>
          <p>Compute the average prediction error for the entire training dataset</p>
        </li>
        <li>
          <p>If the average prediction error is above some threshold value, adjust the <span class="bold">weight</span>s and the
            <span class="bold">bias</span>es of the <span class="bold">neural network</span> so as to <span class="underbold">
            MINIMIZE</span> the prediction error of the model and repeat the training process again</p>
        </li>
      </ul>
    </div>
    <div id="para-div">
      <p>What we have outlined above are a very high-level set of steps to train a <span class="bold">neural network</span> model.
        In the following paragraphs we will zoom in to the details.</p>
    </div>
    <br/>
    <div id="gen-step-div">
      <p>Loss Function</p>
    </div>
    <br/>
    <div id="para-div">
      <p>As a <span class="bold">neural network</span> makes a prediction for a given input, we need a way to measure the deviation
        (or the prediction error) from the actual target prediction. The numerical value of the deviation (or the prediction error)
        is often referred to as a <span class="hi-yellow">Loss</span> or a <span class="hi-yellow">Cost</span>.</p>
      <p>The function used to compute the prediction error is often referred to as the <span class="hi-yellow">Loss Function</span>
        or a <span class="hi-yellow">Cost Function</span>.</p>
      <p>There are several types of <span class="bold">loss function</span>s to choose from based on the type of the problem the
        <span class="bold">neural network</span> model is trying to solve for, such as, a <span class="bold">classification</span>
        or a <span class="bold">regression</span> problem.</p>
    </div>
    <div id="para-div">
      <p>For this article, we will use the <span class="hi-yellow">Mean Sqaured Error</span> as the <span class="bold">loss function
        </span> $L(x, W, b)$, which is defined as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$L(x, W, b) = (\sigma(x, W, b) - y)^2$</p>
      <p>where, $x$ is the input, $W$ is the <span class="bold">weights</span>, $b$ is the <span class="bold">biases</span>, $\sigma$
        is the <span class="bold">activation function</span> with its output as the predicted value, and $y$ is the actual target
        prediction value.</p>
    </div>
    <br/>
    <div id="gen-step-div">
      <p>Gradient Descent</p>
    </div>
    <br/>
    <div id="para-div">
      <p>As indicated in the high-level steps above, the main idea is to tune the <span class="bold">neural network</span> model
        by <span class="underbold">MINIMIZING</span> the <span class="bold">loss</span> of the model. This is where the concept of
        <span class="hi-yellow">Gradient Descent</span> comes into play.</p>
    </div>
    <div id="para-div">
      <p>Now, the question one would have is - how does one minimize the error from a function ???</p>
    </div>
    <div id="para-div">
      <p>Well, the answer to that question would be - <a href="https://polarsparc.github.io/Mathematics/Calculus-2.html" target=
        "_blank"><span class="hi-yellow">Derivatives</span></a> from <span class="bold">Calculus</span> to the rescue !!!</p>
      <p>The <span class="underbold">MINIMUM</span> of a function occurs when the <span class="bold">derivative</span> of that
        function is <span class="underbold">ZERO</span>.</p>
    </div>
    <div id="para-div">
      <p>Let us look at an example to get a better understanding of this concept.</p>
      <p>Let $y$ be a function of $x$ as defined below:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$y = x^2 - 3.x + 1$</p>
      <p>Then, the <span class="bold">derivative</span> of the function $y$ with respect to $x$ is as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\frac{dy}{dx}}\normalsize{= 2.x - 3}$</p>
    </div>
    <div id="para-div">
      <p>The following illustration shows the plots for $y$ and its <span class="bold">derivative</span> $\Large{\frac{dy}{dx}}$:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Function Minimum" class="gen-img-cls" src="./images/deep-learning-15.png">
        <div class="gen-img-cap">Figure.2</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>As is evident from the plot in Figure.2 above, the function minimum (<span class="hi-green">green dot</span>) occurs when
        its <span class="bold">derivative</span> $\Large{\frac{dy}{dx}}$ is zero (<span class="hi-red">red dot</span>).</p>
    </div>
    <div id="para-div">
      <p>It is easy for humans to look at the plot in Figure.2 above and deduce where the the function minimum occurs. How about
        computers ???</p>
      <p>This is where the algorithm for <span class="bold">gradient descent</span> comes in handy.</p>
    </div>
    <div id="para-div">
      <p>The following are the high-level steps for <span class="bold">gradient descent</span>:</p>
    </div>
    <div id="para-div">
      <ul id="gen-sqr-ul">
        <li>
          <p>Initialize the <span class="hi-blue">Maximum Number of Iterations</span> (also called <span class="hi-yellow">Epochs</span>)
            and the <span class="hi-blue">Learning Rate</span> (denoted using the symbol $\eta$)</p>
        </li>
        <li>
          <p>Initialize the minimum value ($min$) of a function to a random value</p>
        </li>
        <li>
          <p>For each iteration upto the maximum number of iterations (epochs), perform the following steps:</p>
          <ul id="gen-sqr-ul">
            <li>Compute the slope or the gradient ($G$) of the function using derivative at $min$</li>
            <li>$min = min - \eta . G$</li>
          </ul>
        </li>
        <li>
          <p>The final minimum value ($min$) will be an approximation for the minimum of the function</p>
        </li>
      </ul>
    </div>
    <div id="para-div">
      <p>The following illustration shows the points traversed by the <span class="bold">gradient descent</span> algorithm before
        the final stop (function minimum) for two cases - one from the left and one from the right:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Gradient Descent" class="gen-img-cls" src="./images/deep-learning-16.png">
        <div class="gen-img-cap">Figure.3</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>Note that the final function minimum will be a close approximation, but <span class="underbold">NOT</span> an exact value.</p>
    </div>
    <div id="para-div">
      <p>The <span class="bold">gradient descent</span> algorithm is akin to the approach taken by a person, who wants to reach the
        the valley at the bottom of a mountain as shown in the illustration below:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Mountain Descent" class="gen-img-cls" src="./images/deep-learning-17.png">
        <div class="gen-img-cap">Figure.4</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The person moves forward at each step when the slope is downward (hence descent).</p>
    </div>
    <div id="para-div">
      <p>The <span class="hi-yellow">Learning Rate</span> controls how quickly the algorithm will learn about the function minimum.
        If the value is <span class="underbold">SMALL</span>, the learning will take a longer time and on the other hand, if the
        value is <span class="underbold">LARGE</span>, the learning may result in a sub-optimal solution (wrong minimum). One needs
        to tune the <span class="bold">learning rate</span> for an optimal value. The value of <span class="underbold">0.01</span>
        is typically a good start.</p>
    </div>
    <div id="para-div">
      <p>The plot of the function $y = x^2 - 3.x + 1$ as shown in the Figure.2 above was a simple polynomial of $2^{nd}$ degree and
        had a single minimum, which was easy to identify.</p>
    </div>
    <div id="para-div">
      <p>Now, let us look at a more complex polynomial function of the $4^{th}$ degree. The following illustration shows plot for
        the polynomial function $y = x^4 - 3.x^2 + x - 2$:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="4th Degree Function" class="gen-img-cls" src="./images/deep-learning-18.png">
        <div class="gen-img-cap">Figure.5</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>Notice the plot in the Figure.5 above has two minimum points - the one with the <span class="hi-red">red dot</span> and the
        other with the <span class="hi-green">green dot</span>. The one with the <span class="hi-red">red dot</span> is referred to
        as the <span class="underbold">GLOBAL MINIMUM</span>, while the one with the <span class="hi-green">green dot</span> is known
        as the <span class="underbold">LOCAL MINIMUM</span>.</p>
    </div>
    <div id="para-div">
      <p>The <span class="bold">gradient descent</span> algorithm can get into an interesting situation and predict very different
        function minimum based on where the initial random value for $min$ falls - <span class="hi-green">green dot</span> if the
        $min$ value is in the interval $(0.2, 2.0)$ and <span class="hi-red">red dot</span> if the $min$ value is in the interval
        $(0.0, -2.0)$.</p>
    </div>
    <div id="para-div">
      <p>Now for a more interesting case, consider the polynomial function $2.sin(x) - 3.cos(\sqrt{5}.x)$. The following illustration
        shows plot for this trigonometric function:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Trigonometric Function" class="gen-img-cls" src="./images/deep-learning-19.png">
        <div class="gen-img-cap">Figure.6</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>As is evident from the plot in the Figure.6 above, there are more than two minimums. The lowest minimum is referred to as
        the <span class="underbold">GLOBAL MINIMUM</span> identified by the <span class="hi-red">red dot</span>, while the remaining
        ones are known as the <span class="underbold">LOCAL MINIMUM</span> marked by the <span class="hi-green">green dot</span>s.</p>
      <p>When there are many <span class="underbold">LOCAL MINIMUM</span>s, sometimes the <span class="bold">gradient descent</span>
        algorithm may identify a sub-optimal <span class="underbold">LOCAL MINIMUM</span>.</p>
    </div>
    <div id="para-div">
      <p>Until this point, we looked at functions with one variable $x$ in a 2-dimensional space. Let us now look at functions in a
        3-dimensional space with two variables.</p>
    </div>
    <div id="para-div">
      <p>The following illustration shows the 3-dimensional plot for the function $y = x_1^2 + x_2^2 - 2$ with two variable $x_1$
        and $x_2$, with a view from a top angle:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="3D One Minima" class="gen-img-cls" src="./images/deep-learning-20.png">
        <div class="gen-img-cap">Figure.7</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The <span class="hi-red">red dot</span> is the <span class="underbold">MINIMUM</span> point, which is easy to visualize from
        the 3-dimensional plot above in Figure.7.</p>
    </div>
    <div id="para-div">
      <p>Now, the question one would have is - how does one find the <span class="underbold">LOCAL MINIMUM</span> for a function with
        more than one variable (<span class="hi-yellow">Multivariate Function</span>) as in the above case ???</p>
    </div>
    <div id="para-div">
      <p>Once again, <span class="bold">Calculus</span> to the rescue with a small twist - we make use of <span class="hi-yellow">Partial
        Derivatives</span> !!!</p>
      <p>With <span class="bold">partial derivative</span>s, one would find the <span class="bold">derivative</span> of the multivariate
        function with respect to each of the variables, treating the remaining variables as constants. Therefore, the <span class="bold">
        gradient</span> of the multivariate function, denoted as $\nabla$, is nothing more than a vector of all the <span class="bold">
        partial derivative</span>s.</p>
      <p>As as example, for our multivariate function (from the above) with two variables $x_1$ and $x_2$, its <span class="bold">
        gradient</span> is the vector $\nabla = [\Large{\frac{\partial{f}}{\partial{x_1}}}$$\:\Large{\frac{\partial{f}}{\partial{x_2}}}$
        $] = [2.x_1\:2.x_2]$.</p>
      <p>The <span class="underbold">MINIMUM</span> of the multivariate function occurs when the <span class="bold">derivative</span>
        of that function is equal to a <span class="underbold">ZERO VECTOR</span> (a vector with <span class="bold">ZERO</span>s).</p>
      <p>For our multivariate function, the minimum is computed as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$[2.x_1\:2.x_2] = [0\:0]$</p>
      <p>That is:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$[x_1\:x_2] = [0\:0]$</p>
    </div>
    <div id="para-div">
      <p>With that, the following are the high-level steps of the <span class="bold">gradient descent</span> algorithm for a higher
        dimensional space:</p>
    </div>
    <div id="para-div">
      <ul id="gen-sqr-ul">
        <li>
          <p>Initialize the <span class="hi-blue">Maximum Number of Iterations</span> (also called <span class="hi-yellow">Epochs</span>)
            and the <span class="hi-blue">Learning Rate</span> (denoted using the symbol $\eta$)</p>
        </li>
        <li>
          <p>Initialize a vector (of size equal to the number of variables in the multivariate function) with random minimum values
            ($min$)</p>
        </li>
        <li>
          <p>For each iteration upto the maximum number of iterations (epochs), perform the following steps:</p>
          <ul id="gen-sqr-ul">
            <li>Compute the vector of <span class="bold">partial derivative</span>s $\nabla G$ for the multivariate function at $min$</li>
            <li>$min = min - \eta . \nabla G$</li>
          </ul>
        </li>
        <li>
          <p>The final minimum vector ($min$) will be an approximation for the minimum of the multivariate function</p>
        </li>
      </ul>
    </div>
    <br/>
    <div id="gen-step-div">
      <p>Backpropagation</p>
    </div>
    <br/>
    <div id="para-div">
      <p>Now that we understand the <span class="bold">loss function</span> and an approach to minimize a function using <span class=
        "bold">gradient descent</span>, we are ready to dive into the details on how to train a <span class="bold">neural network</span>
        for optimal performance by adjusting its <span class="bold">weight</span>s and <span class="bold">bias</span>es.</p>
    </div>
    <div id="para-div">
      <p>Let us consider a very simple <span class="bold">neural network</span> with just an <span class="bold">input layer</span>
        and an <span class="bold">output layer</span> with no <span class="bold">hidden layer</span>(s). In addition, let will set
        the <span class="bold">bias</span> to <span class="bold">ZERO</span> and use an <span class="underbold">IDENTITY</span>
        <span class="bold">activation function</span>.</p>
    </div>
    <div id="para-div">
      <p>The following illustration depicts the simple <span class="bold">neural network</span> with the sample data below:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Simple Network" class="gen-img-cls" src="./images/deep-learning-21.png">
        <div class="gen-img-cap">Figure.8</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>We know the <span class="bold">identity activation function</span> $\sigma$ is as given below:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\sigma = w.x + b$ $..... \color{red}\textbf{(1)}$</p>
      <p>where $w$ is the <span class="bold">weight</span> and $b$ is the <span class="bold">bias</span>.</p>
      <p>Since the <span class="bold">bias</span> $b$ is equal to $0$, the equation $\color{red}\textbf{(1)}$ becomes:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\sigma = w.x$ $..... \color{red}\textbf{(2)}$</p>
      <p>Also, we know the <span class="bold">loss function</span> $L$ is as given below:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$L = (\sigma - y)^2$ $..... \color{red}\textbf{(3)}$</p>
      <p>As we know from <span class="bold">gradient descent</span>, to minimize the <span class="bold">loss function</span>, we
        need to find its <span class="bold">gradient</span> $\nabla L$.</p>
      <p>In other words, given that $L$ is dependent on $w$, we need to compute the <span class="bold">partial derivative</span>
        of $L$ with respect to $w$. Note that $L$ is dependent on $\sigma$ (see equation $\color{red}\textbf{(3)}$), which in-turn
        is dependent on $w$ (see equation $\color{red}\textbf{(2)}$). Therefore, we will need to apply the <span class="hi-yellow">
        Chain Rule</span> to find the <span class="bold">partial derivative</span> of $L$ with respect to $w$.</p>
      <p>That is:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\nabla L = \Large{\frac{\partial L}{\partial w}}$ $=\Large{\frac{\partial L}{\partial \sigma}}$
        $.\Large{\frac{\partial \sigma}{\partial w}}$ $= 2.(\sigma - y).x = 2.(w.x - y).x$ $..... \color{red}\textbf{(4)}$</p>
    </div>
    <div id="para-div">
      <p>To minimize the <span class="bold">loss</span> from the <span class="bold">neural network</span> model, we will need to
        tweak or adjust the <span class="bold">weight</span> $w$ using <span class="bold">gradient descent</span>.</p>
      <p>In other words:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$w = w - \eta.\nabla L$ $..... \color{red}\textbf{(5)}$</p>
      <p>where $\eta$ is the <span class="bold">learning rate</span> and let it be set to $0.05$.</p>
    </div>
    <div id="para-div">
      <p>Assume the initial random value for $w = 1.2$. Also, let us use $x = 2.0$ as the training data. The following computations
        demonstrate the iterative training process of our simple <span class="bold">neural network</span> model.</p>
    </div>
    <div id="para-div">
      <p><span class="bold">Iteration - 1</span>:</p>
      <ul id="gen-sqr-ul">
        <li>
          <p>With $x = 2.0$ and $w = 1.2$, we find the loss $L = (1.2 * 2.0 - 1.0)^2 = 1.96$ using equation $\color{red}\textbf{(3)}$</p>
        </li>
        <li>
          <p>To minimize the loss, we find the gradient $\nabla L = 2 * (1.2 * 2.0 - 1.0) * 2.0 = 5.6$ using equation
            $\color{red}\textbf{(4)}$</p>
        </li>
        <li>
          <p>Given $\eta = 0.05$, we adjust the <span class="bold">weight</span> $w = 1.2 - 0.05 * 5.6 = 0.92$ using equation
            $\color{red}\textbf{(5)}$</p>
        </li>
      </ul>
    </div>
    <div id="para-div">
      <p><span class="bold">Iteration - 2</span>:</p>
      <ul id="gen-sqr-ul">
        <li>
          <p>With $x = 2.0$ and $w = 0.92$, we find the loss $L = (0.92 * 2.0 - 1.0)^2 = 0.7$ using equation $\color{red}\textbf{(3)}$</p>
        </li>
        <li>
          <p>To minimize the loss, we find the gradient $\nabla L = 2 * (0.92 * 2.0 - 1.0) * 2.0 = 3.36$ using equation
            $\color{red}\textbf{(4)}$</p>
        </li>
        <li>
          <p>Given $\eta = 0.05$, we adjust the <span class="bold">weight</span> $w = 0.92 - 0.05 * 3.36 = 0.75$ using equation
            $\color{red}\textbf{(5)}$</p>
        </li>
      </ul>
    </div>
    <div id="para-div">
      <p><span class="bold">Iteration - 3</span>:</p>
      <ul id="gen-sqr-ul">
        <li>
          <p>With $x = 2.0$ and $w = 0.75$, we find the loss $L = (0.75 * 2.0 - 1.0)^2 = 0.25$ using equation $\color{red}\textbf{(3)}$</p>
        </li>
        <li>
          <p>To minimize the loss, we find the gradient $\nabla L = 2 * (0.75 * 2.0 - 1.0) * 2.0 = 2.02$ using equation
            $\color{red}\textbf{(4)}$</p>
        </li>
        <li>
          <p>Given $\eta = 0.05$, we adjust the <span class="bold">weight</span> $w = 0.75 - 0.05 * 2.02 = 0.65$ using equation
            $\color{red}\textbf{(5)}$</p>
        </li>
      </ul>
    </div>
    <div id="para-div">
      <p>Continuing this iterative process, the following illustration shows the values at each iteration:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Iterative Training" class="gen-img-cls" src="./images/deep-learning-22.png">
        <div class="gen-img-cap">Figure.9</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>As is evident, the gradient $\nabla L$ is approaching $0.0$ and the value for $w$ is converging to $0.5$, which is the
        correct value for the <span class="bold">weight</span> $w$ of our simple <span class="bold">neural network</span> model.</p>
    </div>
    <div id="para-div">
      <p>Now that we have a better understanding of how a very simple <span class="bold">neural network</span> works, let us build
        on it for a better intuition on how to compute the <span class="bold">gradient</span>s for the various <span class="bold">
        weight</span>s of the <span class="bold">neural network</span>.</p>
    </div>
    <div id="para-div">
      <p>The following illustration depicts another simple <span class="bold">neural network</span> with a <span class="bold">hidden
        layer</span>:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="With Hidden Layer" class="gen-img-cls" src="./images/deep-learning-23.png">
        <div class="gen-img-cap">Figure.9</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The two <span class="bold">weight</span>s of the <span class="bold">neural network</span> are $w_0$ and $w_1$ respectively.
        Also, we will set the two <span class="bold">bias</span>es ($b_0$ and $b_1$) to <span class="bold">ZERO</span>. Note that we
        represent the two <span class="bold">activation function</span>s as $a_0$ and $a_1$ for simplicity.</p>
    </div>
    <div id="para-div">
      <p>The following illustration depicts the above <span class="bold">neural network</span> as a computational graph:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Computational Graph" class="gen-img-cls" src="./images/deep-learning-24.png">
        <div class="gen-img-cap">Figure.10</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The above computational graph makes it easy to understand the various <span class="bold">gradient</span>s.</p>
      <p>For example, to find the <span class="bold">gradient</span> of the <span class="bold">loss function</span> $L$ with respect
        to the <span class="bold">weight</span> $w_1$, we use the <span class="bold">chain rule</span> as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\frac{\partial L}{\partial w_1}}$ $= \Large{\frac{\partial L}{\partial a_1}}$ $.\Large{\frac
        {\partial a_1}{\partial w_1}}$</p>
    </div>
    <div id="para-div">
      <p>The above <span class="bold">chain rule</span> is depicted in the following illustration:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Chain Rule W1" class="gen-img-cls" src="./images/deep-learning-25.png">
        <div class="gen-img-cap">Figure.11</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>Similarly, to find the <span class="bold">gradient</span> of the <span class="bold">loss function</span> $L$ with respect to
        the <span class="bold">weight</span> $w_0$, we use the <span class="bold">chain rule</span> as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\frac{\partial L}{\partial w_0}}$ $= \Large{\frac{\partial L}{\partial a_1}}$ $.\Large{\frac
        {\partial a_1}{\partial a_0}}$ $.\Large{\frac{\partial a_0}{\partial w_0}}$</p>
    </div>
    <div id="para-div">
      <p>The above <span class="bold">chain rule</span> is depicted in the following illustration:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Chain Rule W0" class="gen-img-cls" src="./images/deep-learning-26.png">
        <div class="gen-img-cap">Figure.12</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>With all the basics firmed up, it becomes evident that the <span class="bold">gradient</span>s from a layer be propagated
        backwards to the previous layer(s) in order to efficiently adjust the <span class="bold">weight</span>s of the <span class=
        "bold">neural network</span>. Hence the approach is known as <span class="hi-yellow">Backpropagation</span>.</p>
    </div>
    <div id="para-div">
      <p>For the final home stretch, let us consider the following illustration of the <span class="bold">neural network</span> with
        an <span class="bold">input layer</span> with two inputs, two <span class="bold">hidden layer</span>s each consisting of two
        <span class="bold">neuron</span>s, and an <span class="bold">output layer</span> with two outputs:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Final Network" class="gen-img-cls" src="./images/deep-learning-27.png">
        <div class="gen-img-cap">Figure.13</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The illustration above in Figure.13 may appear ver complex with lots of letters with exponent and subscript numbers. Let us
        first break that down as follows:</p>
    </div>
    <div id="para-div">
      <ul id="gen-sqr-ul">
        <li>
          <p>The number in the exponent such as $w^l$ represents the layer number $l$</p>
        </li>
        <li>
          <p>The two number subscript such as $w_{j, k}$ represent the input $j$ and the neuron $k$</p>
        </li>
        <li>
          <p>The letter $w^l_{j, k}$ represents the <span class="bold">weight</span> associated with the input $j$ to neuron $k$ in
            the layer $l$</p>
        </li>
        <li>
          <p>The letter $b^l_k$ represents the <span class="bold">bias</span> to neuron $k$ in the layer $l$</p>
        </li>
        <li>
          <p>The letter $z^l_k$ represents the input computation $\sum w^l_{j, k}.x^l_j + b^l_k$ going into neuron $k$</p>
        </li>
        <li>
          <p>The letter $a^l_k$ represents the output from the <span class="bold">activation function</span> of neuron $k$</p>
        </li>
      </ul>
    </div>
    <div id="para-div">
      <p>Let us consider the output from the first neuron in the <span class="bold">output layer</span> as highlighted in Figure.13
        above (in <span class="hi-green">green</span>).</p>
      <p>To find the influence of the <span class="bold">weight</span> $w^3_{1,1}$ on the <span class="bold">loss</span> $L$, we have
        to look at the following computational graph:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Compute Graph W311" class="gen-img-cls" src="./images/deep-learning-28.png">
        <div class="gen-img-cap">Figure.14</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The <span class="bold">gradient</span> of the <span class="bold">loss</span> $L$ with respect to the <span class="bold">
        weight</span> $w^3_{1,1}$ can be computed using the <span class="bold">chain rule</span> as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\frac{\partial L}{\partial w^3_{1,1}}}$ $= \Large{\frac{\partial L}{\partial a^3_1}}$
        $.\Large{\frac{\partial a^3_1}{\partial z^3_1}}$ $.\Large{\frac{\partial z^3_1}{\partial w^3_{1,1}}}$ $..... \color{red}
        \textbf{(6)}$</p>
    </div>
    <div id="para-div">
      <p>To find the influence of the <span class="bold">weight</span> $w^2_{2,1}$ on the <span class="bold">loss</span> $L$, we have
        to look at the following computational graph:</p>
    </div>
    <br/>
    <div id="para-div">
      <div id="gen-img-outer-div">
        <img alt="Compute Graph W221" class="gen-img-cls" src="./images/deep-learning-29.png">
        <div class="gen-img-cap">Figure.15</div>
      </div>
    </div>
    <br/>
    <div id="para-div">
      <p>The <span class="bold">gradient</span> of the <span class="bold">loss</span> $L$ with respect to the <span class="bold">
        weight</span> $w^2_{2,1}$ can be computed using the <span class="bold">chain rule</span> as follows:</p>
      <p>&nbsp;&nbsp;&nbsp;&nbsp;$\Large{\frac{\partial L}{\partial w^2_{2,1}}}$ $= \Large{\frac{\partial L}{\partial a^3_1}}$
        $.\Large{\frac{\partial a^3_1}{\partial z^3_1}}$ $.\Large{\frac{\partial z^3_1}{\partial a^2_1}}$ $.\Large{\frac{\partial
        a^2_1}{\partial z^2_1}}$ $.\Large{\frac{\partial z^2_1}{\partial w^2_{2,1}}}$ $..... \color{red}\textbf{(7)}$</p>
    </div>
    <div id="para-div">
      <p>Some of the <span class="bold">gradient</span>s in equation $\color{red}\textbf{(7)}$ are already computed in the equation
        $\color{red}\textbf{(6)}$ and can be propagated backwards for more efficient computation. This pattern repeats itself for
        the other <span class="bold">weight</span>s and <span class="bold">bias</span>es as well.</p>
    </div>
    <br/>
    <div id="section-div">
      <p>References</p>
    </div>
    <div id="para-div">
      <p><a href="https://polarsparc.github.io/DeepLearning/DeepLearning-1.html" target="_blank"><span class="bold">Introduction to
        Deep Learning - Part 1</span></a></p>
      <p><a href="https://polarsparc.github.io/Mathematics/Calculus-2.html" target="_blank"><span class="bold">Introduction to Calculus
        - Part 2</span></a></p>
    </div>
    <hr class="gen-line-hr" />
    <div>
      <a id="gen-footer-a" href="https://polarsparc.github.io/">&copy;&nbsp;PolarSPARC</a>
    </div>
  </body>
</html>
